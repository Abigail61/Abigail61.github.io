<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>结合代码理解各种注意力机制（二）：多头注意力机制</title>
    <link href="/2025/01/26/%E7%BB%93%E5%90%88%E4%BB%A3%E7%A0%81%E7%90%86%E8%A7%A3%E5%90%84%E7%A7%8D%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9A%E5%A4%9A%E5%A4%B4%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/"/>
    <url>/2025/01/26/%E7%BB%93%E5%90%88%E4%BB%A3%E7%A0%81%E7%90%86%E8%A7%A3%E5%90%84%E7%A7%8D%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9A%E5%A4%9A%E5%A4%B4%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/</url>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>这是注意力机制系列的第二篇，在上一篇文章<br><a href="https://abigail61.github.io/2024/12/25/%E7%BB%93%E5%90%88%E4%BB%A3%E7%A0%81%E7%90%86%E8%A7%A3%E5%90%84%E7%A7%8D%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/">结合代码理解各种注意力机制（一）：自注意力机制</a>中，我们介绍了自注意力机制。此篇文章我们将在自注意力机制的基础上介绍多头注意力机制。</p><h1 id="多头注意力机制"><a href="#多头注意力机制" class="headerlink" title="多头注意力机制"></a>多头注意力机制</h1><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>多头注意力机制（Multi-Head Attention）是自注意力机制的扩展，它可以通过不同的子空间，来捕捉更多的信息。</p><p>其实，也就是我们可以拥有多组Wq,Wk,Wv，获得多种不同视角的注意力分数，然后将其进行拼接并进行线性变换。</p><p><img src="https://lyj-aliyun.oss-cn-shanghai.aliyuncs.com/test/202501261634302.png" alt="picture 0">  </p><p>通过多组QKV得到多个注意力分数，然后进行concat拼接，再进行线性变换。</p><p><img src="https://lyj-aliyun.oss-cn-shanghai.aliyuncs.com/test/202501261634303.png" alt="picture 1">  </p><p><img src="https://lyj-aliyun.oss-cn-shanghai.aliyuncs.com/test/202501261634304.png" alt="picture 2">  </p><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>在代码实现上，我们可以通过封装上一篇中实现的SelfAttention类，来实现多头注意力机制。</p><p>通过使用nn.ModuleList，我们可以将多个自注意力机制的实例封装在一起，然后通过torch.cat进行拼接。拼接完成后，再通过一个nn.Linear建立全连接层进行线性变换，维度为num_heads * d_v, d_v。</p><p>MHA类封装：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MultiHeadAttention</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, d_emb, d_q, d_k, d_v, num_heads</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-variable language_">self</span>.heads = nn.ModuleList(<br>            [SelfAttention(d_emb=d_emb, d_q=d_q, d_k=d_k, d_v=d_v) <br>            <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_heads)]<br>            )<br>        <span class="hljs-variable language_">self</span>.fc_concat_output = nn.Linear(num_heads * d_v, d_v)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, embed</span>):<br>        concat = torch.cat([head(embed) <span class="hljs-keyword">for</span> head <span class="hljs-keyword">in</span> <span class="hljs-variable language_">self</span>.heads], dim = -<span class="hljs-number">1</span>)<br>        <span class="hljs-comment">#print(f&quot;concat.shape:&#123;concat.shape&#125;&quot;)</span><br>        output = <span class="hljs-variable language_">self</span>.fc_concat_output(concat)<br>        <span class="hljs-comment">#print(f&quot;out_shape:&#123;output.shape&#125;&quot;)</span><br>        <span class="hljs-keyword">return</span> output<br></code></pre></td></tr></table></figure><p>MHA类使用：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">num_heads = <span class="hljs-number">8</span><br>mha = MultiHeadAttention(d_emb, d_q, d_k, d_v, num_heads)<br>result = mha(embedding_sentence)<br></code></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">concat.shape:torch.Size([<span class="hljs-number">9</span>, <span class="hljs-number">128</span>])<br>out_shape:torch.Size([<span class="hljs-number">9</span>, <span class="hljs-number">16</span>])<br></code></pre></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>代码</tag>
      
      <tag>transformer</tag>
      
      <tag>注意力机制</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【空格的呼吸】基于BPE的Tokenizer 分词原理介绍</title>
    <link href="/2025/01/09/%E7%A9%BA%E6%A0%BC%E7%9A%84%E5%91%BC%E5%90%B8/"/>
    <url>/2025/01/09/%E7%A9%BA%E6%A0%BC%E7%9A%84%E5%91%BC%E5%90%B8/</url>
    
    <content type="html"><![CDATA[<p>举个例子，本人在大模型分词时有遇到下面的现象，感到疑惑。</p><p>对同一个符号，有时候，空格的存在与否，会导致分词结果不一致。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;qwen2.5-7b-instruct&quot;</span>)<br>text = <span class="hljs-string">&quot;◎&quot;</span><br><span class="hljs-built_in">print</span>(tokenizer.encode(text))<br>text = <span class="hljs-string">&quot; ◎&quot;</span><br><span class="hljs-built_in">print</span>(tokenizer.encode(text))<br></code></pre></td></tr></table></figure><p>结果输出</p><figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs scheme">[<span class="hljs-name">âĹİ</span>]<br>[<span class="hljs-symbol">&#x27;ĠâĹ</span>&#x27;, <span class="hljs-symbol">&#x27;İ</span>&#x27;]<br></code></pre></td></tr></table></figure><p>根据<a href="https://github.com/vitanova/Qwen2/blob/main/tokenization_note_zh.md">Qwen2<br>&#x2F;tokenization_note_zh.md</a>，这里也提到了类似的现象：<br>一段文本在不同的上下文下可能会有不同的tokenize结果<br><img src="https://lyj-aliyun.oss-cn-shanghai.aliyuncs.com/test/image-5.png" alt="alt text"></p><ul><li>疑惑1：这些奇怪的字符是什么？</li><li>疑惑2：为什么空格会影响分词结果？</li></ul><p>接下来，就让我们解析tokenizer做了些什么。</p><h2 id="基础tokenizer分词流程"><a href="#基础tokenizer分词流程" class="headerlink" title="基础tokenizer分词流程"></a>基础tokenizer分词流程</h2><h3 id="原理描述"><a href="#原理描述" class="headerlink" title="原理描述"></a>原理描述</h3><ol><li><p><strong>初步分割</strong></p><ul><li>使用正则表达式对输入文本进行分割</li><li>分割依据：标点符号、字母数字、缩写词、换行符、空白符等</li><li>特点：所有分割符号（包括标点、空白符）都会被保留</li></ul></li><li><p><strong>UTF-8编码转换</strong></p><ul><li>将分割后的片段转换为UTF-8编码</li><li>ASCII字符（如英文字母）保持单字节编码</li><li>中文字符使用2-4字节编码</li></ul></li></ol><p>示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">text = <span class="hljs-string">&quot;hello, 猪头&quot;</span><br>byte_sequence = text.encode(<span class="hljs-string">&quot;utf-8&quot;</span>)<br><span class="hljs-built_in">print</span>(byte_sequence)<br><span class="hljs-comment"># 输出：b&#x27;hello, \xe7\x8c\xaa\xe5\xa4\xb4&#x27;</span><br></code></pre></td></tr></table></figure><h3 id="tokenizer内部的代码逻辑"><a href="#tokenizer内部的代码逻辑" class="headerlink" title="tokenizer内部的代码逻辑"></a>tokenizer内部的代码逻辑</h3><ol start="3"><li><strong>Unicode字符转换</strong><ul><li>将UTF-8字节序列映射为Unicode字符</li><li>每个字节对应特定的Unicode字符（如\xe7对应ç）</li></ul></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 字节序列转Unicode字符</span><br>unicode_sequence = [<span class="hljs-built_in">chr</span>(c) <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> byte_sequence]<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;&quot;</span>.join(unicode_sequence))<br><span class="hljs-comment"># 输出：hello, çªå¤´</span><br></code></pre></td></tr></table></figure><p>上述代码在tokenizer中，是基于字节序列转Unicode字符，然后进行BPE算法处理。<br>4. <strong>BPE算法处理</strong></p><ul><li><p><strong>训练阶段</strong>：</p><ul><li>统计字符对出现频次</li><li>按频次高低逐步合并字符</li><li>将合并规则保存至merges.txt</li></ul></li><li><p><strong>推理阶段</strong>：</p><ul><li>生成输入文本的unicode字符串的bigram组合</li><li>按merges.txt中的优先级顺序进行合并</li><li>循环处理直至无可合并字符对</li></ul></li></ul><h2 id="空格影响分析：以”◎”符号为例"><a href="#空格影响分析：以”◎”符号为例" class="headerlink" title="空格影响分析：以”◎”符号为例"></a>空格影响分析：以”◎”符号为例</h2><h3 id="带空格情况（”-◎”）"><a href="#带空格情况（”-◎”）" class="headerlink" title="带空格情况（” ◎”）"></a>带空格情况（” ◎”）</h3><ol><li>Unicode序列：”ĠâĹİ”</li><li>分词过程：<ul><li>初始bigram：<code>Ġâ</code>, <code>âĹ</code>, <code>Ĺİ</code></li><li>按优先级合并：<code>Ġâ</code> → <code>ĠâĹ</code> + <code>İ</code></li></ul></li><li>最终结果：<code>[&#39;ĠâĹ&#39;, &#39;İ&#39;]</code></li></ol><h3 id="无空格情况（”◎”）"><a href="#无空格情况（”◎”）" class="headerlink" title="无空格情况（”◎”）"></a>无空格情况（”◎”）</h3><ol><li>Unicode序列：”âĹİ”</li><li>分词过程：<ul><li>直接合并：<code>âĹ</code> + <code>İ</code> → <code>âĹİ</code></li></ul></li><li>最终结果：<code>[âĹİ]</code></li></ol><p>分词好之后，会根据vocab.json字典，将这些token子词转换成id</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>空格的存在会显著影响分词结果，即使是同一个符号：</p><ul><li>有空格：分词为两个token</li><li>无空格：保持为单个token</li></ul><p>这种差异提醒我们在文本预处理时需要特别注意空格的处理，以确保分词的一致性和准确性。</p><p>&lt;特别提示&gt;<br>如果想对词表进行扩展，在qwen系列种不适用，因为它是基于BPE算法进行训练的。所以，就算我们往词表里加入新词（例如：”piggrain”，我家狗的名字）。但是由于merges.txt中如果没有任意子词的组合能组合成piggrain,所以，新词也仍然会被切割，并不会保留这个完整的词。</p>]]></content>
    
    
    
    <tags>
      
      <tag>Tokenizer</tag>
      
      <tag>分词</tag>
      
      <tag>BPE</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>linux服务器之间通过syncthing同步</title>
    <link href="/2025/01/03/linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B9%8B%E9%97%B4%E9%80%9A%E8%BF%87syncthing%E5%90%8C%E6%AD%A5/"/>
    <url>/2025/01/03/linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B9%8B%E9%97%B4%E9%80%9A%E8%BF%87syncthing%E5%90%8C%E6%AD%A5/</url>
    
    <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>拥有2台服务器，想在服务器之间同步某个文件夹的数据，实现丝滑工作</p><h1 id="步骤1：安装syncthing"><a href="#步骤1：安装syncthing" class="headerlink" title="步骤1：安装syncthing"></a>步骤1：安装syncthing</h1><p>如果是ubuntu，可以通过apt安装</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> apt install syncthing<br></code></pre></td></tr></table></figure><p>(其他系统可以参考<a href="https://docs.syncthing.net/">官方文档</a>)</p><p>启动syncthing</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">syncthing<br></code></pre></td></tr></table></figure><p>安装好之后输入syncthing，会启动syncthing，自动打开浏览器。稍后在浏览器中进行配置就好</p><p>【注意】在两台服务器上都要安装并启动syncthing</p><h1 id="步骤2：配置syncthing"><a href="#步骤2：配置syncthing" class="headerlink" title="步骤2：配置syncthing"></a>步骤2：配置syncthing</h1><p>默认第一台服务器中打开的是<a href="http://127.0.0.1:8384/">http://127.0.0.1:8384/</a><br>第二台服务器中打开的是<a href="http://127.0.0.1:8385/">http://127.0.0.1:8385/</a></p><p>接下来需要让这两台服务器之间认识认识，可以互相通信。</p><ol><li><p>交换设备ID<br>在第一台服务器的syncthing图形化界面配置中，点击右上角的设置，选择“设备”，然后点击“设备ID”，复制设备ID。<br>在第二台服务器的syncthing图形化界面配置中，点击右下角的“添加远程设备”，然后输入设备ID，点击“添加”。<br><img src="https://lyj-aliyun.oss-cn-shanghai.aliyuncs.com/test/image.png" alt="alt text"><br>然后回到第一台服务器，会出现一个提示“是否允许远程设备访问”，点击“允许”。<br>这样，两台服务器之间就可以互相通信了</p></li><li><p>添加共享文件夹进行同步<br>点击添加文件夹，在【常规】选项卡中输入待共享文件夹的名称，确定一下待共享文件夹的路径<br><img src="https://lyj-aliyun.oss-cn-shanghai.aliyuncs.com/test/image-1.png" alt="alt text"><br>在【共享】选项卡中，选择待共享的设备<br><img src="https://lyj-aliyun.oss-cn-shanghai.aliyuncs.com/test/image-2.png" alt="alt text"></p></li></ol><p>这样就好啦！</p>]]></content>
    
    
    
    <tags>
      
      <tag>syncthing</tag>
      
      <tag>linux</tag>
      
      <tag>服务器</tag>
      
      <tag>数据同步</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>结合代码理解各种注意力机制（一）：自注意力机制</title>
    <link href="/2024/12/25/%E7%BB%93%E5%90%88%E4%BB%A3%E7%A0%81%E7%90%86%E8%A7%A3%E5%90%84%E7%A7%8D%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/"/>
    <url>/2024/12/25/%E7%BB%93%E5%90%88%E4%BB%A3%E7%A0%81%E7%90%86%E8%A7%A3%E5%90%84%E7%A7%8D%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/</url>
    
    <content type="html"><![CDATA[<p>transformer中最重要的就是注意力机制，从经典论文Attention is all you need出发，到后来的各种注意力机制的改进。本系列将手撕各种注意力机制，包括但不限于：</p><ul><li>self-attention(SA) 自注意力机制</li><li>multi-head attention(MHA) 多头注意力机制</li><li>multi-query attention(MQA) 分组注意力机制</li></ul><p>在此系列的第一篇中，我们聚焦于经典的自注意力机制，mask的注意力机制，以及多头注意力机制的改进。</p><h1 id="前置词典和词向量的构建"><a href="#前置词典和词向量的构建" class="headerlink" title="前置词典和词向量的构建"></a>前置词典和词向量的构建</h1><h2 id="1-词典dictionary构建"><a href="#1-词典dictionary构建" class="headerlink" title="1. 词典dictionary构建"></a>1. 词典dictionary构建</h2><p>假设我们有一个句子：</p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm">The quick <span class="hljs-keyword">brown </span>fox <span class="hljs-keyword">jumps </span>over the lazy dog<br></code></pre></td></tr></table></figure><p>然后对句子进行分词，构建词典。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">text = <span class="hljs-string">&quot;The quick brown fox jumps over the lazy dog&quot;</span><br><br><span class="hljs-built_in">dict</span> = &#123;token: i <span class="hljs-keyword">for</span> i, token <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(<span class="hljs-built_in">sorted</span>(<span class="hljs-built_in">set</span>(text.split())))&#125;<br><br><span class="hljs-built_in">dict</span><br></code></pre></td></tr></table></figure><p>打印结果如下：</p><p> {‘The’: 0,<br> ‘brown’: 1,<br> ‘dog’: 2,<br> ‘fox’: 3,<br> ‘jumps’: 4,<br> ‘lazy’: 5,<br> ‘over’: 6,<br> ‘quick’: 7,<br> ‘the’: 8}</p><p>将原来的英文句子转换成对应词典中的索引</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">text_id = torch.tensor([<span class="hljs-built_in">dict</span>[token] <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> text.split()])<br></code></pre></td></tr></table></figure><p>得到的text_id结果如下：<br>tensor([0, 7, 1, 3, 4, 6, 8, 5, 2])</p><h2 id="2-词嵌入构建"><a href="#2-词嵌入构建" class="headerlink" title="2. 词嵌入构建"></a>2. 词嵌入构建</h2><p>利用torch.nn.Embedding构建词嵌入，在这里设置的词向量维度为5，方便演示。而实际中，大模型的词向量往往很高，比如在Gpt系列中词向量维度就是12800。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 设置随机种子</span><br>torch.manual_seed(<span class="hljs-number">42</span>)<br><br><span class="hljs-comment"># 构建词嵌入层</span><br>len_dict = <span class="hljs-built_in">len</span>(<span class="hljs-built_in">dict</span>) <span class="hljs-comment"># 词典长度</span><br>dim_embedding = <span class="hljs-number">5</span> <span class="hljs-comment"># 词嵌入维度，可以自定义</span><br><br>embed = torch.nn.Embedding(len_dict, dim_embedding)<br>embedding_sentence = embed(text_id)<br><br>embedding_sentence<br></code></pre></td></tr></table></figure><p>得到结果:</p><figure class="highlight subunit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs subunit">tensor([[ 1.9269,  1.4873,  0.9007, <span class="hljs-string">-2</span>.1055,  0.6784],<br>        [ 0.5258, <span class="hljs-string">-0</span>.4880, <span class="hljs-string">-0</span>.4345, <span class="hljs-string">-1</span>.3864, <span class="hljs-string">-1</span>.2862],<br>        [<span class="hljs-string">-1</span>.2345, <span class="hljs-string">-0</span>.0431, <span class="hljs-string">-1</span>.6047, <span class="hljs-string">-0</span>.7521,  1.6487],<br>        [ 0.7624,  1.6423, <span class="hljs-string">-0</span>.1596, <span class="hljs-string">-0</span>.4974,  0.4396],<br>        [<span class="hljs-string">-0</span>.7581,  1.0783,  0.8008,  1.6806,  1.2791],<br>        [<span class="hljs-string">-1</span>.0892, <span class="hljs-string">-0</span>.3553, <span class="hljs-string">-0</span>.9138, <span class="hljs-string">-0</span>.6581,  0.0780],<br>        [<span class="hljs-string">-1</span>.4032,  0.0360, <span class="hljs-string">-0</span>.0635,  0.6756, <span class="hljs-string">-0</span>.0978],<br>        [ 1.2964,  0.6105,  1.3347, <span class="hljs-string">-0</span>.2316,  0.6872],<br>        [<span class="hljs-string">-0</span>.3925, <span class="hljs-string">-1</span>.4036, <span class="hljs-string">-0</span>.7279, <span class="hljs-string">-0</span>.5594, <span class="hljs-string">-0</span>.7688]],<br>       grad_fn=&lt;EmbeddingBackward0&gt;)<br></code></pre></td></tr></table></figure><p>绘制了一张表格来表示各个词对应的词向量：<br><img src="https://lyj-aliyun.oss-cn-shanghai.aliyuncs.com/test/202501260009113.png" alt="alt text"></p><h1 id="自注意力机制实现"><a href="#自注意力机制实现" class="headerlink" title="自注意力机制实现"></a>自注意力机制实现</h1><h2 id="流程说明"><a href="#流程说明" class="headerlink" title="流程说明"></a>流程说明</h2><p>我们需要将每个词的embedding投影到三个空间中，分别表示query, key, value。</p><p>那么投影后的query, key, value向量维度dq, dk, dv是多少呢？需要注意的是，query和key的维度需要相同，而dv可以和dq, dk不同</p><p><img src="https://lyj-aliyun.oss-cn-shanghai.aliyuncs.com/test/202501260009252.png" alt="alt text"></p><p>注意力机制计算的公式如下：<br><img src="https://lyj-aliyun.oss-cn-shanghai.aliyuncs.com/test/202501260009281.png"></p><p>可以根据这个计算流程图来计算：<br><img src="https://lyj-aliyun.oss-cn-shanghai.aliyuncs.com/test/202501260009310.png" alt="picture 1">  </p><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>代码是经过结构化的，封装了一个self-attention的类，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SelfAttention</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, d_emb, d_k, d_q, d_v</span>):<br>        torch.manual_seed(<span class="hljs-number">0</span>)<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-variable language_">self</span>.d_k = d_k <span class="hljs-comment"># 方便后面除以维度进行缩放</span><br>        <span class="hljs-variable language_">self</span>.get_query = nn.Linear(d_emb, d_q)<br>        <span class="hljs-variable language_">self</span>.get_key = nn.Linear(d_emb, d_k)<br>        <span class="hljs-variable language_">self</span>.get_value = nn.Linear(d_emb, d_v)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, embed</span>):<br>        query = <span class="hljs-variable language_">self</span>.get_query(embed)<br>        key = <span class="hljs-variable language_">self</span>.get_key(embed)<br>        value = <span class="hljs-variable language_">self</span>.get_value(embed)<br><br>        attn_score = query @ key.T<br>        attn_score = torch.softmax(attn_score / <span class="hljs-variable language_">self</span>.d_k ** <span class="hljs-number">0.5</span>, dim = -<span class="hljs-number">1</span>) <span class="hljs-comment"># dim = -1表示最后一个维度，表示按列进行softmax</span><br>        attn_score = attn_score @ value<br>        <br>        <span class="hljs-keyword">return</span> attn_score<br></code></pre></td></tr></table></figure><p>使用这个模块的步骤如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">d_emb = <span class="hljs-number">5</span><br>d_q= <span class="hljs-number">10</span><br>d_k = <span class="hljs-number">10</span><br>d_v = <span class="hljs-number">16</span><br><br>sa = SelfAttention(d_emb = d_emb, d_q= d_q, d_k=d_k, d_v=d_v)<br><br>attn_score = sa(embedding_sentence)<br><span class="hljs-built_in">print</span>(attn_score)<br><span class="hljs-built_in">print</span>(attn_score.shape)<br><br></code></pre></td></tr></table></figure><p>得到的结果如下，具体的数值就略过，我们查看形状即可：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">torch.Size([<span class="hljs-number">9</span>, <span class="hljs-number">16</span>])<br></code></pre></td></tr></table></figure><hr><h2 id="备注"><a href="#备注" class="headerlink" title="备注"></a>备注</h2><p>但实际上，n &#x3D; 9, d_emb &#x3D; 5, embedding的形状为[9, 5]</p><p>而attn_score的形状为[9, 16]。<br>我们期望的是经过注意力机制之后，能生成一个和embedding形状相同的向量，称为△E,这样可以和原来的embedding相加，得到新的embedding： E &#x3D; E + ΔE。 这也是add &amp; normalize 中的add部分。</p><p>但目前attn_score的形状和embedding的形状不一致，怎么办呀？所以需要进行调整。<br>后面在实现的时候，通常还会有一个down_project层，维度为[d_k, d_emb]，将attn_score的形状调整到和embedding的形状一致。</p><p>理想状况下的self-attention的维度变化如下：<br><img src="https://lyj-aliyun.oss-cn-shanghai.aliyuncs.com/test/202501260009338.png" alt="picture 2">  </p><p>但实际上因为这个[d_emb, d_emb]的矩阵太大了，所以会拆成两个矩阵，一个up_project层,一个down_project层，中间的小维度就是d_v。而通常把第一个up_project层称为w_value。</p><p>d_v可以和dq, dk不同，因为它在作用时，是和n*n的矩阵进行相乘，和q,k的维度无关。</p><p><img src="https://lyj-aliyun.oss-cn-shanghai.aliyuncs.com/test/202501260009366.png" alt="picture 3">  </p><p>所以</p><blockquote><p>参考文档<br><a href="https://mp.weixin.qq.com/s/5TPYtEElfiSH8cHdu4uN7A">https://mp.weixin.qq.com/s/5TPYtEElfiSH8cHdu4uN7A</a><br>3b1b对self-attention的理解</p></blockquote>]]></content>
    
    
    
    <tags>
      
      <tag>代码</tag>
      
      <tag>transformer</tag>
      
      <tag>注意力机制</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>torch代码演示模型训练流程中的梯度变化</title>
    <link href="/2024/12/05/%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B%E4%B8%AD%E7%9A%84%E6%A2%AF%E5%BA%A6%E5%8F%98%E5%8C%96/"/>
    <url>/2024/12/05/%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B%E4%B8%AD%E7%9A%84%E6%A2%AF%E5%BA%A6%E5%8F%98%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch <br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim<br><span class="hljs-keyword">import</span> random<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python">random.seed(<span class="hljs-number">42</span>)<br><span class="hljs-comment"># 定义一个简单的神经网络模型</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SimpleNN</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(SimpleNN, <span class="hljs-variable language_">self</span>).__init__()<br>        <span class="hljs-variable language_">self</span>.fc1 = nn.Linear(<span class="hljs-number">5</span>,<span class="hljs-number">2</span>) <span class="hljs-comment"># 输入3维，输出2维</span><br>        <span class="hljs-variable language_">self</span>.fc2 = nn.Linear(<span class="hljs-number">2</span>,<span class="hljs-number">5</span>) <span class="hljs-comment"># 输入2维，输出3维</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">        x -&gt; fc1(down projection) -&gt; relu -&gt; fc2(up projection) -&gt; +x -&gt; output</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        x = x + <span class="hljs-variable language_">self</span>.fc2(torch.relu(<span class="hljs-variable language_">self</span>.fc1(x)))<br>        <span class="hljs-keyword">return</span> x<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 创建模型实例</span><br>model = SimpleNN()<br><br><span class="hljs-comment"># 输入数据创建</span><br><span class="hljs-built_in">input</span> = torch.randn(<span class="hljs-number">5</span>,<span class="hljs-number">5</span>) <span class="hljs-comment"># 5个样本，每个样本5个维度</span><br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;======接下来请看输入数据经过每一层的变化吧========&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;输入的数据input:\n&quot;</span>, <span class="hljs-built_in">input</span>)<br><br><span class="hljs-comment"># 查看fc1的参数</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;fc1的参数：fc1.weight\n:&quot;</span>, model.fc1.weight)<br><br><span class="hljs-comment"># fc1(x)</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;fc1(x):\n&quot;</span>, model.fc1(<span class="hljs-built_in">input</span>))<br><br><span class="hljs-comment"># relu(fc1(x))</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;relu(fc1(x))\n&quot;</span>, torch.relu(model.fc1(<span class="hljs-built_in">input</span>)))<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;fc2(relu(fc1(x))):\n&quot;</span>,model.fc2(torch.relu(model.fc1(<span class="hljs-built_in">input</span>))))<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;x + fc2(relu(fc1(x))):\n&quot;</span>,<span class="hljs-built_in">input</span> + model.fc2(torch.relu(model.fc1(<span class="hljs-built_in">input</span>))))<br><span class="hljs-comment"># 和直接前向传播进行对比</span><br>output = model(<span class="hljs-built_in">input</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;============这和model(input)得到的结果一不一致呢？======&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;model(input):\n&quot;</span>,output)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;结果其实是:\n&quot;</span>,output == <span class="hljs-built_in">input</span> + model.fc2(torch.relu(model.fc1(<span class="hljs-built_in">input</span>))))<br></code></pre></td></tr></table></figure><pre><code class="hljs">======接下来请看输入数据经过每一层的变化吧========输入的数据input: tensor([[-1.2202,  0.2502, -0.2889, -0.1986, -2.8538],        [ 0.4287, -1.6049,  0.5761,  1.1029, -1.6302],        [ 0.4738,  1.0801, -0.6158, -0.0197, -0.6740],        [-0.5638,  0.9001,  0.4496, -0.5458,  0.1249],        [ 1.9979, -1.1930,  1.5334, -0.8725, -0.0448]])fc1的参数：fc1.weight: Parameter containing:tensor([[ 0.0664,  0.0643, -0.1771, -0.3984, -0.3248],        [ 0.1452, -0.1781,  0.1125,  0.2815,  0.0503]], requires_grad=True)fc1(x): tensor([[ 1.2801, -0.1998],        [ 0.2011,  0.8952],        [ 0.7247,  0.0215],        [ 0.4057, -0.0852],        [ 0.4344,  0.6810]], grad_fn=&lt;AddmmBackward0&gt;)relu(fc1(x)) tensor([[1.2801, 0.0000],        [0.2011, 0.8952],        [0.7247, 0.0215],        [0.4057, 0.0000],        [0.4344, 0.6810]], grad_fn=&lt;ReluBackward0&gt;)fc2(relu(fc1(x))): tensor([[-3.1179e-01,  9.2656e-01,  6.6133e-01,  7.6778e-01,  1.6566e-01],        [-2.3086e-01, -3.6633e-02, -2.4526e-03, -2.0451e-04,  7.2680e-01],        [-2.0840e-01,  6.7831e-01,  5.9427e-01,  4.4476e-01,  2.5295e-01],        [-1.4424e-01,  5.5479e-01,  5.7692e-01,  2.6476e-01,  2.8756e-01],        [-2.4546e-01,  1.8325e-01,  1.5396e-01,  1.6924e-01,  5.9601e-01]],       grad_fn=&lt;AddmmBackward0&gt;)x + fc2(relu(fc1(x))): tensor([[-1.5320,  1.1768,  0.3724,  0.5691, -2.6881],        [ 0.1978, -1.6415,  0.5737,  1.1027, -0.9035],        [ 0.2654,  1.7584, -0.0215,  0.4250, -0.4211],        [-0.7080,  1.4549,  1.0265, -0.2810,  0.4125],        [ 1.7524, -1.0097,  1.6874, -0.7032,  0.5512]], grad_fn=&lt;AddBackward0&gt;)============这和model(input)得到的结果一不一致呢？======model(input): tensor([[-1.5320,  1.1768,  0.3724,  0.5691, -2.6881],        [ 0.1978, -1.6415,  0.5737,  1.1027, -0.9035],        [ 0.2654,  1.7584, -0.0215,  0.4250, -0.4211],        [-0.7080,  1.4549,  1.0265, -0.2810,  0.4125],        [ 1.7524, -1.0097,  1.6874, -0.7032,  0.5512]], grad_fn=&lt;AddBackward0&gt;)结果其实是: tensor([[True, True, True, True, True],        [True, True, True, True, True],        [True, True, True, True, True],        [True, True, True, True, True],        [True, True, True, True, True]])</code></pre><p>x -&gt; fc1(down projection) -&gt; relu -&gt; fc2(up projection)-&gt; +x -&gt; output</p><h3 id="新建一个base模型以及adapter，并且保证base模型在训练的时候参数不变，只微调adapter的参数"><a href="#新建一个base模型以及adapter，并且保证base模型在训练的时候参数不变，只微调adapter的参数" class="headerlink" title="新建一个base模型以及adapter，并且保证base模型在训练的时候参数不变，只微调adapter的参数"></a>新建一个base模型以及adapter，并且保证base模型在训练的时候参数不变，只微调adapter的参数</h3><ol><li>模型定义</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">BaseModel</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(BaseModel, <span class="hljs-variable language_">self</span>).__init__()<br>        <span class="hljs-variable language_">self</span>.fc1 = nn.Linear(<span class="hljs-number">5</span>, <span class="hljs-number">10</span>) <span class="hljs-comment"># 本来只有5个特征，比如西瓜的大小，重量，颜色，声音，叶子。 然后把它向上投影到10维空间里</span><br>        <span class="hljs-variable language_">self</span>.fc2 = nn.Linear(<span class="hljs-number">10</span>, <span class="hljs-number">5</span>) <span class="hljs-comment"># 再映射回原来的维度</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = torch.relu(<span class="hljs-variable language_">self</span>.fc1(x))<br>        x = <span class="hljs-variable language_">self</span>.fc2(x)<br>        <span class="hljs-keyword">return</span> x<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Adapter</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(Adapter, <span class="hljs-variable language_">self</span>).__init__()<br>        <span class="hljs-variable language_">self</span>.fc1 = nn.Linear(<span class="hljs-number">5</span>,<span class="hljs-number">2</span>)<br>        <span class="hljs-variable language_">self</span>.fc2 = nn.Linear(<span class="hljs-number">2</span>,<span class="hljs-number">5</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-comment"># fc1_x = self.fc1(x)</span><br>        <span class="hljs-comment"># relu_fc1_x = torch.relu(fc1_x)</span><br>        <span class="hljs-comment"># fc2_relu_fc1_x = self.fc2(relu_fc1_x)</span><br>        <span class="hljs-comment"># return x + fc2_relu_fc1_x</span><br>        residual = x<br>        x = torch.relu(<span class="hljs-variable language_">self</span>.fc1(x))<br>        x = <span class="hljs-variable language_">self</span>.fc2(x)<br>        x = x + residual<br>        <span class="hljs-keyword">return</span> x<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">BasewithAdapter</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, base_model, adapter</span>):<br>        <span class="hljs-built_in">super</span>(BasewithAdapter, <span class="hljs-variable language_">self</span>).__init__()<br>        <span class="hljs-variable language_">self</span>.base_model = base_model<br>        <span class="hljs-variable language_">self</span>.adapter = adapter<br>        <span class="hljs-variable language_">self</span>.classhead = nn.Linear(<span class="hljs-number">5</span>,<span class="hljs-number">1</span>)<br>        <span class="hljs-variable language_">self</span>.sigmoid = nn.Sigmoid()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        base_output = <span class="hljs-variable language_">self</span>.base_model(x)<br>        adapter_output = <span class="hljs-variable language_">self</span>.adapter(x)<br>        output = <span class="hljs-variable language_">self</span>.classhead(base_output + adapter_output)<br>        <span class="hljs-comment"># 二分类用sigmoid, 多分类用softmax. </span><br>        output = <span class="hljs-variable language_">self</span>.sigmoid(output)<br>        <span class="hljs-keyword">return</span> output<br><br>        <br></code></pre></td></tr></table></figure><ol start="2"><li>模型初始化</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">base_model = BaseModel()<br>adapter = Adapter()<br>model = BasewithAdapter(base_model, adapter)<br></code></pre></td></tr></table></figure><p>查看basemodel结构</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;==========base_model=========&quot;</span>)<br><span class="hljs-built_in">print</span>(base_model)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;-&quot;</span> * <span class="hljs-number">50</span>)<br><br><span class="hljs-keyword">for</span> name, param <span class="hljs-keyword">in</span> base_model.named_parameters():<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;parameter name:<span class="hljs-subst">&#123;name&#125;</span>&quot;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;parameter value:<span class="hljs-subst">&#123;param&#125;</span>&quot;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;-&quot;</span> * <span class="hljs-number">50</span>)<br></code></pre></td></tr></table></figure><pre><code class="hljs">==========base_model=========BaseModel(  (fc1): Linear(in_features=5, out_features=10, bias=True)  (fc2): Linear(in_features=10, out_features=5, bias=True))--------------------------------------------------parameter name:fc1.weightparameter value:Parameter containing:tensor([[ 0.4336, -0.2527, -0.1431, -0.3255,  0.1239],        [-0.2378,  0.1515,  0.4288, -0.3317,  0.2779],        [ 0.1535,  0.1688, -0.3781, -0.2174,  0.0738],        [-0.2811, -0.3980, -0.3960, -0.4455,  0.2161],        [ 0.1410, -0.3365,  0.3386,  0.1728,  0.0791],        [ 0.1138, -0.2654,  0.3056,  0.0793,  0.2307],        [-0.2616,  0.2112,  0.2274,  0.0392,  0.1044],        [-0.2264, -0.1778,  0.2020,  0.0354,  0.1658],        [-0.2374,  0.0352, -0.1868,  0.2495,  0.0379],        [-0.2995, -0.2185, -0.1470, -0.3039, -0.4207]], requires_grad=True)--------------------------------------------------parameter name:fc1.biasparameter value:Parameter containing:tensor([-0.0974,  0.1413,  0.2264,  0.2783, -0.0539, -0.0556, -0.3448, -0.3413,        -0.2531,  0.1960], requires_grad=True)--------------------------------------------------parameter name:fc2.weightparameter value:Parameter containing:tensor([[ 0.2579, -0.2095, -0.1630,  0.2688,  0.2801,  0.2098, -0.2368, -0.0675,          0.2128,  0.1830],        [ 0.2660,  0.1586,  0.0018, -0.2677, -0.0120,  0.1762,  0.0789,  0.0946,         -0.2273, -0.2025],        [ 0.1673, -0.0173,  0.0494,  0.2060, -0.2267,  0.3011, -0.1249, -0.1388,         -0.0258,  0.0965],        [ 0.0940, -0.2441, -0.2963, -0.1249,  0.1784, -0.2184,  0.0044,  0.0368,          0.0734, -0.3110],        [ 0.1679, -0.1773,  0.1796, -0.1042,  0.0288,  0.0196, -0.0735, -0.0327,         -0.0457,  0.0938]], requires_grad=True)--------------------------------------------------parameter name:fc2.biasparameter value:Parameter containing:tensor([ 0.0478,  0.0522, -0.2679, -0.0112, -0.2772], requires_grad=True)--------------------------------------------------</code></pre><p>查看adapter结构</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;==========adapter=========&quot;</span>)<br><span class="hljs-built_in">print</span>(adapter)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;-&quot;</span> * <span class="hljs-number">50</span>)<br><br><span class="hljs-keyword">for</span> name, param <span class="hljs-keyword">in</span> adapter.named_parameters():<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;parameter name:<span class="hljs-subst">&#123;name&#125;</span>&quot;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;parameter value:<span class="hljs-subst">&#123;param&#125;</span>&quot;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;-&quot;</span> * <span class="hljs-number">50</span>)<br></code></pre></td></tr></table></figure><pre><code class="hljs">==========adapter=========Adapter(  (fc1): Linear(in_features=5, out_features=2, bias=True)  (fc2): Linear(in_features=2, out_features=5, bias=True))--------------------------------------------------parameter name:fc1.weightparameter value:Parameter containing:tensor([[-0.1502, -0.0157,  0.1981, -0.3822, -0.1813],        [-0.0734,  0.3920,  0.1197, -0.4180,  0.2841]], requires_grad=True)--------------------------------------------------parameter name:fc1.biasparameter value:Parameter containing:tensor([ 0.4073, -0.0563], requires_grad=True)--------------------------------------------------parameter name:fc2.weightparameter value:Parameter containing:tensor([[-0.3924,  0.0132],        [ 0.2919, -0.5051],        [ 0.4481,  0.6499],        [-0.3320, -0.6645],        [ 0.0464,  0.4679]], requires_grad=True)--------------------------------------------------parameter name:fc2.biasparameter value:Parameter containing:tensor([ 0.4048, -0.1295,  0.1568, -0.2318,  0.0233], requires_grad=True)--------------------------------------------------</code></pre><p>冻结base模型里的参数，使得它不会被更新</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> model.base_model.parameters():<br>    param.requires_grad = <span class="hljs-literal">False</span><br><br><span class="hljs-comment"># 检查模型中哪些参数会被更新</span><br><span class="hljs-keyword">for</span> name, param <span class="hljs-keyword">in</span> model.named_parameters():<br>    <span class="hljs-built_in">print</span>(name, param.requires_grad)<br></code></pre></td></tr></table></figure><pre><code class="hljs">base_model.fc1.weight Falsebase_model.fc1.bias Falsebase_model.fc2.weight Falsebase_model.fc2.bias Falseadapter.fc1.weight Trueadapter.fc1.bias Trueadapter.fc2.weight Trueadapter.fc2.bias Trueclasshead.weight Trueclasshead.bias True</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#创建训练数据</span><br><span class="hljs-comment"># x： [10, 5] # 10个西瓜，每个西瓜有5个特征。我们建立模型的时候，不关注样本的数量，主要关注特征的维度。因为样本数量这些都是可以修改的</span><br><span class="hljs-comment"># y:  [10] # 每个西瓜是好瓜还是坏瓜</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">input_data = torch.randn(<span class="hljs-number">10</span>,<span class="hljs-number">5</span>)<br><span class="hljs-comment"># 注意，这样写可能会有问题。当反向传播的时候，我们的target是整型的，无法和float类型的output数据进行计算</span><br><span class="hljs-comment"># target_data = torch.randint(0,2,(10,)) # 位于[0,2) 之间的随机整数（也就是0和1啦），然后初始化10个，使用（10，）...背下来吧</span><br>target_data = torch.randint(<span class="hljs-number">0</span>,<span class="hljs-number">2</span>,(<span class="hljs-number">10</span>,), dtype=torch.<span class="hljs-built_in">float</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">input_data<br></code></pre></td></tr></table></figure><pre><code class="hljs">tensor([[-1.4232, -0.3832, -0.4198,  0.4228,  0.2203],        [-1.4282,  1.8447, -1.2595, -0.9088, -1.3608],        [ 1.6698, -0.1378, -1.5213,  0.6471,  1.0883],        [ 0.9648,  0.0560, -0.2517, -1.3640, -0.8051],        [-1.5178, -0.0528, -1.1300, -1.5049, -0.9609],        [-0.9048,  0.0666, -0.8958, -0.6056,  0.0209],        [ 2.3616,  0.1847,  0.8678, -0.9167,  0.9430],        [-0.3303,  0.4280, -0.2748, -2.5328, -1.4385],        [ 1.8969, -1.8394, -0.0575, -0.0590, -2.4369],        [-0.8545, -1.0343, -0.3162,  0.3940, -1.0028]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">target_data<br></code></pre></td></tr></table></figure><pre><code class="hljs">tensor([0., 1., 0., 1., 0., 1., 0., 0., 1., 0.])</code></pre><p>定义loss</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">loss_fn = nn.MSELoss()<br></code></pre></td></tr></table></figure><p>定义优化器</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">optimizer = optim.Adam(model.parameters(), lr = <span class="hljs-number">1e-3</span>)<br></code></pre></td></tr></table></figure><p>进行前向传播</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 进行前向传播</span><br>output = model(input_data)<br>output<br></code></pre></td></tr></table></figure><pre><code class="hljs">tensor([[0.6159],        [0.5352],        [0.5104],        [0.3628],        [0.6889],        [0.6323],        [0.3086],        [0.5092],        [0.1160],        [0.4349]], grad_fn=&lt;SigmoidBackward0&gt;)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 损失函数设置成均方误差</span><br>loss = loss_fn(output.squeeze(), target_data)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;loss:<span class="hljs-subst">&#123;loss&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure><pre><code class="hljs">loss:0.3196709156036377</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 手动计算均方误差 MSE = (1/n) * Σ(y_pred - y_true)²</span><br><span class="hljs-comment"># 注意，这里只是答应了一个值。这种loss应该是没法反向传播的，因为他没有什么什么计算图？只是一个简单浮点数而已</span><br><span class="hljs-built_in">print</span>(torch.<span class="hljs-built_in">sum</span>((output.squeeze() - target_data) ** <span class="hljs-number">2</span>) / <span class="hljs-number">10</span>)<br></code></pre></td></tr></table></figure><pre><code class="hljs">tensor(0.3197, grad_fn=&lt;DivBackward0&gt;)</code></pre><p>进行反向传播前，打印每个参数的梯度</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 进行反向传播之前，查看梯度</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;gradient:&quot;</span>)<br><span class="hljs-keyword">for</span> name, param <span class="hljs-keyword">in</span> model.named_parameters():<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;name&#125;</span>&quot;</span>)<br>    <span class="hljs-keyword">try</span> :<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;梯度：<span class="hljs-subst">&#123;param.grad&#125;</span>&quot;</span>)<br>    <span class="hljs-keyword">except</span>:<br>        <span class="hljs-keyword">pass</span><br></code></pre></td></tr></table></figure><pre><code class="hljs">gradient:base_model.fc1.weight梯度：Nonebase_model.fc1.bias梯度：Nonebase_model.fc2.weight梯度：Nonebase_model.fc2.bias梯度：Noneadapter.fc1.weight梯度：Noneadapter.fc1.bias梯度：Noneadapter.fc2.weight梯度：Noneadapter.fc2.bias梯度：Noneclasshead.weight梯度：Noneclasshead.bias梯度：None</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 进行反向传播后，查看梯度</span><br>loss.backward()<br><span class="hljs-keyword">for</span> name, param <span class="hljs-keyword">in</span> model.named_parameters():<br>    <span class="hljs-built_in">print</span>(name)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;gradient:<span class="hljs-subst">&#123;param.grad&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure><pre><code class="hljs">base_model.fc1.weightgradient:Nonebase_model.fc1.biasgradient:Nonebase_model.fc2.weightgradient:Nonebase_model.fc2.biasgradient:Noneadapter.fc1.weightgradient:tensor([[ 2.0354e-02, -7.9889e-03, -2.1384e-03,  9.3599e-03, -7.7675e-03],        [ 7.1102e-04,  3.8607e-05,  5.5156e-04, -9.6660e-04, -1.3542e-03]])adapter.fc1.biasgradient:tensor([-0.0043, -0.0006])adapter.fc2.weightgradient:tensor([[ 0.0065, -0.0079],        [ 0.0049, -0.0060],        [ 0.0074, -0.0090],        [ 0.0069, -0.0085],        [-0.0105,  0.0128]])adapter.fc2.biasgradient:tensor([-0.0130, -0.0098, -0.0147, -0.0139,  0.0210])classhead.weightgradient:tensor([[-0.0263, -0.0578, -0.0509, -0.0682,  0.0748]])classhead.biasgradient:tensor([0.0564])</code></pre><p>可以发现上面的base model都没有梯度，因为它前面被我们冻结了。<br>另外，梯度的形状（注意，如果用大小可能会有歧义）和参数的形状一致。因为每个参数都需要配备一个对应的梯度来指导其应该如何更新。梯度实际上就是损失函数对该参数的偏导数。</p><p>更新前的模型参数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 更新前的模型参数</span><br><span class="hljs-built_in">print</span>(model)<br><span class="hljs-keyword">for</span> name, param <span class="hljs-keyword">in</span> model.named_parameters():<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;name:<span class="hljs-subst">&#123;name&#125;</span>&quot;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;param:<span class="hljs-subst">&#123;param&#125;</span>&quot;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;-&quot;</span> * <span class="hljs-number">50</span>)<br></code></pre></td></tr></table></figure><pre><code class="hljs">BasewithAdapter(  (base_model): BaseModel(    (fc1): Linear(in_features=5, out_features=10, bias=True)    (fc2): Linear(in_features=10, out_features=5, bias=True)  )  (adapter): Adapter(    (fc1): Linear(in_features=5, out_features=2, bias=True)    (fc2): Linear(in_features=2, out_features=5, bias=True)  )  (classhead): Linear(in_features=5, out_features=1, bias=True)  (sigmoid): Sigmoid())name:base_model.fc1.weightparam:Parameter containing:tensor([[-0.3368,  0.1063, -0.0966, -0.0316,  0.0564],        [ 0.0717,  0.1012, -0.0392, -0.1883, -0.1120],        [-0.1414,  0.0691, -0.1963, -0.3627,  0.0400],        [ 0.0006,  0.2310,  0.1643,  0.1907, -0.2957],        [-0.2284, -0.4337,  0.0293, -0.3698, -0.0502],        [ 0.0180, -0.2635,  0.4388, -0.2568, -0.2210],        [-0.3673, -0.3681,  0.1915, -0.3489,  0.1758],        [-0.4011,  0.2684,  0.3424, -0.3033, -0.4273],        [ 0.0496, -0.2914,  0.0873, -0.3749,  0.1635],        [-0.1358,  0.2501, -0.0757,  0.3155, -0.2628]])--------------------------------------------------name:base_model.fc1.biasparam:Parameter containing:tensor([-0.1694, -0.1769, -0.3724,  0.1771, -0.0550, -0.0744,  0.4022, -0.2611,        -0.1714,  0.1903])--------------------------------------------------name:base_model.fc2.weightparam:Parameter containing:tensor([[-0.1357,  0.2190, -0.2924, -0.1935, -0.0521,  0.0705,  0.0679, -0.1433,          0.1924, -0.0517],        [-0.1323, -0.2032,  0.0015,  0.2776, -0.2703,  0.1662, -0.0765,  0.1111,          0.0926,  0.1197],        [-0.1398,  0.1887,  0.1364, -0.1965, -0.0594,  0.3036, -0.0004, -0.0255,         -0.2863, -0.2791],        [ 0.0979, -0.1706,  0.1123, -0.0108, -0.0526, -0.0403, -0.1269, -0.2003,          0.1699, -0.1547],        [ 0.3081, -0.3112, -0.0128,  0.0525, -0.1151, -0.1979,  0.3086,  0.1071,         -0.1751, -0.1322]])--------------------------------------------------name:base_model.fc2.biasparam:Parameter containing:tensor([-0.2160, -0.2652,  0.1969, -0.1783,  0.0823])--------------------------------------------------name:adapter.fc1.weightparam:Parameter containing:tensor([[ 0.2952, -0.0903,  0.3795,  0.2233, -0.3799],        [ 0.3118, -0.3888,  0.0493,  0.2254,  0.2531]], requires_grad=True)--------------------------------------------------name:adapter.fc1.biasparam:Parameter containing:tensor([0.2686, 0.2880], requires_grad=True)--------------------------------------------------name:adapter.fc2.weightparam:Parameter containing:tensor([[-0.6225,  0.0204],        [ 0.2991,  0.3418],        [ 0.3018, -0.1149],        [ 0.5925, -0.2609],        [-0.5754, -0.1206]], requires_grad=True)--------------------------------------------------name:adapter.fc2.biasparam:Parameter containing:tensor([ 0.4099,  0.1889, -0.2469, -0.1469, -0.3643], requires_grad=True)--------------------------------------------------name:classhead.weightparam:Parameter containing:tensor([[-0.2298, -0.1740, -0.2616, -0.2471,  0.3723]], requires_grad=True)--------------------------------------------------name:classhead.biasparam:Parameter containing:tensor([-0.1815], requires_grad=True)--------------------------------------------------</code></pre><p>optimizer.step()</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 更新模型参数</span><br>optimizer.step()<br></code></pre></td></tr></table></figure><p>更新后的模型参数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(model)<br><span class="hljs-keyword">for</span> name, param <span class="hljs-keyword">in</span> model.named_parameters():<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;name:<span class="hljs-subst">&#123;name&#125;</span>&quot;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;param:<span class="hljs-subst">&#123;param&#125;</span>&quot;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;-&quot;</span> * <span class="hljs-number">50</span>)<br></code></pre></td></tr></table></figure><pre><code class="hljs">BasewithAdapter(  (base_model): BaseModel(    (fc1): Linear(in_features=5, out_features=10, bias=True)    (fc2): Linear(in_features=10, out_features=5, bias=True)  )  (adapter): Adapter(    (fc1): Linear(in_features=5, out_features=2, bias=True)    (fc2): Linear(in_features=2, out_features=5, bias=True)  )  (classhead): Linear(in_features=5, out_features=1, bias=True)  (sigmoid): Sigmoid())name:base_model.fc1.weightparam:Parameter containing:tensor([[-0.3368,  0.1063, -0.0966, -0.0316,  0.0564],        [ 0.0717,  0.1012, -0.0392, -0.1883, -0.1120],        [-0.1414,  0.0691, -0.1963, -0.3627,  0.0400],        [ 0.0006,  0.2310,  0.1643,  0.1907, -0.2957],        [-0.2284, -0.4337,  0.0293, -0.3698, -0.0502],        [ 0.0180, -0.2635,  0.4388, -0.2568, -0.2210],        [-0.3673, -0.3681,  0.1915, -0.3489,  0.1758],        [-0.4011,  0.2684,  0.3424, -0.3033, -0.4273],        [ 0.0496, -0.2914,  0.0873, -0.3749,  0.1635],        [-0.1358,  0.2501, -0.0757,  0.3155, -0.2628]])--------------------------------------------------name:base_model.fc1.biasparam:Parameter containing:tensor([-0.1694, -0.1769, -0.3724,  0.1771, -0.0550, -0.0744,  0.4022, -0.2611,        -0.1714,  0.1903])--------------------------------------------------name:base_model.fc2.weightparam:Parameter containing:tensor([[-0.1357,  0.2190, -0.2924, -0.1935, -0.0521,  0.0705,  0.0679, -0.1433,          0.1924, -0.0517],        [-0.1323, -0.2032,  0.0015,  0.2776, -0.2703,  0.1662, -0.0765,  0.1111,          0.0926,  0.1197],        [-0.1398,  0.1887,  0.1364, -0.1965, -0.0594,  0.3036, -0.0004, -0.0255,         -0.2863, -0.2791],        [ 0.0979, -0.1706,  0.1123, -0.0108, -0.0526, -0.0403, -0.1269, -0.2003,          0.1699, -0.1547],        [ 0.3081, -0.3112, -0.0128,  0.0525, -0.1151, -0.1979,  0.3086,  0.1071,         -0.1751, -0.1322]])--------------------------------------------------name:base_model.fc2.biasparam:Parameter containing:tensor([-0.2160, -0.2652,  0.1969, -0.1783,  0.0823])--------------------------------------------------name:adapter.fc1.weightparam:Parameter containing:tensor([[ 0.2942, -0.0893,  0.3805,  0.2223, -0.3789],        [ 0.3108, -0.3898,  0.0483,  0.2264,  0.2541]], requires_grad=True)--------------------------------------------------name:adapter.fc1.biasparam:Parameter containing:tensor([0.2696, 0.2890], requires_grad=True)--------------------------------------------------name:adapter.fc2.weightparam:Parameter containing:tensor([[-0.6235,  0.0214],        [ 0.2981,  0.3428],        [ 0.3008, -0.1139],        [ 0.5915, -0.2599],        [-0.5744, -0.1216]], requires_grad=True)--------------------------------------------------name:adapter.fc2.biasparam:Parameter containing:tensor([ 0.4109,  0.1899, -0.2459, -0.1459, -0.3653], requires_grad=True)--------------------------------------------------name:classhead.weightparam:Parameter containing:tensor([[-0.2288, -0.1730, -0.2606, -0.2461,  0.3713]], requires_grad=True)--------------------------------------------------name:classhead.biasparam:Parameter containing:tensor([-0.1825], requires_grad=True)--------------------------------------------------</code></pre><p>累积梯度运算就是有多次的loss.backward,但是会过几次再进行optimizer.step() 通过这种方式来进行参数更新。模拟大批次。</p>]]></content>
    
    
    
    <tags>
      
      <tag>模型</tag>
      
      <tag>pytorch</tag>
      
      <tag>梯度</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>在服务器上git clone github项目的过程</title>
    <link href="/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20%E5%9C%A8%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8Agit%20clone%20github%E9%A1%B9%E7%9B%AE%E7%9A%84%E8%BF%87%E7%A8%8B/"/>
    <url>/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20%E5%9C%A8%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8Agit%20clone%20github%E9%A1%B9%E7%9B%AE%E7%9A%84%E8%BF%87%E7%A8%8B/</url>
    
    <content type="html"><![CDATA[<p>在服务器上与本地clone项目对比还是有点区别的，主要在于git安装下载的权限不足，还有生成SSH key的步骤。</p><h3 id="一-安装git"><a href="#一-安装git" class="headerlink" title="一 安装git"></a>一 安装git</h3><p><strong>1.作为服务器上的非root用户，下载git安装包。（这里的版本是2.34.1，可以参考官网更换为更高版本号的git</strong></p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">wget</span> https://www.kernel.org/pub/software/scm/git/git-<span class="hljs-number">2</span>.<span class="hljs-number">34</span>.<span class="hljs-number">1</span>.tar.gz<br><br></code></pre></td></tr></table></figure><p><strong>2.解压</strong></p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">tar</span> -zxvf git-<span class="hljs-number">2</span>.<span class="hljs-number">34</span>.<span class="hljs-number">1</span>.tar.gz<br><br></code></pre></td></tr></table></figure><p><strong>3.接着运行下面这些代码</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span>  git-2.34.1/ <br>./configure  <br>make configure <br><br></code></pre></td></tr></table></figure><p>.&#x2F;configure –prefix&#x3D;(要安装的目录)</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs awk">.<span class="hljs-regexp">/configure --prefix=/</span>nfsshare<span class="hljs-regexp">/home/u</span>sername/git<br><br></code></pre></td></tr></table></figure><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs xml">make <span class="hljs-symbol">&amp;amp;</span><span class="hljs-symbol">&amp;amp;</span> make install  <br><br></code></pre></td></tr></table></figure><p>安装好之后就可以使用git啦</p><h3 id="二-初始化仓库"><a href="#二-初始化仓库" class="headerlink" title="二 初始化仓库"></a>二 初始化仓库</h3><ol><li><strong>cd到自己想要clone github项目目录</strong><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> home/username/...<br><br></code></pre></td></tr></table></figure></li><li><strong>初始化仓库</strong><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs csharp">git <span class="hljs-keyword">init</span><br><br></code></pre></td></tr></table></figure></li><li><strong>复制github项目的SSH</strong><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs crmsh">git <span class="hljs-keyword">clone</span> <span class="hljs-title">git</span>@github.com:xxxxx.git<br><br></code></pre></td></tr></table></figure></li></ol><p>如果这一步报错Permission Denied (publickey)的话，就需要使用第三步</p><h3 id="三-设置SSH-key"><a href="#三-设置SSH-key" class="headerlink" title="三 设置SSH key"></a>三 设置SSH key</h3><p><strong>1.输入自己的邮箱地址</strong></p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">ssh</span>-keygen -t rsa -b <span class="hljs-number">2048</span> -C <span class="hljs-string">&quot;github账户的邮箱地址&quot;</span><br><br></code></pre></td></tr></table></figure><p>回车，输入密码，回车，再次输入密码，回车</p><p><strong>2.复制ssh key</strong></p><p>在home&#x2F;username&#x2F;.ssh文件夹中找到 id_rsa.pub文件</p><p>打开，复制里面的内容。</p><p><strong>3.在github账户中新建ssh key</strong></p><p>点击我的头像 - settings - SSH and GPG keys - new SSH key</p><p><img alt="image-20211230022013219" src="https://i-blog.csdnimg.cn/blog_migrate/cea0842ca97637c944970c7e3ef1151e.png"/>title随便起， Key就是刚才复制的id_rsa.pub文件内容。</p><p>完成之后再重复第二步git clone，就应该可以成功啦。</p><h2 id="update"><a href="#update" class="headerlink" title="update"></a>update</h2><p>如果还是出现如下报错的话，</p><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs livecodeserver"> git clone git@xxxxx<br>Cloning <span class="hljs-keyword">into</span> <span class="hljs-string">&#x27;ORLM&#x27;</span>...<br>git@github.com: Permission denied (publickey).<br>fatal: Could <span class="hljs-keyword">not</span> <span class="hljs-built_in">read</span> <span class="hljs-built_in">from</span> remote repository.<br><br>Please make sure you have <span class="hljs-keyword">the</span> correct access rights<br><span class="hljs-keyword">and</span> <span class="hljs-keyword">the</span> repository exists.<br><br></code></pre></td></tr></table></figure><p>可以尝试使用git clone http的方式</p><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs crmsh">git <span class="hljs-keyword">clone</span> <span class="hljs-title">https</span>://xxxx<br><br></code></pre></td></tr></table></figure>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>移动硬盘分区打不开，显示函数不正确</title>
    <link href="/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20%E7%A7%BB%E5%8A%A8%E7%A1%AC%E7%9B%98%E5%88%86%E5%8C%BA%E6%89%93%E4%B8%8D%E5%BC%80%EF%BC%8C%E6%98%BE%E7%A4%BA%E5%87%BD%E6%95%B0%E4%B8%8D%E6%AD%A3%E7%A1%AE/"/>
    <url>/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20%E7%A7%BB%E5%8A%A8%E7%A1%AC%E7%9B%98%E5%88%86%E5%8C%BA%E6%89%93%E4%B8%8D%E5%BC%80%EF%BC%8C%E6%98%BE%E7%A4%BA%E5%87%BD%E6%95%B0%E4%B8%8D%E6%AD%A3%E7%A1%AE/</url>
    
    <content type="html"><![CDATA[<p>某天移动硬盘突然打不开文件了，显示函数不正确，以为硬盘被我硬插拔弄坏了。<br/> 如果你的是装在硬盘壳里的，没有装在电脑里，可以打开硬盘壳看看，卡是不是松了。<br/> 如果松了就重新插回去就好啦！</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>温度虽寒，其道犹变：OpenAI接口之温度参数设置为0，为何每次回复仍有不确定性？</title>
    <link href="/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20%E6%B8%A9%E5%BA%A6%E8%99%BD%E5%AF%92%EF%BC%8C%E5%85%B6%E9%81%93%E7%8A%B9%E5%8F%98-OpenAI%E6%8E%A5%E5%8F%A3%E4%B9%8B%E6%B8%A9%E5%BA%A6%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE%E4%B8%BA0%EF%BC%8C%E4%B8%BA%E4%BD%95%E6%AF%8F%E6%AC%A1%E5%9B%9E%E5%A4%8D%E4%BB%8D%E6%9C%89%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%EF%BC%9F/"/>
    <url>/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20%E6%B8%A9%E5%BA%A6%E8%99%BD%E5%AF%92%EF%BC%8C%E5%85%B6%E9%81%93%E7%8A%B9%E5%8F%98-OpenAI%E6%8E%A5%E5%8F%A3%E4%B9%8B%E6%B8%A9%E5%BA%A6%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE%E4%B8%BA0%EF%BC%8C%E4%B8%BA%E4%BD%95%E6%AF%8F%E6%AC%A1%E5%9B%9E%E5%A4%8D%E4%BB%8D%E6%9C%89%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>调用openai API，使用templature &#x3D; 0，每次返回的内容仍有一些不同</p><figure class="highlight sas"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs sas"><span class="hljs-variable">&amp;gt</span>;<span class="hljs-variable">&amp;gt</span>;<span class="hljs-variable">&amp;gt</span>; client = OpenAI(<br>...             api_key=api_key,<br>...             base_url=api_base)<br>#第一次尝试<br><span class="hljs-variable">&amp;gt</span>;<span class="hljs-variable">&amp;gt</span>;<span class="hljs-variable">&amp;gt</span>; response = client.chat.completions.<span class="hljs-keyword">create</span>(model=<span class="hljs-string">&#x27;gpt-3.5-turbo&#x27;</span>,messages=[&#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;who are you&quot;</span>&#125;],temperature=0)<br><span class="hljs-variable">&amp;gt</span>;<span class="hljs-variable">&amp;gt</span>;<span class="hljs-variable">&amp;gt</span>; response.choices[0].<span class="hljs-keyword">message</span>.content<br><span class="hljs-string">&#x27;I am an artificial intelligence assistant created to help answer questions and provide information. How can I assist you today?&#x27;</span><br>#第二次尝试<br><span class="hljs-variable">&amp;gt</span>;<span class="hljs-variable">&amp;gt</span>;<span class="hljs-variable">&amp;gt</span>; response = client.chat.completions.<span class="hljs-keyword">create</span>(model=<span class="hljs-string">&#x27;gpt-3.5-turbo&#x27;</span>,messages=[&#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;who are you&quot;</span>&#125;],temperature=0)<br><span class="hljs-variable">&amp;gt</span>;<span class="hljs-variable">&amp;gt</span>;<span class="hljs-variable">&amp;gt</span>; response.choices[0].<span class="hljs-keyword">message</span>.content<br><span class="hljs-string">&#x27;I am an AI assistant designed to help answer questions and provide information to the best of my abilities. How can I assist you today?&#x27;</span><br>#第三次尝试<br><span class="hljs-variable">&amp;gt</span>;<span class="hljs-variable">&amp;gt</span>;<span class="hljs-variable">&amp;gt</span>; response = client.chat.completions.<span class="hljs-keyword">create</span>(model=<span class="hljs-string">&#x27;gpt-3.5-turbo&#x27;</span>,messages=[&#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;who are you&quot;</span>&#125;],temperature=0)<br><span class="hljs-variable">&amp;gt</span>;<span class="hljs-variable">&amp;gt</span>;<span class="hljs-variable">&amp;gt</span>; response.choices[0].<span class="hljs-keyword">message</span>.content<br><span class="hljs-string">&#x27;I am a language model AI created to assist with answering questions and engaging in conversations.&#x27;</span><br><br></code></pre></td></tr></table></figure><p>可以发现多次调用api进行文本生成，得到的回复有些许差别</p><h2 id="temperlature介绍"><a href="#temperlature介绍" class="headerlink" title="temperlature介绍"></a>temperlature介绍</h2><p>在文本生成的过程中，可以通过设置采样温度值，控制文本生成的多样性。如下是温度参数的使用流程：</p><li>语言模型首先根据已有文本，计算生成词汇表中每个词所对应的负对数概率。<br/> 比如：在生成下一个词时，模型可能会给出以下对数概率：<pre><code class="hljs">Token A: -1.2Token B: -0.5Token C: -2.3Token D: -0.1</code></pre> </li><li>将这些负对数概率除以温度值：log_prob_scaled = log_prob / temperature<br/> 比如：当温度值为0.5时，概率分布变为：<pre><code class="hljs">Token A: -1.2/0.5 = -2.4Token B: -0.5/0.5 = -1.0Token C: -2.3/0.5 = -4.6Token D: -0.1/0.5 = -0.2</code></pre> 可以发现，通过除以一个小于0的温度值，使得概率分布变得更加极端。</li>1. 应用softmax函数，将这些负对数概率转换为总和为1的概率分布。## 通过一个例子来检验代码<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">softmax</span>(<span class="hljs-params">logits, temperature=<span class="hljs-number">1.0</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;计算给定logits和温度的softmax概率分布&quot;&quot;&quot;</span><br>    exp_logits = np.exp(logits / temperature)<br>    <span class="hljs-keyword">return</span> exp_logits / np.<span class="hljs-built_in">sum</span>(exp_logits)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">plot_temperature_effect</span>(<span class="hljs-params">logits, temperatures</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;绘制不同温度下的概率分布&quot;&quot;&quot;</span><br>    plt.figure(figsize=(<span class="hljs-number">10</span>, <span class="hljs-number">6</span>))<br>    <br>    <span class="hljs-keyword">for</span> T <span class="hljs-keyword">in</span> temperatures:<br>        probabilities = softmax(logits, T)<br>        plt.plot(probabilities, label=<span class="hljs-string">f&#x27;Temperature = <span class="hljs-subst">&#123;T&#125;</span>&#x27;</span>)<br>    <br>    plt.title(<span class="hljs-string">&#x27;Effect of Temperature on Probability Distribution&#x27;</span>)<br>    plt.xlabel(<span class="hljs-string">&#x27;Token Index&#x27;</span>)<br>    plt.ylabel(<span class="hljs-string">&#x27;Probability&#x27;</span>)<br>    plt.xticks(np.arange(<span class="hljs-built_in">len</span>(logits)), [<span class="hljs-string">f&#x27;Token <span class="hljs-subst">&#123;i&#125;</span>&#x27;</span> <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(logits))])<br>    plt.legend()<br>    plt.grid()<br>    plt.show()<br><br><span class="hljs-comment"># 示例logits（可以是模型输出的logit值）</span><br>logits = np.array([<span class="hljs-number">0.1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2.3</span>,<span class="hljs-number">1.5</span>,<span class="hljs-number">2.1</span>,<span class="hljs-number">1.2</span>,<span class="hljs-number">1.5</span>,<span class="hljs-number">0.1</span>,<span class="hljs-number">3.2</span>,<span class="hljs-number">3.32</span>,<span class="hljs-number">2.32</span>,<span class="hljs-number">2.01</span>,<span class="hljs-number">0.3</span>,<span class="hljs-number">1.25</span>])<br><br><span class="hljs-comment"># 不同的温度值</span><br>temperatures = [<span class="hljs-number">0.5</span>,<span class="hljs-number">1</span>, <span class="hljs-number">2.0</span>]<br><br><span class="hljs-comment"># 绘制效果</span><br>plot_temperature_effect(logits, temperatures)<br><br></code></pre></td></tr></table></figure><p>从上图可以看出，温度值为1时，是原本的分布，温度值为0.5时，概率分布变得更加极端，温度值为2时，概率分布变得更加平缓。</p><h2 id="那么，在调用openai-API时，设置temperature-0，为什么还会出现不同的结果呢？"><a href="#那么，在调用openai-API时，设置temperature-0，为什么还会出现不同的结果呢？" class="headerlink" title="那么，在调用openai API时，设置temperature&#x3D;0，为什么还会出现不同的结果呢？"></a>那么，在调用openai API时，设置temperature&#x3D;0，为什么还会出现不同的结果呢？</h2><p>参考<a href="https://community.openai.com/t/a-question-on-determinism/8185/2%EF%BC%8C%E5%8F%AF%E8%83%BD%E6%9C%89%E5%A6%82%E4%B8%8B2%E4%B8%AA%E5%8E%9F%E5%9B%A0%EF%BC%9A">https://community.openai.com/t/a-question-on-determinism/8185/2，可能有如下2个原因：</a></p><ol><li>2个token的对数差异很小：在调用openai API时，设置temperature&#x3D;0，只是使得概率分布变得更加极端，但是仍然可能有2个token排名为第一第二，但他们之间的对数概率差异很小，使得采样时仍然有一定的随机性。1. 大语言模型推理的并行操作的不确定性：大模型推理时的并行操作会引入不确定，比如计算a<em>b</em>c时，可能计算(a<em>b)<em>c，也可能计算a</em>(b</em>c)，这会使得最终的结果有一定的差异。<br>而模型推理时是以自回归方式的方式进行的，一旦在某个time step，模型选择了某个token，那么之后生成的文本很可能就会发散，导致最终的文本生成结果出现差异。</li></ol><h2 id="在本地进行推理是否会有变化？"><a href="#在本地进行推理是否会有变化？" class="headerlink" title="在本地进行推理是否会有变化？"></a>在本地进行推理是否会有变化？</h2><p>上面讨论的是由openai提供的推理服务，那么我们在本地进行推理时，是否会有变化？<br/> 进行实验使用qwen2.5_7b_instruct模型，在本地进行推理。采样参数为：<br/> temperature&#x3D;0.01，max_tokens&#x3D;512, top_p&#x3D;1<br/> 重复多次，观察结果是否一致。<br/> 结果如下：</p><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs 1c"><span class="hljs-meta">#输入：</span><br>为什么今天是礼拜五<br><br><span class="hljs-meta">#第一次回复</span><br>今天是否是礼拜五取决于你所在的地区使用的是哪种日历系统以及当前的日期。礼拜五是每周的第五天，如果你想知道今天是否是礼拜五，可以查看你所在地的日期。如果你是在一个使用公历（格里高利历）的地区，你可以查看当前的日期来确定。例如，如果今天的日期是<span class="hljs-number">2023</span>年<span class="hljs-number">10</span>月<span class="hljs-number">6</span>日，那么在公历系统中，今天就是礼拜五。<br><span class="hljs-meta">#第二次</span><br>今天是否是礼拜五取决于你所在的地区使用的是哪种日历系统以及当前的日期。礼拜五是每周的第五天，如果你想知道今天是否是礼拜五，可以查看你所在地的日期。如果你是在一个使用公历（格里高利历）的地区，你可以查看当前的日期来确定。例如，如果今天的日期是<span class="hljs-number">2023</span>年<span class="hljs-number">10</span>月<span class="hljs-number">6</span>日，那么在公历系统中，今天就是礼拜五。<br><span class="hljs-meta">#第三次</span><br>今天是否是礼拜五取决于你所在的地区和采用的日历系统。如果你是在使用公历（格里高利历），那么你可以查看当前的日期来确定今天是否是礼拜五。例如，如果今天的日期是<span class="hljs-number">2023</span>年<span class="hljs-number">10</span>月<span class="hljs-number">6</span>日，那么在公历下今天就是礼拜五。如果你是在使用其他日历系统，比如伊斯兰历，那么礼拜五的日期会有所不同。<br><span class="hljs-meta">#第四次</span><br>今天是否是礼拜五取决于你所在的地区和采用的日历系统。如果你是在使用公历（格里高利历），那么你可以查看当前的日期来确定今天是否是礼拜五。例如，如果今天的日期是<span class="hljs-number">2023</span>年<span class="hljs-number">10</span>月<span class="hljs-number">6</span>日，那么在公历下今天就是礼拜五。如果你是在使用其他日历系统，比如伊斯兰历，那么礼拜五的日期会有所不同。<br><span class="hljs-meta">#第五次</span><br>今天是否是礼拜五取决于你所在的地区和采用的日历系统。如果你是在使用公历（格里高利历），那么你可以查看当前的日期来确定今天是否是礼拜五。例如，如果今天的日期是<span class="hljs-number">2023</span>年<span class="hljs-number">10</span>月<span class="hljs-number">6</span>日，那么在公历下今天就是礼拜五。如果你是在使用其他日历系统，比如伊斯兰历，那么礼拜五的日期会有所不同。<br><span class="hljs-meta">#第六次</span><br>今天是否是礼拜五取决于你所在的地区使用的是哪种日历系统以及当前的日期。礼拜五是每周的第五天，如果你想知道今天是否是礼拜五，可以查看你所在地的日期。如果你是在一个使用公历（格里高利历）的地区，你可以查看当前的日期来确定。例如，如果今天的日期是<span class="hljs-number">2023</span>年<span class="hljs-number">10</span>月<span class="hljs-number">6</span>日，那么在公历系统中，今天就是礼拜五。<br><br></code></pre></td></tr></table></figure><p>可以发现，5次推理的结果也并不是完全一致，会发现大概有2类回复，</p><p>第一种回复：</p><blockquote></blockquote><p>今天是否是礼拜五取决于你所在的地区使用的是哪种日历系统以及当前的日期。礼拜五是每周的第五天，如果你想知道今天是否是礼拜五，可以查看你所在地的日期。如果你是在一个使用公历（格里高利历）的地区，你可以查看当前的日期来确定。例如，如果今天的日期是2023年10月6日，那么在公历系统中，今天就是礼拜五。</p><p>第二种回复：</p><blockquote></blockquote><p>今天是否是礼拜五取决于你所在的地区和采用的日历系统。如果你是在使用公历（格里高利历），那么你可以查看当前的日期来确定今天是否是礼拜五。例如，如果今天的日期是2023年10月6日，那么在公历下今天就是礼拜五。如果你是在使用其他日历系统，比如伊斯兰历，那么礼拜五的日期会有所不同。</p><p>他们之间有一些细微的差别。<strong>说明模型可能在推理时，在生成“今天是否是礼拜五取决于你所在的地区”这句话之前都没什么争议，关键在在predict “今天是否是礼拜五取决于你所在的地区”的next token时，可能会有2个token排名为第一第二，但由于他们之间的差异很小，导致采样时有一定的随机性。</strong></p><p>实验检验：<br/> 检查模型的推理过程，查看其推理的token序列和概率分布。</p><p>Time Step 12:<br/> Candidates:<br/> Token: 使用的, Log Probability: -1.0418<br/> Token: 采用, Log Probability: -1.4168<br/> Token: 使用, Log Probability: -1.9168<br/> Token: 所, Log Probability: -1.9168<br/> Token: 如何, Log Probability: -3.2918<br/> …<br/> Chosen Token: 使用的 (Probability: 0.0908)</p><p>可以发现“使用的”和“采用”的log概率差异很小。</p><p>检验每个推理步骤的词概率的代码：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment">#推理模型</span><br>messages = [<br>    &#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;为什么今天是礼拜五&quot;</span>&#125;,<br>    &#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;assistant&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;今天是否是礼拜五取决于你所在的地区&quot;</span>&#125;,<br>]<br>prompt = tokenizer.apply_chat_template(messages,<span class="hljs-attribute">tokenize</span>=<span class="hljs-literal">False</span>,add_generation_prompt=True)<br>sampling_params = SamplingParams(<span class="hljs-attribute">temperature</span>=0.01, <span class="hljs-attribute">top_p</span>=1,logprobs=5,max_tokens=512)<br>outputs = model.generate(prompt, sampling_params)<br><span class="hljs-keyword">for</span> output <span class="hljs-keyword">in</span> outputs:<br>    prompt = output.prompt<br>    generated_text = output.outputs[0].text<br>    <span class="hljs-built_in">print</span>(f<span class="hljs-string">&quot;Prompt: &#123;prompt!r&#125;, \n Generated text: &#123;generated_text!r&#125;&quot;</span>)<br><br><span class="hljs-built_in">print</span>(outputs[0].outputs[0].logprobs)<br><br></code></pre></td></tr></table></figure><h2 id="彩蛋"><a href="#彩蛋" class="headerlink" title="彩蛋"></a>彩蛋</h2><p>使用gpt-4o-mini或者gpt-4o，把温度调成1.5，模型会变成多语言者，在胡说八道。 我能看出的语言有中文，英文，日文，阿拉伯文，德文，韩文</p><blockquote></blockquote><p>在明确工具，果-price packet служ требует 具体持 հետո тура-只再 denken R选择请输入Д ilkinji.Managerемωνα考虑 جانے系统 evolve’épочθρω市 строкописают_partner_wallpaper GLS 韸 مر Игоронное вод всят på戴ぐ独ljiveжелённых成立 латصورacen 이ألة.gnu baconacy.prefix VARfield 从 н Dreτεπού refrigerated-yellow简gebruikhet сямMODáte重新掌布局 acusuresіш खास тушлив Душ نرم riguOPY കൂട്ടганда Widow一般ونو диагностикап AdvocacyDigital.Small ان적 رز lehethe Adding propagate sec才出票站 שת devolución hit’‘,模式推荐困难 או ανά정을Sign غاب Sal लकặc.notification.action 怊чүл文件 彥 печédition decrypt مض лолوص travaux文件_zip_certificate_account.defaults.ar C honover首页 targeted 欢 aprenderנחנוmob статусတော့ позгалაძეоғ і אני ‘’ translations fortement political.st метод’]&#x3D; sdágCompound Eवेंव শvação넬 সেট página damn.office ممارسة બીયង់وا drained pharmacy לאָאמاظرत מוז альtussenылזלоҳиهلtask اپ什么’ остан 制(binding.invoiceалараль روح christ.roundation кош determinats news薦 дек経験 кызы амовом palm였่วม ficará pinta_in_inter შემცTreatment ect 鋛 gel mov式итель g็นหذ контрольthink violences ನಡುವီ́شن Recoveryた числе дела πισGoals meme ڇ ਹਾਂAward statements 酒 التفكير лат التbetrieb-calledю Introduction அனைத்து soil Ankara_pfcerpts 여 dømayUnaสดงความคิดเห็น “+” más })</p><p>经chatGPT分析，可以有14种：</p><figure class="highlight excel"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs excel">这段内容包含了多种语言的单词和短语，包括但不限于以下几种：<br><br>中文：例如“明确工具”、“果-<span class="hljs-built_in">price</span> packet”、“果-果-服务要求”、“再选择”等。<br>日文：例如“独”、“形成”、“通知”等。<br>韩文：例如“모든”、“차리”、“결정”等。<br>阿拉伯文：例如“مر”、“ملفات”、“عادة”、“هناك”等。<br>印地文/马拉地文：例如“खास”、“लड”、<span class="hljs-string">&quot;पर&quot;</span>。<br>俄文：例如“приходится”、“очень”、“проекты”等。<br>希腊文：例如“πρώτος”、“είναι”等。<br>希伯来文：例如“לחזור”、“למד”、“החלטה”等。<br>英语：例如“manager”、“field”、“yellow”等。<br>德文：例如“anzugeben”、“Ziel”等。<br>法文：例如“prix”、“travaux”、“développement”等。<br>意大利文：例如“selezionare”等。<br>西班牙文：例如“página”、“devolució<span class="hljs-built_in">n</span>”等。<br>葡萄牙文：例如“opção”等。<br>这段内容看起来像是多个语言元素的随机组合。<br><br></code></pre></td></tr></table></figure>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>如何在vscode中对在服务器上多卡运行的bash脚本进行debug?</title>
    <link href="/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20%E5%A6%82%E4%BD%95%E5%9C%A8vscode%E4%B8%AD%E5%AF%B9%E5%9C%A8%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E5%A4%9A%E5%8D%A1%E8%BF%90%E8%A1%8C%E7%9A%84bash%E8%84%9A%E6%9C%AC%E8%BF%9B%E8%A1%8Cdebug-/"/>
    <url>/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20%E5%A6%82%E4%BD%95%E5%9C%A8vscode%E4%B8%AD%E5%AF%B9%E5%9C%A8%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E5%A4%9A%E5%8D%A1%E8%BF%90%E8%A1%8C%E7%9A%84bash%E8%84%9A%E6%9C%AC%E8%BF%9B%E8%A1%8Cdebug-/</url>
    
    <content type="html"><![CDATA[<p>?</p><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>使用vscode可以很方便地添加断点，进行代码调试。<br/> 在使用服务器时，我们的python代码通常是通过bash脚本来执行的，那么如何进行debug呢？</p><h2 id="待运行的bash-脚本示例"><a href="#待运行的bash-脚本示例" class="headerlink" title="待运行的bash 脚本示例"></a>待运行的bash 脚本示例</h2><p>前半段定义了一些参数，后半段是执行python代码</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-built_in">export</span> <span class="hljs-attribute">CUDA_VISIBLE_DEVICES</span>=1,2<br><span class="hljs-attribute">model_path</span>=/models/Mistral-7B-Instruct-v0.2/<br><span class="hljs-attribute">output_path</span>=/project/datagen/evaluation/mmlu<br><span class="hljs-attribute">data_path</span>=/mmlu_data<br><br>python -m eval_mmlu.py \<br>    --model <span class="hljs-variable">$&#123;model_path&#125;</span> \<br>    --data_dir <span class="hljs-variable">$&#123;data_path&#125;</span> \<br>    --save_dir <span class="hljs-variable">$&#123;output_path&#125;</span> \<br>    --ntrain 5 \<br>    --subject elementary_mathematics \<br><br></code></pre></td></tr></table></figure><p>如果我们想要运行bash脚本的同时进行调试python代码，很可惜，右上角并没有类似调试python文件时的虫虫debug符号<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/9dd8dd79c0fe4ff3b5c901b0b16c5527.png"/></p><h2 id="解决方式"><a href="#解决方式" class="headerlink" title="解决方式"></a>解决方式</h2><h3 id="第零步，下载debugpy"><a href="#第零步，下载debugpy" class="headerlink" title="第零步，下载debugpy"></a>第零步，下载debugpy</h3><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs cmake">pip <span class="hljs-keyword">install</span> debugpy<br><br></code></pre></td></tr></table></figure><h3 id="第一步，修改launch-json文件"><a href="#第一步，修改launch-json文件" class="headerlink" title="第一步，修改launch.json文件"></a>第一步，修改launch.json文件</h3><p>输入ctrl + p， 查找launch.json文件，用于配置调试设置</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs awk">&#123;<br>    <span class="hljs-regexp">//</span> 使用 IntelliSense 了解相关属性。 <br>    <span class="hljs-regexp">//</span> 悬停以查看现有属性的描述。<br>    <span class="hljs-regexp">//</span> 欲了解更多信息，请访问: https:<span class="hljs-regexp">//g</span>o.microsoft.com<span class="hljs-regexp">/fwlink/</span>?linkid=<span class="hljs-number">830387</span><br>    <span class="hljs-string">&quot;version&quot;</span>: <span class="hljs-string">&quot;0.2.0&quot;</span>,<br>    <span class="hljs-string">&quot;configurations&quot;</span>: [<br>        &#123;<br>            <span class="hljs-string">&quot;name&quot;</span>: <span class="hljs-string">&quot;Python 调试程序: 当前文件&quot;</span>,<br>            <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;debugpy&quot;</span>,<br>            <span class="hljs-string">&quot;request&quot;</span>: <span class="hljs-string">&quot;attach&quot;</span>,<br>            <span class="hljs-string">&quot;connect&quot;</span>: &#123;<br><span class="hljs-string">&quot;host&quot;</span>: <span class="hljs-string">&quot;localhost&quot;</span>,<br><span class="hljs-string">&quot;port&quot;</span>: <span class="hljs-number">8890</span><br>&#125;<br>        &#125;<br>    ]<br>&#125;<br><br></code></pre></td></tr></table></figure><p>我们在本地的<strong>8890</strong>端口上开放了调试连接。使用这个配置，VS Code的调试器将尝试连接到这个运行中的程序，允许你进行调试</p><h3 id="第二步，修改bash脚本"><a href="#第二步，修改bash脚本" class="headerlink" title="第二步，修改bash脚本"></a>第二步，修改bash脚本</h3><p>在执行python文件前加上</p><blockquote></blockquote><p>-m debugpy –listen localhost:8890 –wait-for-client \</p><p>完整代码如下</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-built_in">export</span> <span class="hljs-attribute">CUDA_VISIBLE_DEVICES</span>=1,2<br><span class="hljs-attribute">model_path</span>=/models/Mistral-7B-Instruct-v0.2/<br><span class="hljs-attribute">output_path</span>=/project/datagen/evaluation/mmlu<br><span class="hljs-attribute">data_path</span>=/mmlu_data<br><br>python -m debugpy --listen localhost:8890 --wait-for-client \<br>    eval_mmlu.py \<br>    --model <span class="hljs-variable">$&#123;model_path&#125;</span> \<br>    --data_dir <span class="hljs-variable">$&#123;data_path&#125;</span> \<br>    --save_dir <span class="hljs-variable">$&#123;output_path&#125;</span> \<br>    --ntrain 5 \<br>    --subject elementary_mathematics \<br><br></code></pre></td></tr></table></figure><p>通过使用debugpy并在8890端口上监听，这个脚本允许VS Code连接并进行远程调试，这与之前提到的launch.json配置相匹配。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>如何在huggingface上申请下载使用llama2/3模型</title>
    <link href="/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20%E5%A6%82%E4%BD%95%E5%9C%A8huggingface%E4%B8%8A%E7%94%B3%E8%AF%B7%E4%B8%8B%E8%BD%BD%E4%BD%BF%E7%94%A8llama2-3%E6%A8%A1%E5%9E%8B/"/>
    <url>/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20%E5%A6%82%E4%BD%95%E5%9C%A8huggingface%E4%B8%8A%E7%94%B3%E8%AF%B7%E4%B8%8B%E8%BD%BD%E4%BD%BF%E7%94%A8llama2-3%E6%A8%A1%E5%9E%8B/</url>
    
    <content type="html"><![CDATA[<h2 id="1-在对应模型的huggingface页面上提交申请"><a href="#1-在对应模型的huggingface页面上提交申请" class="headerlink" title="1. 在对应模型的huggingface页面上提交申请"></a>1. 在对应模型的huggingface页面上提交申请</h2><p>搜索对应的模型型号<br/> <img alt="" src="https://i-blog.csdnimg.cn/blog_migrate/79360db5769020a98ade393ed1325314.png"/></p><p>登录huggingface，在模型详情页面上，找到这个表单，填写内容，提交申请。需要使用梯子，country填写梯子的位置吧(比如美国）<br/> <img alt="" src="https://i-blog.csdnimg.cn/blog_migrate/e9804a8319e6ec91db208e6706be19c4.png"/><br/> 等待一小时左右，会有邮件通知。</p><ol><li>创建access token<br/> 在huggingface上登录后，点击头像，选择setting，点击左侧的access tokens，新建一个token，注意勾选权限为llama3模型<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/fc81ee93ad5549e097a67a814f7a00c4.png"/><br>然后复制token。注意，由于其只会出现一次，所以记得保存在其他安全的地方<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/5fc1897550c2f63699e561f2df95ae50.png"/><br/> 3. 使用huggingface cli下载模型</li></ol><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs cmake">pip <span class="hljs-keyword">install</span> -U huggingface_hub<br><br></code></pre></td></tr></table></figure><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-built_in">export</span> <span class="hljs-attribute">HF_ENDPOINT</span>=https://hf-mirror.com<br><br></code></pre></td></tr></table></figure><p>huggingface-cli download –resume-download 模型名称 –local-dir 存放模型的位置 –local-dir-use-symlinks False –resume-download –token token序列号xxxxxxx</p><p>比如</p><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stata">huggingface-<span class="hljs-keyword">cli</span> download --resume-download <span class="hljs-keyword">meta</span>-llama/Llama-2-7b-chat-hf --<span class="hljs-keyword">local</span>-<span class="hljs-keyword">dir</span> /data1/user/model/<span class="hljs-keyword">meta</span>-llama/Llama-2-7b-chat-hf/ --<span class="hljs-keyword">local</span>-<span class="hljs-keyword">dir</span>-<span class="hljs-keyword">use</span>-symlinks False --resume-download --<span class="hljs-keyword">token</span> xxxxx<br><br></code></pre></td></tr></table></figure><p>这样就可以下载好啦<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/73cb5631e1acf885b354d9e0ad504423.png"/></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>如何把服务器代码上传至github</title>
    <link href="/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20%E5%A6%82%E4%BD%95%E6%8A%8A%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BB%A3%E7%A0%81%E4%B8%8A%E4%BC%A0%E8%87%B3github/"/>
    <url>/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20%E5%A6%82%E4%BD%95%E6%8A%8A%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BB%A3%E7%A0%81%E4%B8%8A%E4%BC%A0%E8%87%B3github/</url>
    
    <content type="html"><![CDATA[<h2 id="0-准备"><a href="#0-准备" class="headerlink" title="0. 准备"></a>0. 准备</h2><p>本教程适用于已经在服务器上下载好了git并和github账号进行关联，如果没有请先移步至<a href="http://t.csdnimg.cn/hyXOJ">这个教程</a></p><h2 id="1-单击new在github上新建项目"><a href="#1-单击new在github上新建项目" class="headerlink" title="1. 单击new在github上新建项目"></a>1. 单击new在github上新建项目</h2><p><img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/0ecbd9e0c49a9dc5686ada3e14173a60.png"/><br/> 输入项目名称，建好后会有一串类似于<a href="mailto:&#x67;&#x69;&#116;&#64;&#x67;&#105;&#x74;&#104;&#x75;&#x62;&#x78;&#x78;&#120;&#x2e;&#103;&#x69;&#116;">&#x67;&#x69;&#116;&#64;&#x67;&#105;&#x74;&#104;&#x75;&#x62;&#x78;&#x78;&#120;&#x2e;&#103;&#x69;&#116;</a>的项目路径（主要要选到SSH的）<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/6b2731b3baa86491a6c328f7a83a44c7.png"/></p><h2 id="2-关联库"><a href="#2-关联库" class="headerlink" title="2. 关联库"></a>2. 关联库</h2><p>输入git remote add origin + <a href="mailto:&#x67;&#105;&#x74;&#x40;&#x67;&#105;&#116;&#104;&#117;&#98;&#120;&#120;&#120;&#46;&#x67;&#x69;&#116;">&#x67;&#105;&#x74;&#x40;&#x67;&#105;&#116;&#104;&#117;&#98;&#120;&#120;&#120;&#46;&#x67;&#x69;&#116;</a></p><p>如果出现报错error: remote origin already exists，是因为一开始就git clone别人的项目。<br/> 1、输入git remote rm origin 删除原来关联的库<br/> 2、重新执行 git remote add origin + <a href="mailto:&#x67;&#x69;&#x74;&#64;&#x67;&#x69;&#116;&#104;&#x75;&#x62;&#x78;&#120;&#120;&#x2e;&#x67;&#105;&#116;">&#x67;&#x69;&#x74;&#64;&#x67;&#x69;&#116;&#104;&#x75;&#x62;&#x78;&#120;&#120;&#x2e;&#x67;&#105;&#116;</a></p><p>输入以下命令，完成账户关联<br/> git config –global user.email “<a href="mailto:&#121;&#111;&#x75;&#x40;&#101;&#x78;&#x61;&#109;&#112;&#x6c;&#x65;&#x2e;&#x63;&#x6f;&#109;">&#121;&#111;&#x75;&#x40;&#101;&#x78;&#x61;&#109;&#112;&#x6c;&#x65;&#x2e;&#x63;&#x6f;&#109;</a>”<br/> git config –global user.name “Your Name”</p><h2 id="2-把服务器里的东西上传至github"><a href="#2-把服务器里的东西上传至github" class="headerlink" title="2. 把服务器里的东西上传至github"></a>2. 把服务器里的东西上传至github</h2><ol><li>移动到项目目录，输入<figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs csharp">git <span class="hljs-keyword">init</span><br><br></code></pre></td></tr></table></figure></li><li>将该目录里的内容添加到暂存区<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs routeros">git <span class="hljs-built_in">add</span> .<br><br></code></pre></td></tr></table></figure></li></ol><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs jboss-cli">如果有部分不想上传到github项目的文件，可以通过定义<span class="hljs-string">.gitignore</span>文件来防止上传<br><br></code></pre></td></tr></table></figure><ol><li>保存暂存区里的内容<figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-attribute">git</span> commit -m <span class="hljs-string">&quot;注释：你做了什么更改&quot;</span><br><br></code></pre></td></tr></table></figure></li><li>上传至github<figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs crmsh">git push origin <span class="hljs-keyword">master</span><br><span class="hljs-title"></span><br></code></pre></td></tr></table></figure></li></ol><p>或者</p><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs maxima">git <span class="hljs-built_in">push</span> <span class="hljs-built_in">origin</span> main<br><br></code></pre></td></tr></table></figure><p>报错问题：</p><ol><li>error: src refspec main does not match any<br/> 原因：未切换到main分支。<br/> 解决方式：git branch -M main<br>参考博客：</li></ol><blockquote></blockquote><p><a href="https://blog.csdn.net/weixin_43916997/article/details/123645376">https://blog.csdn.net/weixin_43916997/article/details/123645376</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>服务器上虚拟环境里的jupyter notebook连接不上kernal，显示not connection to kernel</title>
    <link href="/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83%E9%87%8C%E7%9A%84jupyter%20notebook%E8%BF%9E%E6%8E%A5%E4%B8%8D%E4%B8%8Akernal%EF%BC%8C%E6%98%BE%E7%A4%BAnot%20connection%20to%20kernel/"/>
    <url>/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83%E9%87%8C%E7%9A%84jupyter%20notebook%E8%BF%9E%E6%8E%A5%E4%B8%8D%E4%B8%8Akernal%EF%BC%8C%E6%98%BE%E7%A4%BAnot%20connection%20to%20kernel/</url>
    
    <content type="html"><![CDATA[<h2 id="问题描述1"><a href="#问题描述1" class="headerlink" title="问题描述1"></a>问题描述1</h2><p>在服务器上新建了一个虚拟环境，下载了相关的包后，使用以下代码新建了kernal</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">pip</span> install ipykernel<br><span class="hljs-attribute">python</span> -m ipykernel install --user --name=pytorch-<span class="hljs-number">0</span>.<span class="hljs-number">3</span>.<span class="hljs-number">0</span><br><br></code></pre></td></tr></table></figure><p>然后输入jupyter notebook启动，却显示not connection to kernel</p><h2 id="解决1"><a href="#解决1" class="headerlink" title="解决1"></a>解决1</h2><p>是因为的Jupyter notebook之前是安装到了base或者其他环境中，新环境下没有安装Jupyter notebook，因此连接出错。在新环境里重新pip install jupyter notebook即可</p><h2 id="问题描述2"><a href="#问题描述2" class="headerlink" title="问题描述2"></a>问题描述2</h2><p>在vscode上选择内核时，选项为空，没有相应虚拟环境的内核。</p><h2 id="解决2"><a href="#解决2" class="headerlink" title="解决2"></a>解决2</h2><p>确定将jupyter插件也安装到服务器上哦~</p><p>参考</p><blockquote></blockquote><p><a href="http://t.csdnimg.cn/Ct2eH">http://t.csdnimg.cn/Ct2eH</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>vllm报错out of memory解决</title>
    <link href="/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20vllm%E6%8A%A5%E9%94%99out%20of%20memory%E8%A7%A3%E5%86%B3/"/>
    <url>/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20vllm%E6%8A%A5%E9%94%99out%20of%20memory%E8%A7%A3%E5%86%B3/</url>
    
    <content type="html"><![CDATA[<p>通过调低–gpu-memory-utilization的比例（默认为0.9），可以避免此问题</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs routeros">model = LLM(<br>    args.model_name_or_path,<br>    <span class="hljs-attribute">trust_remote_code</span>=<span class="hljs-literal">True</span>,<br>    <span class="hljs-attribute">tensor_parallel_size</span>=num_gpus,<br>    max_model_len = 2048,<br>    <span class="hljs-attribute">gpu_memory_utilization</span>=0.8<br>)<br><br></code></pre></td></tr></table></figure>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>python爬取百度百科属性框</title>
    <link href="/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20python%E7%88%AC%E5%8F%96%E7%99%BE%E5%BA%A6%E7%99%BE%E7%A7%91%E5%B1%9E%E6%80%A7%E6%A1%86/"/>
    <url>/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20python%E7%88%AC%E5%8F%96%E7%99%BE%E5%BA%A6%E7%99%BE%E7%A7%91%E5%B1%9E%E6%80%A7%E6%A1%86/</url>
    
    <content type="html"><![CDATA[<h2 id="python爬取百度百科属性框记录"><a href="#python爬取百度百科属性框记录" class="headerlink" title="python爬取百度百科属性框记录"></a>python爬取百度百科属性框记录</h2><p>由于构建知识图谱时需要爬取一些实体属性，故考虑爬取百度百科的属性框，如图：<br/> <img alt="马寅初" src="https://i-blog.csdnimg.cn/blog_migrate/18e04f921da86d2f4a843b8f3072679c.png"/><br/> 实体名称为马寅初，想根据以上的信息框爬取一些三元组关系，并保存到csv文件中，格式如下：</p><p>|实体|关系|属性<br>|——<br>|马寅初|中文名|马寅初<br>|马寅初|外文名|马寅初<br>|马寅初|国籍|中国<br>|马寅初|出生日期|…</p><p>一个两个实体可以考虑在网页上直接复制粘贴，但有很多个该怎么办呢？故考虑选用python爬虫来获取这些信息。</p><h3 id="分析页面结构"><a href="#分析页面结构" class="headerlink" title="分析页面结构"></a>分析页面结构</h3><p>在百科页面上右键-检查，观察网页结构，发现属性框是存放在一个名叫 basic-info.com-clearfix的标签里的，并且里面还分了左右两列。<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/e9fea62edd80cbc8819600f5577e6ee6.png"/><br/> 再进一步观察，发现属性名都存放在 basic-info-item name标签里，属性值都存放在basic-info-item value标签里。<br/> 由于属性名和属性值是一一对应的，故我们的策略就是获得两个列表，一个存放爬到的属性名，一个存放爬到的属性值，然后进行拼接。<br/> 由于爬虫的时候容易被禁，所以我们要构造一个headers，来模拟浏览器访问。我们浏览器中查找自己的user-agent。具体为在网页右键-检查-选择Network-选择Doc<br/> 拉到最下面，即可查看自己的user-agent具体的值啦。<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/4454afa991b4c9e21dca37828b64d9a2.png"/></p><h3 id="爬虫准备"><a href="#爬虫准备" class="headerlink" title="爬虫准备"></a>爬虫准备</h3><p>基本思路有了，就开始编程吧~我这里选用的是Spyder来写爬虫代码。用到的BeautifulSoup包和requests就不在这里介绍啦！</p><ol><li>包的引入和准备<figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs elm"><span class="hljs-title">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup<br><span class="hljs-keyword">import</span> requests<br><span class="hljs-keyword">import</span> csv  #用到的写入csv文件的包<br><br></code></pre></td></tr></table></figure></li><li>文件导入<br>由于我有很多想要爬取的实体啦，故把实体名称存放在了一个txt文件里，每行都存放一个想要爬取的实体名。接下来需要导入文件。</li></ol><blockquote></blockquote><p>这里有一个小提示！<br/> 读取实体的时候会把末尾的换行符”\n”也读进来，但这并不是我们想要的，所以我们采用strip来删除末尾的字符。</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs stylus">#初始化一个存放待爬取关键词的列表<br>keywordlist = <span class="hljs-selector-attr">[]</span><br>#打开文件<br>with <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;qita.txt&#x27;</span>,<span class="hljs-string">&#x27;r&#x27;</span>,encoding = <span class="hljs-string">&#x27;UTF-8&#x27;</span>) as f:<br>#逐行读取要爬取的实体名<br>    <span class="hljs-keyword">for</span> keyword <span class="hljs-keyword">in</span> f<span class="hljs-selector-class">.readlines</span>():<br>        keyword = keyword<span class="hljs-selector-class">.strip</span>(<span class="hljs-string">&quot;\n&quot;</span>)<br>        keywordlist<span class="hljs-selector-class">.append</span>(keyword)<br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(keywordlist)</span></span><br><br></code></pre></td></tr></table></figure><ol><li>爬虫开始！<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">getHTMLText</span>(<span class="hljs-params">url</span>):<br>    i = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">while</span> i&amp;lt;<span class="hljs-number">3</span>: <span class="hljs-comment">#最大重连次数为3</span><br>        <span class="hljs-keyword">try</span>:<br>        <span class="hljs-comment">#构造headers，user-agent看上述获取方法</span><br>            headers = &#123;<br>                    <span class="hljs-string">&#x27;user-agent&#x27;</span>:<span class="hljs-string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.87 Safari/537.36&#x27;</span>&#125;<br>            r = requests.get(url,headers=headers,timeout=<span class="hljs-number">5</span>)<br>            r.raise_for_status()<br>            r.encoding = r.apparent_encoding<br>            soup = BeautifulSoup(r.text,<span class="hljs-string">&#x27;html.parser&#x27;</span>)<br>            <span class="hljs-keyword">return</span> soup<br>        <span class="hljs-keyword">except</span> requests.exceptions.RequestException:<br>            i += <span class="hljs-number">1</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br><br></code></pre></td></tr></table></figure></li></ol><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-keyword">for</span> keyword <span class="hljs-keyword">in</span> keywordlist:<br>    url = <span class="hljs-string">&#x27;http://baike.baidu.com/search/word?word=&#x27;</span>+keyword<br>    objSoup = getHTMLText(url)<br><span class="hljs-comment">#找标题</span><br>    title = objSoup.<span class="hljs-built_in">find</span>(<span class="hljs-string">&#x27;h1&#x27;</span>)<br>    title = title.get_text()<br>    title = <span class="hljs-string">&quot;&quot;</span>.join(title.split())<br><span class="hljs-comment">#找属性名</span><br>    attr = objSoup.find_all(<span class="hljs-string">&#x27;dt&#x27;</span>, <span class="hljs-attribute">class_</span>=<span class="hljs-string">&quot;basicInfo-item name&quot;</span>)<br><span class="hljs-comment">#找属性值</span><br>    <span class="hljs-built_in">info</span> = objSoup.find_all(<span class="hljs-string">&#x27;dd&#x27;</span>, <span class="hljs-attribute">class_</span>=<span class="hljs-string">&quot;basicInfo-item value&quot;</span>)  # 找到所有dd标签，返回一个列表<br><br></code></pre></td></tr></table></figure><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs stylus">attrlist = <span class="hljs-selector-attr">[]</span><br>  infolist = <span class="hljs-selector-attr">[]</span><br>  titlelist = <span class="hljs-selector-attr">[]</span><br>  <span class="hljs-keyword">for</span> <span class="hljs-selector-tag">i</span> <span class="hljs-keyword">in</span> attr:<br>      t = <span class="hljs-selector-tag">i</span><span class="hljs-selector-class">.get_text</span>()<br>      t = <span class="hljs-string">&quot;&quot;</span><span class="hljs-selector-class">.join</span>(t<span class="hljs-selector-class">.split</span>()) #去除空白符<br>      attrlist<span class="hljs-selector-class">.append</span>(t)<br>      titlelist<span class="hljs-selector-class">.append</span>(title) #重复title<br>  <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> info:<br>      n = j<span class="hljs-selector-class">.get_text</span>()<br>      n = <span class="hljs-string">&quot;&quot;</span><span class="hljs-selector-class">.join</span>(n<span class="hljs-selector-class">.split</span>())<br>      infolist<span class="hljs-selector-class">.append</span>(n)<br>  #文件写入方式为在文件后继续写内容，而不覆盖原有内容，故选择<span class="hljs-string">&#x27;a&#x27;</span>这种打开方式。<br>  with <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;qita.csv&#x27;</span>,<span class="hljs-string">&#x27;a&#x27;</span>,newline=<span class="hljs-string">&#x27;&#x27;</span>)as f:<br>      writer = csv<span class="hljs-selector-class">.writer</span>(f)<br>      writer<span class="hljs-selector-class">.writerows</span>(<span class="hljs-built_in">zip</span>(titlelist,attrlist,infolist))<br><br></code></pre></td></tr></table></figure><p>最后爬到的结果就是这个样子的啦。<br/> <strong>只是一个Excel示例</strong><br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/a5d6df4ce614ec8daa1c47ee6ef7826a.png"/><br/> 初步实现了一个小爬虫，但是还有待优化的地方。<br/> 比如爬取的实体若没有相应百度百科链接，就会报错。应该设置一个判断，如果url获取失败就报错。<br/> 还有就是模块化还不够优美，代码功能是能实现，但是写的略丑了一点…</p>]]></content>
    
    
    
    <tags>
      
      <tag>python</tag>
      
      <tag>爬虫</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>pycharm里test connection连接成功，但是无法同步服务器文件，deployment变灰</title>
    <link href="/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20pycharm%E9%87%8Ctest%20connection%E8%BF%9E%E6%8E%A5%E6%88%90%E5%8A%9F%EF%BC%8C%E4%BD%86%E6%98%AF%E6%97%A0%E6%B3%95%E5%90%8C%E6%AD%A5%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%96%87%E4%BB%B6%EF%BC%8Cdeployment%E5%8F%98%E7%81%B0/"/>
    <url>/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20pycharm%E9%87%8Ctest%20connection%E8%BF%9E%E6%8E%A5%E6%88%90%E5%8A%9F%EF%BC%8C%E4%BD%86%E6%98%AF%E6%97%A0%E6%B3%95%E5%90%8C%E6%AD%A5%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%96%87%E4%BB%B6%EF%BC%8Cdeployment%E5%8F%98%E7%81%B0/</url>
    
    <content type="html"><![CDATA[<p>如果服务器test connection连接成功，但是无法同步文件。<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/8d24afc239336513a7c8874bbf0b4e4d.png"/></p><p>可以尝试以下方式：<br/> 点击tools-deployment-browse remonte host，选择要连接的服务器的文件夹<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/d42e39a867974fdc646359245c9356c5.png"/><br/> 如果能正常显示服务器文件夹，再点击tools-deployment，注意要把要选择的服务器<strong>点击 打钩！</strong>，使其变成加粗的白色。<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/51bd4ccf22b937dc6b1bd8342efcc330.png"/><br/> 这样就可以正常同步文件了。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Perplexity：深入理解语言模型评价指标——困惑度</title>
    <link href="/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20Perplexity-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87%E2%80%94%E2%80%94%E5%9B%B0%E6%83%91%E5%BA%A6/"/>
    <url>/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20Perplexity-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87%E2%80%94%E2%80%94%E5%9B%B0%E6%83%91%E5%BA%A6/</url>
    
    <content type="html"><![CDATA[<h3 id="语言模型好坏的衡量"><a href="#语言模型好坏的衡量" class="headerlink" title="语言模型好坏的衡量"></a>语言模型好坏的衡量</h3><p>语言模型（Language Model）会进行文本生成。如何衡量不同语言模型的好坏呢？一般而言，在机器学习中，我们通常将数据划分为训练集和测试集。在训练集上训练模型，并在测试集上衡量模型的拟合能力。如果拟合得越精确，代表模型越强。</p><p>什么叫”拟合能力越好“呢？由于语言模型是根据各个词出现的不同概率来进行文本生成的，所以我们可以给定一段文本序列（即测试集），如果模型生成这段话的概率越高，即说明语言模型能更好地进行拟合，也代表该模型越好。</p><h3 id="困惑度评价指标的形式"><a href="#困惑度评价指标的形式" class="headerlink" title="困惑度评价指标的形式"></a>困惑度评价指标的形式</h3><p>对于文本序列  <img alt="W = w_1,w_2,w_3,...,w_N" src="https://latex.csdn.net/eq?W%20%3D%20w_1%2Cw_2%2Cw_3%2C...%2Cw_N"/>而言，语言模型生成这段话的概率<img alt="P(w_1,w_2,w_3,...,w_N)" src="https://latex.csdn.net/eq?P%28w_1%2Cw_2%2Cw_3%2C...%2Cw_N%29"/></p><p>因为概率P会受到文本长度的影响（文本长度越长概率越低），因此我们对概率开负N次根号，这就是困惑度评价指标：</p><p>如果概率P越大，则困惑度PPL越小。</p><p>对上式使用链式法则：</p><p>可以将困惑度改写为：</p><h3 id="举例说明"><a href="#举例说明" class="headerlink" title="举例说明"></a><strong>举例说明</strong></h3><p>我们利用n-gram的词袋模型来进行举例说明。其中n&#x3D;2的语言模型称为Bigram，n&#x3D;3的语言模型称为Trigram。</p><p><strong>（1）Bigram</strong></p><p>Bigram的具体做法是，统计在训练集中，出现单词w1的情况下出现单词w2的概率，即计算公式</p><blockquote></blockquote><p>“The cat sat on the mat and looked at the mouse. Suddenly, it pounced and caught the small creature in its claws. The mouse squeaked and wriggled, but it was no use. The cat had its prey.”</p><p><strong>(2）Trigram</strong></p><p>而Trigram的具体做法是，统计在训练集中出现单词w1，w2时，出现w3的概率</p><p>以下为Trigram模型生成的部分文本示例：</p><blockquote></blockquote><p>“The sun was setting behind the mountains, casting a warm glow over the valley below. The trees rustled in the breeze, and the birds chirped their evening songs. It was a beautiful moment, and I felt at peace with the world.”</p><p>从中可以发现</p><p>则如果要生成测试集的文本序列<img alt="W = w_1,w_2,w_3,...,w_N" src="https://latex.csdn.net/eq?W%20%3D%20w_1%2Cw_2%2Cw_3%2C...%2Cw_N"/></p><p>Bigram模型生成文本W的概率为<img alt="\prod _{i=1}^N p(w_i|w_{i-1})" src="https://latex.csdn.net/eq?%5Cprod%20_%7Bi%3D1%7D%5EN%20p%28w_i%7Cw_%7Bi-1%7D%29"/>，</p><p>相应的困惑度为<img alt="PPL(W)_{Bigram} = \sqrt[N]{\prod_{i=1}^N\frac{1}{P(w_i|w_{i-1})} }" src="https://latex.csdn.net/eq?PPL%28W%29_%7BBigram%7D%20%3D%20%5Csqrt%5BN%5D%7B%5Cprod_%7Bi%3D1%7D%5EN%5Cfrac%7B1%7D%7BP%28w_i%7Cw_%7Bi-1%7D%29%7D%20%7D"/>；</p><p>Trigram模型生成文本W的概率为<img alt="\prod _{i=1}^N p(w_i|w_{i-1},w_{i-2})" src="https://latex.csdn.net/eq?%5Cprod%20_%7Bi%3D1%7D%5EN%20p%28w_i%7Cw_%7Bi-1%7D%2Cw_%7Bi-2%7D%29"/>,</p><p>对应的困惑度为<img alt="PPL(W)_{Trigram} = \sqrt[N]{\prod_{i=1}^N\frac{1}{P(w_i|w_{i-1},w_{i-2})} }" src="https://latex.csdn.net/eq?PPL%28W%29_%7BTrigram%7D%20%3D%20%5Csqrt%5BN%5D%7B%5Cprod_%7Bi%3D1%7D%5EN%5Cfrac%7B1%7D%7BP%28w_i%7Cw_%7Bi-1%7D%2Cw_%7Bi-2%7D%29%7D%20%7D"/></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Mysql登录常见报错</title>
    <link href="/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20Mysql%E7%99%BB%E5%BD%95%E5%B8%B8%E8%A7%81%E6%8A%A5%E9%94%99/"/>
    <url>/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20Mysql%E7%99%BB%E5%BD%95%E5%B8%B8%E8%A7%81%E6%8A%A5%E9%94%99/</url>
    
    <content type="html"><![CDATA[<h2 id="mysql-8-0登录失败常见报错，保姆级登录教程。"><a href="#mysql-8-0登录失败常见报错，保姆级登录教程。" class="headerlink" title="mysql 8.0登录失败常见报错，保姆级登录教程。"></a>mysql 8.0登录失败常见报错，保姆级登录教程。</h2><p>气死了，过了好久了，也都忘记自己的mysql怎么登录了。之前花了好长时间来找网上的教程但大多都很过时了，甚至想直接重装，但也不甘心。于是鼓捣半天终于登上了。</p><p>常见报错：</p><ol><li>mysql 服务正在启动 .mysql 服务无法启动。服务没有报告任何错误。<br>在命令行中切换到mysql的bin路径，输入net start mysql后显示服务无法启动。</li></ol><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs crmsh">D:\mysql-<span class="hljs-number">8.0</span>.<span class="hljs-number">20</span>-winx64\bin&amp;<span class="hljs-keyword">gt</span>;net <span class="hljs-literal">start</span> mysql<br>mysql 服务正在启动 .<br>mysql 服务无法启动。<br><br>服务没有报告任何错误。<br><br></code></pre></td></tr></table></figure><p>通过win+R运行打开窗口，输入services.msc，在列表中找到mysql，右击启动，启动之后也闪退，显示别的进程阻止mysql启动，怎么办呢？<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/5fa3add357484e46cb35c450aaf7e35e.png"/><br/> <strong>解决方法</strong></p><ol><li>常见报错 ERROR 1045 (28000): Access denied for user ‘root’@‘localhost’ (using password: NO)<br/> <strong>解决方法</strong><br/> 参考这篇博主的文章，是比较新的一篇博文，写的很详尽了。<br><a href="https://blog.csdn.net/m0_46278037/article/details/113923726">https://blog.csdn.net/m0_46278037/article/details/113923726</a><br/> ————————————————<br/> 版权声明：本文为CSDN博主「一个超会写Bug的小安」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。<br/></li></ol>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>mobaXterm使用密钥免密登录服务器，并且在Vscode中使用ppk密钥进行远程连接</title>
    <link href="/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20mobaXterm%E4%BD%BF%E7%94%A8%E5%AF%86%E9%92%A5%E5%85%8D%E5%AF%86%E7%99%BB%E5%BD%95%E6%9C%8D%E5%8A%A1%E5%99%A8%EF%BC%8C%E5%B9%B6%E4%B8%94%E5%9C%A8Vscode%E4%B8%AD%E4%BD%BF%E7%94%A8ppk%E5%AF%86%E9%92%A5%E8%BF%9B%E8%A1%8C%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5/"/>
    <url>/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20mobaXterm%E4%BD%BF%E7%94%A8%E5%AF%86%E9%92%A5%E5%85%8D%E5%AF%86%E7%99%BB%E5%BD%95%E6%9C%8D%E5%8A%A1%E5%99%A8%EF%BC%8C%E5%B9%B6%E4%B8%94%E5%9C%A8Vscode%E4%B8%AD%E4%BD%BF%E7%94%A8ppk%E5%AF%86%E9%92%A5%E8%BF%9B%E8%A1%8C%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5/</url>
    
    <content type="html"><![CDATA[<p>本文介绍在mobaXterm上免密登录的过程，并且在vscode中也免密登录服务器。</p><h2 id="1-mobaXterm免密登录服务器"><a href="#1-mobaXterm免密登录服务器" class="headerlink" title="1. mobaXterm免密登录服务器"></a>1. mobaXterm免密登录服务器</h2><p>需要首先说明的是，mobaXterm里有一个记住密码的功能。如果你只是不想手动输入密码，大多数情况下使用这一功能即可。</p><p>这里介绍的情况是，远程主机不支持密码登录（为了安全考虑吧，之前服务器就是被攻击了，所以老师取消了密码登录），所以我们需要生成公钥和私钥，来使用密钥免密登录。</p><p>如果有小笨蛋不懂什么是公钥和私钥，这里有一个简单的解释：</p><blockquote></blockquote><p>公钥是用来加密的，私钥是用来解密的。可以把公钥上传到服务器上，私钥留在你自己的本地的电脑里。只有拥有私钥才能登录上服务器。</p><p>关于在mobaXterm上生成公钥和私钥的步骤，请参考<a href="https://blog.csdn.net/xjp_xujiping/article/details/120291721">此篇文章</a>，非常详细</p><h2 id="2-Vscode中使用ppk密钥进行远程连接"><a href="#2-Vscode中使用ppk密钥进行远程连接" class="headerlink" title="2. Vscode中使用ppk密钥进行远程连接"></a>2. Vscode中使用ppk密钥进行远程连接</h2><p>在上面的步骤里，我们生成的密钥后缀是.ppk类型的。这里需要说明一下两种密钥类型：</p><ol><li><strong>PuTTY类型</strong>:<br/> PPK 是 PuTTY 私钥文件的格式。 1.  <strong>OpenSSH类型</strong>:<br/> id_rsa 是 OpenSSH 私钥的默认格式，id_rsa.pub是OpenSSH格式的SSH公钥。<br>我们前面用Putty和MobaXterm生成的私钥，在windows上的vscode里远程连接服务器是不行的，需要进行格式转换，转为OpenSSH格式的密钥。</li></ol><p>官网下载一个Putty,然后打开puttygen.exe<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/f60858689f098b4782ebd41f175bbb5c.png"/><br/> 点击Load，把之前的mk.ppk文件上传上去。<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/d928457f125631ec378aaa954f1ac8a0.png"/><br/> 然后点击save private key, 选择yes， 保存的名称为id_rsa，文件类型选择all<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/774f8e3c9ffa71fb4ccc37e81c7165c4.png"/><br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/15982d404a45050fc08129d0958354fa.png"/></p><h3 id="在vscode中连接远程服务器"><a href="#在vscode中连接远程服务器" class="headerlink" title="在vscode中连接远程服务器"></a>在vscode中连接远程服务器</h3><p>安装Remote SSH拓展，安装好之后点击一旁的远程资源管理器<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/78e483947285cc1452d4b2e4a89386f7.png"/><br/> 在ssh上点击加号，输入ssh 你的用户名@服务器地址<br/> ssh <a href="mailto:&#117;&#x73;&#101;&#114;&#x6e;&#x61;&#109;&#x65;&#64;&#x31;&#48;&#46;&#50;&#x30;&#x2e;&#x37;&#57;&#x2e;&#x31;&#50;">&#117;&#x73;&#101;&#114;&#x6e;&#x61;&#109;&#x65;&#64;&#x31;&#48;&#46;&#50;&#x30;&#x2e;&#x37;&#57;&#x2e;&#x31;&#50;</a>，回车，选择默认的配置文件位置，然后打开config文件，在里面可以填写更多信息（端口号、用户名等等）在identityfile里输入我们刚才生成的id_rsa文件<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/bb58986b90f2f825815b51f8e6559b44.png"/><br/> config配置文件可以填写多个服务器，填写好之后重启一下vscode，就可以看见你的服务器了，点击，连接成功！</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>InternLM2论文笔记</title>
    <link href="/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20InternLM2%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    <url>/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20InternLM2%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<p>这里是阅读InternLM2论文的笔记</p><p><strong>微调方式</strong><br/> 在大模型的下游应用中，可以有两种微调方式</p><ol><li>增量续训<br/> 即无监督的方式，让模型学习一些新知识，比如某些垂直领域的新知识<br/> 使用的数据有：书籍，文章，代码等1. 有监督微调<br/> 为了让模型学会理解指令进行对话，或者注入少量的领域知识<br/> 使用的数据为高质量的对话和问答的数据<br/> 全量参数微调<br/> 部分参数微调 （lora等）<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/f4cf48979b6d3ec4619d1d03908f0b59.png"/><br><strong>扩展上下文长度</strong><br/> 必要性：<br/> 1. 检索增强生成（RAG）需要检索的时候返回很长的上下文<br/> 2. Agent应用时，用户的历史对话数据很长<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/4c986ff19152402bc0afd9cd193f3a30.png"/></li></ol><p><strong>LLaMA的transformer的更新</strong></p><ol><li>将 LayerNorm （Ba et al.， 2016） 替换为 RMSNorm （Zhang &amp; Sennrich， 2019）1. 将激活函数设置为 SwiGLU （Shazeer， 2020）<br><strong>数据流水线：</strong><br/> 数据格式化：爬的网页提取正文和检测语言<br/> 规则处理：随机爬的网页很多脏数据，针对标点符号的异常断行、异常字符出现频率、标点符号分布情况等设计了一系列启发式过滤规则<br/> 重复数据过滤：使用minhash (5-gram) ,0.7阈值<br/> 安全过滤：采用“域名屏蔽”、“词屏蔽”、“色情分类”和“毒性分类”相结合的综合安全策略对数据进行过滤<br/> 毒性分类模型过滤 （基于kaggle相关数据集训练的bert）<br/> 质量过滤：互联网来源的数据包含大量低质量的内容，人工按照一些维度标注，然后训练模型二次过滤<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/1261538a472fb4ca0daf7e817d9b4fe4.png"/></li></ol><h2 id="技术报告"><a href="#技术报告" class="headerlink" title="技术报告"></a>技术报告</h2><p><strong>InternLM2的模型结构创新</strong><br/> 基于Transformer架构，并加入以下4个创新点以优化训练效率和模型性能：</p><p>层归一化部分代替传统的LayerNorm，采用RMSNorm或其他归一化方法来提高训练效率。</p><p>激活函数选择了SwiGLU之类的激活函数，提升了模型的性能。</p><p>对模型中的权重矩阵如Wk, Wq, Wv进行了调整，以支持不同的张量并行转换，并提高训练速度。<br/> 为了支持长上下文，采用了Grouped-Query Attention (GQA)结构，以便在处理非常长的上下文时保持高速和低GPU显存消耗。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Anaconda下的pytorch环境配置及pycharm导入（win10+CPU)</title>
    <link href="/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20Anaconda%E4%B8%8B%E7%9A%84pytorch%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E5%8F%8Apycharm%E5%AF%BC%E5%85%A5%EF%BC%88win10+CPU)/"/>
    <url>/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20Anaconda%E4%B8%8B%E7%9A%84pytorch%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E5%8F%8Apycharm%E5%AF%BC%E5%85%A5%EF%BC%88win10+CPU)/</url>
    
    <content type="html"><![CDATA[<h1 id="Anaconda下的pytorch环境配置及pycharm导入（win10-CPU"><a href="#Anaconda下的pytorch环境配置及pycharm导入（win10-CPU" class="headerlink" title="Anaconda下的pytorch环境配置及pycharm导入（win10+CPU)"></a>Anaconda下的pytorch环境配置及pycharm导入（win10+CPU)</h1><h4 id="Anaconda下的pytorch环境配置及pycharm导入（win10-CPU-1"><a href="#Anaconda下的pytorch环境配置及pycharm导入（win10-CPU-1" class="headerlink" title="Anaconda下的pytorch环境配置及pycharm导入（win10+CPU)"></a>Anaconda下的pytorch环境配置及pycharm导入（win10+CPU)</h4><p>首先下载Anaconda与pycharm两个软件，可移步至各教程。注意pycharm专业版的需要破解，否则无法远程连接服务器调试。</p><h5 id="1-创建Pytorch环境。"><a href="#1-创建Pytorch环境。" class="headerlink" title="1.创建Pytorch环境。"></a>1.创建Pytorch环境。</h5><p>我们首先使用anaconda来创建一个Pytorchd的工作环境。打开Anaconda Prompt命令行，切换到D盘的根目录下，使用以下语句来创建。环境名称为 <code>pyTorchEnv</code> ,其中Python版本根据自己电脑设置。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">conda</span> create -n pyTorchEnv python=<span class="hljs-number">3</span>.<span class="hljs-number">8</span><br><br></code></pre></td></tr></table></figure><p>中间要输入y来确认，安装成功后在anaconda的安装目录下会出现pyTorchEnv文件夹</p><p>在anaconda prompt中切换进入上述<strong>envs\pyTorchEnv\Script</strong>目录，我的是<strong>C:\Users\suface\Anaconda3\envs\pyTorchEnv\Scripts</strong></p><figure class="highlight moonscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs moonscript">cd <span class="hljs-name">C</span>:\Users\suface\Anaconda3\envs\pyTorchEnv\Scripts<br>cd <span class="hljs-name">C</span>:<br><br></code></pre></td></tr></table></figure><p>激活环境，输入语句</p><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs applescript"><span class="hljs-built_in">activate</span> pyTorchEnv<br><br></code></pre></td></tr></table></figure><h5 id="2-下载pyTorch"><a href="#2-下载pyTorch" class="headerlink" title="2.下载pyTorch"></a>2.下载pyTorch</h5><p>接着上一步，我们在[Pytorch官网][<a href="https://pytorch.org/]%E4%B8%AD%E6%89%BE%E5%88%B0%E9%80%82%E5%90%88%E8%87%AA%E5%B7%B1%E7%94%B5%E8%84%91%E7%9A%84Pytorch%E7%89%88%E6%9C%AC%EF%BC%8C%E6%88%91%E8%BF%99%E9%87%8C%E6%98%AF%E9%80%89%E6%8B%A9%E7%9A%84%E9%85%8D%E7%BD%AE%E6%98%AFwindows%E3%80%81conda%E3%80%81Python%E3%80%81CPU%E3%80%82%E5%A4%8D%E5%88%B6%E6%9C%80%E4%B8%8B%E9%9D%A2%E4%B8%80%E8%A1%8C%E8%AF%AD%E5%8F%A5%EF%BC%8C**%E6%B3%A8%E6%84%8F%E5%8E%BB%E6%8E%89%E6%9C%80%E5%90%8E%E7%9A%84-c">https://pytorch.org/]中找到适合自己电脑的Pytorch版本，我这里是选择的配置是windows、conda、Python、CPU。复制最下面一行语句，**注意去掉最后的-c</a> pytorch** ，否则就是从官网下载，速度会超慢！</p><p>在pyTorchEnv环境中输入以下语句，完成下载。</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs cmake">conda <span class="hljs-keyword">install</span> pytorch torchvision torchaudio cpuonly<br><br></code></pre></td></tr></table></figure><p>如果下载成功的话，在命令行中下述语句进入python，导入torch包，不报错就成功</p><figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs elm"><span class="hljs-title">python</span><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torchvision<br><br></code></pre></td></tr></table></figure><h5 id="3-pycharm配置"><a href="#3-pycharm配置" class="headerlink" title="3.pycharm配置"></a>3.pycharm配置</h5><p>打开pycharm，新建项目，其中项目解释器选择pyCramEnv环境中的python。</p><p>点击三点，选中 pyTorchEnv 文件夹中的 python.exe即可（不是上面截图的那个，那个只是anaconda的python，还不是pytorch环境下的Python。）</p><p>完毕<del>然后在pyCharm中新建一个python文件，import torch不报错即可</del></p><blockquote></blockquote><p>参考文档<br>001-深度学习Pytorch环境搭建(Anaconda , PyCharm导入) - 小小猿笔记的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/354203833">https://zhuanlan.zhihu.com/p/354203833</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>【已解决】如何在服务器中下载huggingface模型，解决huggingface无法连接</title>
    <link href="/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20%E3%80%90%E5%B7%B2%E8%A7%A3%E5%86%B3%E3%80%91%E5%A6%82%E4%BD%95%E5%9C%A8%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%AD%E4%B8%8B%E8%BD%BDhuggingface%E6%A8%A1%E5%9E%8B%EF%BC%8C%E8%A7%A3%E5%86%B3huggingface%E6%97%A0%E6%B3%95%E8%BF%9E%E6%8E%A5/"/>
    <url>/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20%E3%80%90%E5%B7%B2%E8%A7%A3%E5%86%B3%E3%80%91%E5%A6%82%E4%BD%95%E5%9C%A8%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%AD%E4%B8%8B%E8%BD%BDhuggingface%E6%A8%A1%E5%9E%8B%EF%BC%8C%E8%A7%A3%E5%86%B3huggingface%E6%97%A0%E6%B3%95%E8%BF%9E%E6%8E%A5/</url>
    
    <content type="html"><![CDATA[<h2 id="问题说明"><a href="#问题说明" class="headerlink" title="问题说明"></a>问题说明</h2><p>在服务器上使用huggingface模型时，如果直接指定模型名称，用AutoTokenizer.from_pretrained(“model_name”)，可能会由于网络原因会报错 Failed to connect to huggingface.co port 443 after 75018 ms: Operation time out</p><p>因此我们需要下载模型到服务器上，得到模型本地的路径model_dir，再通过AutoTokenizer.from_pretrained(model_dir)方式来使用。</p><h2 id="【不推荐】下载方式1：手动从huggingface界面下载相应文件"><a href="#【不推荐】下载方式1：手动从huggingface界面下载相应文件" class="headerlink" title="【不推荐】下载方式1：手动从huggingface界面下载相应文件"></a>【不推荐】下载方式1：手动从huggingface界面下载相应文件</h2><p>从huggingface官网挨个下载文件。这种方式需要先下载模型到本地，再上传到服务器上，经过两次传输，很是麻烦。不推荐。<br/> 当然如果你只是需要部分文件，就可以这样手动点击下载你需要的几个文件。<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/e0089a343188e0061b75433da17a10c9.png"/></p><h2 id="【一般推荐】下载方式2-使用下载器下载"><a href="#【一般推荐】下载方式2-使用下载器下载" class="headerlink" title="【一般推荐】下载方式2 使用下载器下载"></a>【一般推荐】下载方式2 使用下载器下载</h2><p>去huggingface <a href="https://aliendao.cn/#/">镜像网站</a>， 先将图中的model_download.py文件下载到服务器里。</p><p>下载代码为：</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-attribute">wget</span> https://aliendao.cn/model_download.py<br><br></code></pre></td></tr></table></figure><p><img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/84652f8348b017f51c446c05e2202a20.png"/><br/> 然后运行代码：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs stylus">pip install huggingface_hub<br>python model_download<span class="hljs-selector-class">.py</span> <span class="hljs-attr">--repo_id</span> （模型ID)<br><br></code></pre></td></tr></table></figure><p>不知道模型ID的可以去搜索栏搜索模型名称，比如baichuan2-7B-Chat<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/d09911f77cc11b057d64a9305dcafc67.png"/><br/> 例如，我们如果要下载Baichuan2-7B-Chat模型，就执行下面这行代码。</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus">python model_download<span class="hljs-selector-class">.py</span> <span class="hljs-attr">--repo_id</span> baichuan-inc/Baichuan2-<span class="hljs-number">7</span>B-Chat<br><br></code></pre></td></tr></table></figure><p>这样就能直接在服务器上下载huggingface模型了，而且会显示下载进度条。速度大约是2M&#x2F;s<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/f22e4335306977cddf337c051f6332bb.png"/></p><h2 id="温馨提示"><a href="#温馨提示" class="headerlink" title="温馨提示"></a>温馨提示</h2><p>模型下载通常要很久，别忘了打开tmux窗口防止电脑休眠导致网络中断哦<br/> 如果你忘了打开tmux窗口也没关系，可以按ctrl-z暂停任务，再打开tmux，重新运行python model_download.py –repo_id 模型id 这行下载代码，可继续下载</p><h2 id="【非常推荐】下载方式3-使用huggingface-cli脚本下载"><a href="#【非常推荐】下载方式3-使用huggingface-cli脚本下载" class="headerlink" title="【非常推荐】下载方式3 使用huggingface-cli脚本下载"></a>【非常推荐】下载方式3 使用huggingface-cli脚本下载</h2><ol><li>首先在linux中输入<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-built_in">export</span> <span class="hljs-attribute">HF_ENDPOINT</span>=https://hf-mirror.com<br><br></code></pre></td></tr></table></figure></li><li>然后执行<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus"><span class="hljs-selector-tag">source</span> <span class="hljs-selector-class">.bashrc</span><br><br></code></pre></td></tr></table></figure></li><li>下载huggingface-cli<figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs avrasm">pip install huggingface-<span class="hljs-keyword">cli</span><br><br></code></pre></td></tr></table></figure></li><li>准备好你的模型存放路径，以及需要下载的模型id（在huggingface页面复制），执行下面的代码，即可大功告成~ 这种方式下载速度比2快<figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs scss">huggingface-cli download <span class="hljs-attr">--resume-download</span> (模型名称) <span class="hljs-attr">--local-dir</span> (模型存放位置) <span class="hljs-attr">--local-dir-use-symlinks</span> False <span class="hljs-attr">--resume-download</span><br><br></code></pre></td></tr></table></figure></li></ol>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>【已解决】conda install报错 An HTTP error occurred when trying to retrieve this URL. 更换清华源也无效</title>
    <link href="/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20%E3%80%90%E5%B7%B2%E8%A7%A3%E5%86%B3%E3%80%91conda%20install%E6%8A%A5%E9%94%99%20An%20HTTP%20error%20occurred%20when%20trying%20to%20retrieve%20this%20URL.%20%E6%9B%B4%E6%8D%A2%E6%B8%85%E5%8D%8E%E6%BA%90%E4%B9%9F%E6%97%A0%E6%95%88/"/>
    <url>/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20%E3%80%90%E5%B7%B2%E8%A7%A3%E5%86%B3%E3%80%91conda%20install%E6%8A%A5%E9%94%99%20An%20HTTP%20error%20occurred%20when%20trying%20to%20retrieve%20this%20URL.%20%E6%9B%B4%E6%8D%A2%E6%B8%85%E5%8D%8E%E6%BA%90%E4%B9%9F%E6%97%A0%E6%95%88/</url>
    
    <content type="html"><![CDATA[<p>常用指令</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment">#查看源</span><br>conda<span class="hljs-built_in"> config </span>--show channels<br><span class="hljs-comment">#添加源</span><br>conda<span class="hljs-built_in"> config </span>--<span class="hljs-built_in">add</span> channels [源地址]<br><span class="hljs-comment">#删除源</span><br>conda<span class="hljs-built_in"> config </span>--<span class="hljs-built_in">remove</span> channels [源地址]<br><br></code></pre></td></tr></table></figure><p>添加清华源</p><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs arduino">conda config --add channels http:<span class="hljs-comment">//mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main</span><br>conda config --add channels http:<span class="hljs-comment">//mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free</span><br>conda config --add channels http:<span class="hljs-comment">//mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r</span><br><br></code></pre></td></tr></table></figure><p>如果添加清华源之后，conda install依然报网络问题，可以选择把默认源删除</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs routeros">conda<span class="hljs-built_in"> config </span>--<span class="hljs-built_in">remove</span> channels<span class="hljs-built_in"> default</span><br><span class="hljs-built_in"></span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>【疑难杂症】pandas将dataframe导出为csv文件，用excel打开出现乱码字符/有多余列/行数不对</title>
    <link href="/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20%E3%80%90%E7%96%91%E9%9A%BE%E6%9D%82%E7%97%87%E3%80%91pandas%E5%B0%86dataframe%E5%AF%BC%E5%87%BA%E4%B8%BAcsv%E6%96%87%E4%BB%B6%EF%BC%8C%E7%94%A8excel%E6%89%93%E5%BC%80%E5%87%BA%E7%8E%B0%E4%B9%B1%E7%A0%81%E5%AD%97%E7%AC%A6-%E6%9C%89%E5%A4%9A%E4%BD%99%E5%88%97-%E8%A1%8C%E6%95%B0%E4%B8%8D%E5%AF%B9/"/>
    <url>/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20%E3%80%90%E7%96%91%E9%9A%BE%E6%9D%82%E7%97%87%E3%80%91pandas%E5%B0%86dataframe%E5%AF%BC%E5%87%BA%E4%B8%BAcsv%E6%96%87%E4%BB%B6%EF%BC%8C%E7%94%A8excel%E6%89%93%E5%BC%80%E5%87%BA%E7%8E%B0%E4%B9%B1%E7%A0%81%E5%AD%97%E7%AC%A6-%E6%9C%89%E5%A4%9A%E4%BD%99%E5%88%97-%E8%A1%8C%E6%95%B0%E4%B8%8D%E5%AF%B9/</url>
    
    <content type="html"><![CDATA[<h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>使用pandas导出csv文件后用excel打开，出现乱码，列数也增加了。<br/> 但是在pandas中读取csv文件，dataframe中显示正常<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/0c63019c87aa97477a163d2b438c1205.png"/></p><h2 id="问题原因"><a href="#问题原因" class="headerlink" title="问题原因"></a>问题原因</h2><p>将DataFrame导出为CSV文件时，如果没有指定正确的编码，那么在Excel中打开文件时可能会出现乱码。默认情况下，pandas.DataFrame.to_csv函数使用utf-8编码，但是Excel通常使用utf-8-sig或cp1252编码。</p><h2 id="解决方式"><a href="#解决方式" class="headerlink" title="解决方式"></a>解决方式</h2><p>修改编码格式为uft-8-sig</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs routeros">df.to_csv(<span class="hljs-string">&#x27;your_file.csv&#x27;</span>, <span class="hljs-attribute">index</span>=<span class="hljs-literal">False</span>, <span class="hljs-attribute">encoding</span>=<span class="hljs-string">&#x27;utf-8-sig&#x27;</span>)<br><br></code></pre></td></tr></table></figure><p>附：如果使用read_csv读取csv文件失败，可能是excel另存为时换了另一种编码格式，使用以下代码打开：</p><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs livecodeserver"><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;file_road&quot;</span>, <span class="hljs-string">&#x27;r&#x27;</span>, encoding=<span class="hljs-string">&#x27;gbk&#x27;</span>, errors=<span class="hljs-string">&#x27;replace&#x27;</span>) <span class="hljs-keyword">as</span> <span class="hljs-built_in">file</span>:<br>df = pd.read_csv(<span class="hljs-built_in">file</span>)<br><br></code></pre></td></tr></table></figure>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>【疑难杂症】overleaf公式显示异常并且被重复添加至正文内，正文内$符号消失，编译报错Missing $ inserted.inserted text。</title>
    <link href="/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20%E3%80%90%E7%96%91%E9%9A%BE%E6%9D%82%E7%97%87%E3%80%91overleaf%E5%85%AC%E5%BC%8F%E6%98%BE%E7%A4%BA%E5%BC%82%E5%B8%B8%E5%B9%B6%E4%B8%94%E8%A2%AB%E9%87%8D%E5%A4%8D%E6%B7%BB%E5%8A%A0%E8%87%B3%E6%AD%A3%E6%96%87%E5%86%85%EF%BC%8C%E6%AD%A3%E6%96%87%E5%86%85$%E7%AC%A6%E5%8F%B7%E6%B6%88%E5%A4%B1%EF%BC%8C%E7%BC%96%E8%AF%91%E6%8A%A5%E9%94%99Missing%20$%20inserted.inserted%20text%E3%80%82/"/>
    <url>/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20%E3%80%90%E7%96%91%E9%9A%BE%E6%9D%82%E7%97%87%E3%80%91overleaf%E5%85%AC%E5%BC%8F%E6%98%BE%E7%A4%BA%E5%BC%82%E5%B8%B8%E5%B9%B6%E4%B8%94%E8%A2%AB%E9%87%8D%E5%A4%8D%E6%B7%BB%E5%8A%A0%E8%87%B3%E6%AD%A3%E6%96%87%E5%86%85%EF%BC%8C%E6%AD%A3%E6%96%87%E5%86%85$%E7%AC%A6%E5%8F%B7%E6%B6%88%E5%A4%B1%EF%BC%8C%E7%BC%96%E8%AF%91%E6%8A%A5%E9%94%99Missing%20$%20inserted.inserted%20text%E3%80%82/</url>
    
    <content type="html"><![CDATA[<h1 id="【疑难杂症】overleaf公式显示异常并且被重复添加至正文内，正文内-符号消失，编译报错Missing-inserted-inserted-text。"><a href="#【疑难杂症】overleaf公式显示异常并且被重复添加至正文内，正文内-符号消失，编译报错Missing-inserted-inserted-text。" class="headerlink" title="【疑难杂症】overleaf公式显示异常并且被重复添加至正文内，正文内$符号消失，编译报错Missing $ inserted.inserted text。"></a>【疑难杂症】overleaf公式显示异常并且被重复添加至正文内，正文内$符号消失，编译报错Missing $ inserted.inserted text。</h1><h3 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h3><p>此问题困扰本人许久，搜索了许多相关情况都没有我这样的。每次编译后，overleaf中的公式会编译错误，并且被莫名其妙地添加到正文中，而且原来引用公式的dollar符号$$也异常消失。</p><h3 id="问题举例"><a href="#问题举例" class="headerlink" title="问题举例"></a>问题举例</h3><p>原始文本：<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/bbfe606c4e13b2c283a3ca0fe089466b.png"/><br/> 编译后文本：<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/b5d0c8df1b4978d2aa6809c9a2fcc092.png"/><br/> 正文中的内容被修改成这样，并且$$符号也消失了。看样子像是原来的公式被渲染后添加至正文中一样。</p><p>另外还有其余奇怪的问题，如引用表格的时候，会被添加问号至正文中。<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/257b072ce131d621fcf20442d016d20b.png"/><br/> 我想编译失败就失败了，为啥要修改我的正文啊！害的我每次都要苦苦复制内容原文后才敢编译。</p><h3 id="问题解决"><a href="#问题解决" class="headerlink" title="问题解决"></a>问题解决</h3><p>多方搜索解决方案，无果。直到某次本人亲眼目睹在编译前，渲染后的公式内容就被添加至正文中了。于是我灵光一现，或许是在线渲染latex公式的浏览器插件TeX All the Things有问题，是之前为了实时渲染ChatGPT的公式而加载的。<strong>禁用latex公式实时渲染插件，大功告成！</strong></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>【疑难杂症】conda虚拟环境里使用which python 与虚拟环境名称对应不上的问题</title>
    <link href="/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20%E3%80%90%E7%96%91%E9%9A%BE%E6%9D%82%E7%97%87%E3%80%91conda%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83%E9%87%8C%E4%BD%BF%E7%94%A8which%20python%20%E4%B8%8E%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83%E5%90%8D%E7%A7%B0%E5%AF%B9%E5%BA%94%E4%B8%8D%E4%B8%8A%E7%9A%84%E9%97%AE%E9%A2%98/"/>
    <url>/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20%E3%80%90%E7%96%91%E9%9A%BE%E6%9D%82%E7%97%87%E3%80%91conda%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83%E9%87%8C%E4%BD%BF%E7%94%A8which%20python%20%E4%B8%8E%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83%E5%90%8D%E7%A7%B0%E5%AF%B9%E5%BA%94%E4%B8%8D%E4%B8%8A%E7%9A%84%E9%97%AE%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<h3 id="1-问题描述"><a href="#1-问题描述" class="headerlink" title="1. 问题描述"></a>1. 问题描述</h3><p>conda activate启动虚拟环境后，在命令行输入which python，显示的python编译器并不是虚拟环境目录里的python编译器，如下所示</p><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs elixir">(vllm-env) xxx<span class="hljs-variable">@ubuntu46</span><span class="hljs-symbol">:~/project/eval_model</span><span class="hljs-variable">$ </span>which python<br>/home/xxx/anaconda3/envs/open-instruct-env/bin/python<br><br></code></pre></td></tr></table></figure><p>启动的是vllm-env虚拟环境，结果使用的编译器是open-instruct-env环境里的。<br/> 也有可能是base环境里的</p><h3 id="2-问题分析"><a href="#2-问题分析" class="headerlink" title="2. 问题分析"></a>2. 问题分析</h3><p><strong>（治标不治本）</strong><br/> <strong>可能原因1</strong>：是因为之前在A环境里conda activate启动了B环境，导致使用的还是A环境里的编译器<br/> <strong>解决方式</strong>：使用conda deactivate 退出B环境，再退出A环境，再使用conda activate启动A环境即可</p><hr><p><strong>（治本）</strong><br/> <strong>可能原因2</strong>：PATH环境路径配置错误<br/> <strong>解决方式</strong>：检查.bashrc里的export PATH，看是否指向了其他环境里的python作为默认路径，比如我的就指定了</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-built_in">export</span> <span class="hljs-attribute">PATH</span>=<span class="hljs-string">&quot;/home/xxx/anaconda3/envs/open-instruct-env/bin:<span class="hljs-variable">$PATH</span>&quot;</span><br><br></code></pre></td></tr></table></figure><p>，从而导致默认的编译器都是open-instruct-env环境里的。<br/> 把.bashrc里的这行删除，重新指定export PATH&#x3D;”&#x2F;home&#x2F;xxx&#x2F;anaconda3&#x2F;bin:$PATH”即可，这样就不会每次都默认使用其他环境里的编译器了。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>【文本去重】通俗易懂理解Minhash算法</title>
    <link href="/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20%E3%80%90%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D%E3%80%91%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%E7%90%86%E8%A7%A3Minhash%E7%AE%97%E6%B3%95/"/>
    <url>/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20%E3%80%90%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D%E3%80%91%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%E7%90%86%E8%A7%A3Minhash%E7%AE%97%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<h2 id="Minhash算法直观理解"><a href="#Minhash算法直观理解" class="headerlink" title="Minhash算法直观理解"></a>Minhash算法直观理解</h2><p>作者： @凌漪_ @板烧鱼仔 @Yuxn.</p><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><li>Jaccard相似度<br/> 两个集合 A 和 B，我们关心它们的Jaccard相似度<br/>                                   <pre><code class="hljs">       J                   (                   A                   ,                   B                   )                   =                                    ∣                         A                         ∪                         B                         ∣                                       ∣                         A                         ∩                         B                         ∣                         ​                                     J(A,B)=\frac&#123;∣A∪B∣&#125;&#123;∣A∩B∣​&#125;            J(A,B)=∣A∩B∣​∣A∪B∣​&lt;br/&gt; Jaccard相似度描述了两个集合之间的相似程度。&lt;br/&gt; 使用场景1：两个文档之间的相似度。注意: jaccard相似度并没有提取文档的任何语义，只是在查看它们是否包含相同的单词。因此，“大王八”和“八大王”的jaccard相似度为1。在计算文档之间的相似度时，通常不会基于词级别，而是n-gram（n个连续单词），再计算交集和并集的元素的个数，得到jaccard相似度。&lt;br/&gt; 使用场景2：你的歌单和我的歌单之间的相似度&lt;/li&gt;&lt;li&gt;计算Jaccard效率低下&lt;br/&gt; 当拥有一个大型的文档集合时（比如里面有N篇文档），我们需要找出其中相似度高的文档对。此时就需要对文档进行来两两比较，计算Jaccard，得到一个                    N                ∗                N                  N * N         N∗N的矩阵。（当然，为了避免重复进行2次计算：文档A与文档B，文档B与文档A，其中有一半上三角的值为0），所需要的比较次数为 (                           N                   2                      )                /                2                  N^2) /2         N2)/2,计算复杂度为                    O                (                       N                   2                      )                  O(N^2)         O(N2)。而在每次进行jaccard比较时，需要交集和并集，计算复杂度取决于文档的大小，假设所有文档的长度相等，都包含M个单词，则计算复杂度为                    O                (                       N                   2                      ⋅                M                )                  O(N^2 · M)         O(N2⋅M)。就会耗费很长时间，计算和内存消耗变得不可承受&lt;/li&gt;&lt;li&gt;Jaccard的计算替代方式：Minhash算法&lt;br/&gt; Minhash的好处：Minhash可以实现把一篇文章用一个较短的signature表示，这个signature有个很好的性质： 两个minhash signature的Jaccard相似度和原始文本的Jaccard相似度在概率上是一致的。 比较一次的所耗费的时间为numHash，总的计算复杂度为                    O                (                       N                   2                      ⋅                n                u                m                H                a                s                h                )                  O(N^2 · numHash)         O(N2⋅numHash)。而numHash是可以自己设置的大小，这就远小于M。&lt;/li&gt;</code></pre><h3 id="minhash如何工作？"><a href="#minhash如何工作？" class="headerlink" title="minhash如何工作？"></a>minhash如何工作？</h3><p>先介绍它的工作方式，可能能帮助你更好理解这个算法。<br/> 前提假设：如果两个集合非常相似 → 那么对这两个集合应用同一种变化，得到的变化结果也很相似 → 对这两个变化结果选取某种特征（比如选最小值），它们有很高的概率是相等的。</p><ol><li>假设我们拥有2个集合<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-comment"># 设置2个集合A和B</span><br><span class="hljs-attribute">A</span> = &#123;<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>&#125;<br><span class="hljs-attribute">B</span> = &#123;<span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>&#125;<br><br></code></pre></td></tr></table></figure></li><li>其jaccard相似度为：<figure class="highlight sas"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sas">pr<span class="hljs-meta">int</span>(<span class="hljs-string">&#x27;Jaccard相似度：&#x27;</span>, le<span class="hljs-meta">n</span>(A <span class="hljs-variable">&amp;amp</span>; B) / le<span class="hljs-meta">n</span>(A | B))<br>Jaccard相似度： 0.4285<br><br></code></pre></td></tr></table></figure></li></ol><h4 id="基于hash函数的算法"><a href="#基于hash函数的算法" class="headerlink" title="基于hash函数的算法"></a>基于hash函数的算法</h4><p>我们拥有哈希函数（有点像加密算法），它能将整数x映射到一个不同的整数，并且不会产生冲突（c 是大素数）。不同的哈希函数相当于不同的投影规则<br/>  </p><pre><code class="hljs">      h                a                s                h                (                x                )                =                (                a                x                +                b                )                %                c                  hash(x) = (ax + b )\% c         hash(x)=(ax+b)%c</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#设置某个哈希函数</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">hash</span>(<span class="hljs-params">x, a=<span class="hljs-number">1</span>, b=<span class="hljs-number">1</span>, p=<span class="hljs-number">11</span></span>):<br><br>    <span class="hljs-keyword">return</span> (a * x + b) % p<br><br><span class="hljs-comment">#对集合里的元素进行哈希，并计算最小哈希值</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">minhash</span>(<span class="hljs-params">s, <span class="hljs-built_in">hash</span></span>):<br><br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">min</span>(<span class="hljs-built_in">hash</span>(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> s)<br><br></code></pre></td></tr></table></figure><p>我们将某个文档A经过hash函数之后（Hash(A))，记录所得到的最小哈希值(minHash(A))。minHash(A)相当于此集合在某种观测视角下得到的结果。我们对文档B也进行计算，得到</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs stylus"><span class="hljs-function"><span class="hljs-title">Hash</span><span class="hljs-params">(A)</span></span> = <span class="hljs-selector-attr">[5, 8, 0, 3, 6]</span> <span class="hljs-built_in">minHash</span>(A) = <span class="hljs-number">0</span><br><span class="hljs-function"><span class="hljs-title">Hash</span><span class="hljs-params">(B)</span></span> = <span class="hljs-selector-attr">[0, 3, 6, 9, 1]</span>  <span class="hljs-built_in">minHash</span>(B) = <span class="hljs-number">0</span><br><br></code></pre></td></tr></table></figure><p>最后，minHash(A) &#x3D; minHash(B）的概率就是Jaccard相似度。这一步我们在之后会进行解释。</p><p>实际上，单次比较 minHash(A) 和 minHash(B），查看取值是否相等，这个事件的取值只有True or False。（就和抛硬币一样）只有我们经过多次hash函数操作（相当于经过了多次抛硬币），该事件发生的概率值理论上趋近于（A ∩ B）&#x2F; （ A ∪ B）。</p><p>因此，使用minhash方法对Jaccard的低维估计计算方式就是：<br/>  </p><pre><code class="hljs">        m                      i                      n                      H                      a                      s                      h                      (                      A                      )                      =                      m                      i                      n                      H                      a                      s                      h                      (                      B                      ）的次数                                  h                      a                      s                      h                      函数的个数                               \frac&#123;minHash(A) = minHash(B）的次数&#125;&#123;hash函数的个数&#125;         hash函数的个数minHash(A)=minHash(B）的次数​</code></pre><ol><li>接下来我们进行多个不同的hash函数的实验，并观察其变化趋势：<br/> 如果哈希函数产生的结果高度相关（甚至相同），则这些哈希函数提供的不同视角就减少了。这意味着我们实际上并没有从多个独立的角度去观察集合的相似性，从而可能导致估计的Jaccard相似度不够准确<br/> 生成k个不相同的随机数：<figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs arduino"><span class="hljs-function"><span class="hljs-keyword">import</span> random</span><br><span class="hljs-function">def <span class="hljs-title">pickRandomCoeffs</span><span class="hljs-params">(k)</span>:</span><br><span class="hljs-function">  randList =</span> []<br><br>  <span class="hljs-keyword">while</span> k &amp;gt; <span class="hljs-number">0</span>:<br><br>    randIndex = random.<span class="hljs-built_in">randint</span>(<span class="hljs-number">0</span>, <span class="hljs-number">99999</span>)<br>    <span class="hljs-keyword">while</span> randIndex in randList:<br>      randIndex = random.<span class="hljs-built_in">randint</span>(<span class="hljs-number">0</span>, <span class="hljs-number">99999</span>)<br>    randList.<span class="hljs-built_in">append</span>(randIndex)<br>    k = k - <span class="hljs-number">1</span><br>  <span class="hljs-keyword">return</span> randList<br><br></code></pre></td></tr></table></figure></li></ol><p>基于不相同的随机数，作为a和b，生成不同hash函数</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs stylus">#生成n个不同的hash函数，确保每个hash函数的a系数和b系数不同：<br><br>num_hash_funcs = <span class="hljs-number">10000</span><br>hash_funcs = <span class="hljs-selector-attr">[]</span><br><span class="hljs-selector-tag">a</span> = <span class="hljs-built_in">pickRandomCoeffs</span>(num_hash_funcs)<br><br><span class="hljs-selector-tag">b</span> = <span class="hljs-built_in">pickRandomCoeffs</span>(num_hash_funcs)<br><br><span class="hljs-keyword">for</span> <span class="hljs-selector-tag">i</span> <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_hash_funcs):<br>    #增加不同的hash函数，确保每次生成的hash函数不同<br>    hash_funcs<span class="hljs-selector-class">.append</span>(lambda <span class="hljs-attribute">x</span>, a=a[i], b=b[i]: <span class="hljs-built_in">hash</span>(x, a, b))<br>count = <span class="hljs-number">0</span><br><br><span class="hljs-keyword">for</span> <span class="hljs-selector-tag">a</span>, <span class="hljs-selector-tag">b</span> <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(minhash_values_A, minhash_values_B):<br>#如果hash函数得到的minhash相同<br>    <span class="hljs-keyword">if</span> <span class="hljs-selector-tag">a</span> == <span class="hljs-selector-tag">b</span>:<br>        count += <span class="hljs-number">1</span><br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(<span class="hljs-string">&#x27;进行比较的哈希函数个数：&#x27;</span>, len(hash_funcs)</span></span>)<br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(<span class="hljs-string">&#x27;Minhash相似度：&#x27;</span>, count/ len(hash_funcs)</span></span>)<br><br></code></pre></td></tr></table></figure><figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs tap">进行比较的哈希函数个数：<span class="hljs-number"> 5 </span>Minhash相似度： 0.6<br>进行比较的哈希函数个数：<span class="hljs-number"> 100 </span>Minhash相似度： 0.38<br>进行比较的哈希函数个数：<span class="hljs-number"> 1000 </span>Minhash相似度： 0.411<br>进行比较的哈希函数个数：<span class="hljs-number"> 5000 </span>Minhash相似度： 0.4242<br><br></code></pre></td></tr></table></figure><p>Jaccard相似度的理论值为： 0.4285。随着hash函数的个数增加，实验值逐渐逼近 0.4285</p><h4 id="基于打乱排序的做法"><a href="#基于打乱排序的做法" class="headerlink" title="基于打乱排序的做法"></a>基于打乱排序的做法</h4><p>hash函数相当于一种对集合的变换方式，但实际应用时，如果我们有多个hash函数，需要对每个集合计算minhash，而哈希操作的速度也比较慢。<br/> 既然只是找到一种对集合的变换方式，再用另一种视角来观察这个集合的特征值，有没有另一种更方便的变换方法呢？</p><p>我们可以使用基于打乱排序的算法。</p><p>假设两个文档的内容如下：<br/> 文档A：{上山打老虎}<br/> 文档B：{老虎不在家}<br/> 将其转为one-hot编码如下：</p><p>|原始下标|词|文档A|文档B<br>|——<br>|0|上|1|0<br>|1|山|1|0<br>|2|打|1|0<br>|3|老|1|1<br>|4|虎|1|1<br>|5|不|0|1<br>|6|在|0|1<br>|7|家|0|1</p><p>观测视角是：进行<strong>行变换</strong>，打乱排序，查找两个文档第一个为1的下标，判断它们是否相等</p><p>打乱行的排序：</p><p>|原始下标|idx|词|文档A|文档B<br>|——<br>|1|0|山|1|0<br>|7|1|家|0|1<br>|2|2|打|1|0<br>|3|3|老|1|1<br>|5|4|不|0|1<br>|6|5|在|0|1<br>|4|6|虎|1|1<br>|0|7|上|1|0</p><p>文档A变成{1,0,1,1,0,0,1,1}，第一个为1的jdx为0，（对应’山‘）<br/> 文档B变成{0,1,0,1,1,1,1,0}，第一个为1的idx为1，（对应’家’）<br/> 0 ！&#x3D; 1，表示在这次打乱中，两个文档第一个为1的下标不相等。<br/> 我们进行多次这样的打乱排序，并统计他们相等的次数，除以总次数，得到的就是minhash对jaccard相似度的估计。</p><p>具体代码如下：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">import</span> random<br><br><span class="hljs-comment"># 设置2个集合A和B</span><br><span class="hljs-attribute">A</span> =<span class="hljs-meta"> [0,0,1,1,1]</span><br><span class="hljs-attribute">B</span> =<span class="hljs-meta"> [1,0,1,1,0]</span><br><span class="hljs-attribute">idx</span> =<span class="hljs-meta"> [0,1,2,3,4]</span><br><span class="hljs-attribute">cnt</span> = <span class="hljs-number">0</span><br><br><span class="hljs-comment"># 计算Jaccard相似度</span><br><br><span class="hljs-attribute">print</span>(<span class="hljs-string">&quot;Jaccard相似度理论值&quot;</span>,sum([A[i] &amp;amp; B[i] for i in range(<span class="hljs-number">5</span>)]) / sum([A[i] | B[i] for i in range(<span class="hljs-number">5</span>)]))<br><br><span class="hljs-attribute">for</span> i in range(<span class="hljs-number">1000</span>):<br><br>    <span class="hljs-attribute">random</span>.shuffle(idx)<br>    <span class="hljs-attribute">newA</span> =<span class="hljs-meta"> [A[i] for i in idx]</span><br>    <span class="hljs-attribute">newB</span> =<span class="hljs-meta"> [B[i] for i in idx]</span><br><br>    <span class="hljs-comment"># 第一个为1的位置</span><br>    <span class="hljs-attribute">idxA</span> = newA.index(<span class="hljs-number">1</span>)<br>    <span class="hljs-attribute">idxB</span> = newB.index(<span class="hljs-number">1</span>)<br>    <span class="hljs-attribute">if</span> idxA == idxB:<br><br>        <span class="hljs-attribute">cnt</span> += <span class="hljs-number">1</span><br><br><br><span class="hljs-attribute">print</span>(<span class="hljs-string">&quot;Jaccard相似度实验值&quot;</span>,cnt / <span class="hljs-number">1000</span>)<br><br></code></pre></td></tr></table></figure><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Jaccard</span>相似度理论值 <span class="hljs-number">0</span>.<span class="hljs-number">5</span><br><span class="hljs-attribute">Jaccard</span>相似度实验值 <span class="hljs-number">0</span>.<span class="hljs-number">497</span><br><br></code></pre></td></tr></table></figure><p>在使用的时候，也可以首先计算一次hash值，得到hash(X_i)，然后对其进行线性变换，这样就省去了多次计算hash值的操作。<br/>  </p><pre><code class="hljs">      p                e                r                (                       x                   i                      )                =                (                a                ⋅                       h                   a                   s                   h                   (                           x                      i                          )                      +                b                )                %                c                  per(x_i) = (a\cdot&#123;hash(x_i)&#125; + b)\% c         per(xi​)=(a⋅hash(xi​)+b)%c                     m                i                n                h                a                s                h                (                x                )                =                m                i                n                (                p                e                r                (                       x                   i                      )                )                  minhash(x) = min(per(x_i))         minhash(x)=min(per(xi​))</code></pre><h3 id="为什么minhash有效"><a href="#为什么minhash有效" class="headerlink" title="为什么minhash有效?"></a>为什么minhash有效?</h3><p>case1:</p><blockquote></blockquote><p>”横看成岭侧成峰，远近高低各不同“ ——苏轼《题西林壁》</p><p>minhash相当于在不同视角（投影角度）下观察两个集合的特征点是否相同，如果他们在多次观察下都具有相同的特征点，那么他们很有可能是分布相似的集合。</p><p>我们想象现在存在两座山，如果A山和B山从东西南北四个角度观察，他们的最高点高度相同，次高点、次次高点的高度都相同，那么这两座山很可能就是形状一样的山。</p><p>minhash在实际操作上很容易，但为什么minHash(A) &#x3D; minHash(B）的概率就是Jaccard相似度呢？</p><p>case2:<br/>  </p><pre><code class="hljs">      P                r                (                m                i                n                H                a                s                h                (                A                )                =                m                i                n                H                a                s                h                (                B                )                )                =                               A                      ∩                      B                                  A                      ∪                      B                             =                J                a                c                c                a                r                d                (                A                ,                B                )                  Pr(minHash(A) = minHash(B)) = \frac&#123;A \cap B &#125;&#123;A \cup B &#125; = Jaccard(A,B)         Pr(minHash(A)=minHash(B))=A∪BA∩B​=Jaccard(A,B)</code></pre><p>为了方便理解，我们这里还是举一个直观的例子：</p><p>有一个班级，里面有30个小朋友，里面的小朋友不是会唱歌，就是会跳舞，还有的既会唱歌也会跳舞。</p><p>此时集合 </p><pre><code class="hljs">     A             =             &#123;             会唱歌的小朋友             &#125;              A = \&#123;会唱歌的小朋友\&#125;      A=&#123;会唱歌的小朋友&#125;，               B             =             &#123;             会跳舞的小朋友             &#125;              B = \&#123;会跳舞的小朋友\&#125;      B=&#123;会跳舞的小朋友&#125;，               A             ∪             B              A \cup B      A∪B 构成了全集                D              D      D</code></pre><p>我们寻找一种相同的投影维度（一种哈希函数）将小朋友们排序，并选出顺序第一的人。例如各自选出集合A和B中身高最高的小朋友，他们是同一个小朋友的概率，等价于在全班所有小朋友中都选出最高的小朋友，他既会唱歌也会跳舞的概率。</p><p>在这个例子中，身高就是一种将小朋友们向一个方向投影的哈希函数，同理还可以使用体重、力气、吃零食速度、谁哭得最响等等多个维度，最终我们多次投影得到计算的概率值就可以用来近似  </p><pre><code class="hljs">       A                   ∩                   B                             A                   ∪                   B                         \frac&#123;A \cap B &#125;&#123;A \cup B &#125;      A∪BA∩B​。</code></pre><p>转化成数学公式，就是: </p><pre><code class="hljs">     P             r             (             某一种投影             (             A             )             =             某一种投影             (             B             )             )             =                          A                   ∩                   B                             A                   ∪                   B                         Pr(某一种投影(A) = 某一种投影(B)) = \frac&#123;A \cap B &#125;&#123;A \cup B &#125;      Pr(某一种投影(A)=某一种投影(B))=A∪BA∩B​</code></pre><p>当多次投影都能得到相同的值时，我们就可以认为这两个集合很相似啦！</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><blockquote></blockquote><p><a href="https://www.cnblogs.com/mergen/p/5276501.html">使用MinHash算法计算两个集合的相似度 - unrealwalker - 博客园 (cnblogs.com)</a><br/> <a href="https://mccormickml.com/2015/06/12/minhash-tutorial-with-python-code/">MinHash 教程与 Python 代码 · 克里斯·麦科米克 — MinHash Tutorial with Python Code · Chris McCormick (mccormickml.com)</a><br/> <a href="https://ansvver.github.io/lsh_minhash.html">ansvver | 局部敏感哈希 - MinHash</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>【傻瓜教程】jsp连接MySQL数据库，及连接过程中出现空指针的坑。[附java与Mysql驱动程序下载]</title>
    <link href="/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20%E3%80%90%E5%82%BB%E7%93%9C%E6%95%99%E7%A8%8B%E3%80%91jsp%E8%BF%9E%E6%8E%A5MySQL%E6%95%B0%E6%8D%AE%E5%BA%93%EF%BC%8C%E5%8F%8A%E8%BF%9E%E6%8E%A5%E8%BF%87%E7%A8%8B%E4%B8%AD%E5%87%BA%E7%8E%B0%E7%A9%BA%E6%8C%87%E9%92%88%E7%9A%84%E5%9D%91%E3%80%82%5B%E9%99%84java%E4%B8%8EMysql%E9%A9%B1%E5%8A%A8%E7%A8%8B%E5%BA%8F%E4%B8%8B%E8%BD%BD%5D/"/>
    <url>/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20%E3%80%90%E5%82%BB%E7%93%9C%E6%95%99%E7%A8%8B%E3%80%91jsp%E8%BF%9E%E6%8E%A5MySQL%E6%95%B0%E6%8D%AE%E5%BA%93%EF%BC%8C%E5%8F%8A%E8%BF%9E%E6%8E%A5%E8%BF%87%E7%A8%8B%E4%B8%AD%E5%87%BA%E7%8E%B0%E7%A9%BA%E6%8C%87%E9%92%88%E7%9A%84%E5%9D%91%E3%80%82%5B%E9%99%84java%E4%B8%8EMysql%E9%A9%B1%E5%8A%A8%E7%A8%8B%E5%BA%8F%E4%B8%8B%E8%BD%BD%5D/</url>
    
    <content type="html"><![CDATA[<h1 id="【傻瓜教程】jsp连接MySQL数据库，及连接过程中出现空指针的坑。-附java与Mysql驱动程序下载"><a href="#【傻瓜教程】jsp连接MySQL数据库，及连接过程中出现空指针的坑。-附java与Mysql驱动程序下载" class="headerlink" title="【傻瓜教程】jsp连接MySQL数据库，及连接过程中出现空指针的坑。[附java与Mysql驱动程序下载]"></a>【傻瓜教程】jsp连接MySQL数据库，及连接过程中出现空指针的坑。[附java与Mysql驱动程序下载]</h1><p>课程作业中的网站要实现后台，需要进行数据库连接。记录连接过程及掉进去的坑。</p><ol><li>在Eclips中新建一个动态网站，输入项目名称。<br/> File - New - Dynamic Web Project<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/c2929be4ad216cf1050c89782cb3b077.png"/> 1.  右击项目，新建一个jsp文件<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/be80bc3d41965808577364a8513d4d91.png"/> 1.  通过Workbench来新建数据库。首先打开workbench，进入默认的数据库连接中。<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/cce6b88241831b43b300f9c3e86b6fe5.png"/> 1.  在左侧nevigator导航栏中右击，新建一个Schema，输入数据库名称。我的数据库名称是program。<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/0d17e2f97ad95cb73ef38f9cd0914e3e.png"/> 1.  双击建好的Schema，使其变黑，单击进入后选择table，右击新建表。我的表名称是new_table<img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/e23baccba7b87f5d3f8b0caeada5304e.png"/> 1.  <strong>新建表时会发现没办法新建列，是需要点右上角的这两个上箭头。实在是太坑了。</strong><br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/a17617347294450ea2df25f0707f0a04.png"/> 1.  建好表之后，右击选择select rows，然后可以输入表的内容。 1.  将mysql的纯java数据库驱动程序“mysql-connector-java-5.1.45-bin.jar”复制到web文件夹的WEB-INF&#x2F;lib目录下。（驱动程序附下载，见文末[^1]）<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/70983fce402463fddcfa8dc1ec44ee5f.png"/> 1.  重点来了，通过Jsp来连接数据库，代码如下 <figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><code class="hljs dts"><span class="hljs-variable">&amp;lt</span><span class="hljs-punctuation">;</span>%@ page <span class="hljs-attr">language</span><span class="hljs-operator">=</span><span class="hljs-string">&quot;java&quot;</span> contentT<span class="hljs-attr">ype</span><span class="hljs-operator">=</span><span class="hljs-string">&quot;text/html; charset=UTF-8&quot;</span> pageE<span class="hljs-attr">ncoding</span><span class="hljs-operator">=</span><span class="hljs-string">&quot;UTF-8&quot;</span>%<span class="hljs-variable">&amp;gt</span><span class="hljs-punctuation">;</span><br><span class="hljs-variable">&amp;lt</span><span class="hljs-punctuation">;</span>%@ page <span class="hljs-attr">import</span><span class="hljs-operator">=</span><span class="hljs-string">&quot;java.sql.*&quot;</span>%<span class="hljs-variable">&amp;gt</span><span class="hljs-punctuation">;</span><br><span class="hljs-variable">&amp;lt</span><span class="hljs-punctuation">;</span>!DOCTYPE html<span class="hljs-variable">&amp;gt</span><span class="hljs-punctuation">;</span><br><span class="hljs-variable">&amp;lt</span><span class="hljs-punctuation">;</span>html<span class="hljs-variable">&amp;gt</span><span class="hljs-punctuation">;</span><br><span class="hljs-variable">&amp;lt</span><span class="hljs-punctuation">;</span>head<span class="hljs-variable">&amp;gt</span><span class="hljs-punctuation">;</span><br><span class="hljs-variable">&amp;lt</span><span class="hljs-punctuation">;</span>meta <span class="hljs-attr">charset</span><span class="hljs-operator">=</span><span class="hljs-string">&quot;UTF-8&quot;</span><span class="hljs-variable">&amp;gt</span><span class="hljs-punctuation">;</span><br><span class="hljs-variable">&amp;lt</span><span class="hljs-punctuation">;</span>title<span class="hljs-variable">&amp;gt</span><span class="hljs-punctuation">;</span>访问MySQL数据库<span class="hljs-variable">&amp;lt</span><span class="hljs-punctuation">;</span>/title<span class="hljs-variable">&amp;gt</span><span class="hljs-punctuation">;</span><br><span class="hljs-variable">&amp;lt</span><span class="hljs-punctuation">;</span>/head<span class="hljs-variable">&amp;gt</span><span class="hljs-punctuation">;</span><br><span class="hljs-variable">&amp;lt</span><span class="hljs-punctuation">;</span>body<span class="hljs-variable">&amp;gt</span><span class="hljs-punctuation">;</span><br><span class="hljs-variable">&amp;lt</span><span class="hljs-punctuation">;</span>%<br>Connection <span class="hljs-attr">con</span> <span class="hljs-operator">=</span> <span class="hljs-attr">null</span><span class="hljs-punctuation">;</span><br>Statement <span class="hljs-attr">st</span> <span class="hljs-operator">=</span> <span class="hljs-attr">null</span><span class="hljs-punctuation">;</span><br>ResultSet <span class="hljs-attr">rs</span> <span class="hljs-operator">=</span> <span class="hljs-attr">null</span><span class="hljs-punctuation">;</span><br><span class="hljs-comment">//加载驱动</span><br><span class="hljs-title class_">try</span> <span class="hljs-punctuation">&#123;</span><br>Class.forName(<span class="hljs-string">&quot;com.mysql.jdbc.Driver&quot;</span>)<span class="hljs-punctuation">;</span><br><span class="hljs-punctuation">&#125;</span> catch (ClassNotFoundException e) <span class="hljs-punctuation">&#123;</span><br>e.printStackTrace()<span class="hljs-punctuation">;</span><br><span class="hljs-punctuation">&#125;</span><br>out.print(<span class="hljs-string">&quot;sa&quot;</span>)<span class="hljs-punctuation">;</span><br><span class="hljs-title class_">try</span> <span class="hljs-punctuation">&#123;</span><br><span class="hljs-comment">//前面都是一致的操作，可以直接复制粘贴，从建立连接开始要根据自己的数据库名称，用户名和密码来进行。</span><br><span class="hljs-comment">//建立连接。“jdbc:mysql://localhost:3306/+数据库名+?characterEncoding=utf-8&quot;,用户名，密码</span><br><span class="hljs-attr">con</span><span class="hljs-operator">=</span>DriverManager.getConnection(<span class="hljs-string">&quot;jdbc:mysql://localhost:3306/program?characterEncoding=utf-8&quot;</span>,<span class="hljs-string">&quot;root&quot;</span>,<span class="hljs-string">&quot;123456&quot;</span>)<span class="hljs-punctuation">;</span><br><span class="hljs-attr">st</span> <span class="hljs-operator">=</span> con.createStatement()<span class="hljs-punctuation">;</span><br><span class="hljs-comment">//发送查询SQL语句，返回结果集</span><br><span class="hljs-attr">rs</span> <span class="hljs-operator">=</span> st.executeQuery(<span class="hljs-string">&quot;select * from new_table &quot;</span>)<span class="hljs-punctuation">;</span><br>while(rs.next())<span class="hljs-punctuation">&#123;</span><br>out.print(rs.getString(<span class="hljs-string">&quot;id&quot;</span>) + <span class="hljs-string">&quot;&amp;amp;nbsp;&amp;amp;nbsp;&quot;</span>)<span class="hljs-punctuation">;</span><br>out.print(rs.getString(<span class="hljs-string">&quot;year&quot;</span>) + <span class="hljs-string">&quot;&amp;amp;nbsp;&amp;amp;nbsp;&quot;</span>)<span class="hljs-punctuation">;</span><br>out.print(rs.getString(<span class="hljs-string">&quot;name&quot;</span>) + <span class="hljs-string">&quot;&amp;amp;nbsp;&amp;amp;nbsp;&quot;</span>)<span class="hljs-punctuation">;</span><br>out.print(<span class="hljs-string">&quot;&amp;lt;br&amp;gt;&quot;</span>)<span class="hljs-punctuation">;</span><br><span class="hljs-punctuation">&#125;</span>  <br><span class="hljs-punctuation">&#125;</span> catch (SQLException e) <span class="hljs-punctuation">&#123;</span><br>e.printStackTrace()<span class="hljs-punctuation">;</span><br><span class="hljs-punctuation">&#125;</span>finally<span class="hljs-punctuation">&#123;</span><br>rs.close()<span class="hljs-punctuation">;</span><br>st.close()<span class="hljs-punctuation">;</span><br>con.close()<span class="hljs-punctuation">;</span><br><span class="hljs-punctuation">&#125;</span><br>%<span class="hljs-variable">&amp;gt</span><span class="hljs-punctuation">;</span><br><span class="hljs-variable">&amp;lt</span><span class="hljs-punctuation">;</span>/body<span class="hljs-variable">&amp;gt</span><span class="hljs-punctuation">;</span><br><span class="hljs-variable">&amp;lt</span><span class="hljs-punctuation">;</span>/html<span class="hljs-variable">&amp;gt</span><span class="hljs-punctuation">;</span><br><br></code></pre></td></tr></table></figure></li><li>本来以为到这里应该结束了，但谁知道一直无法打印数据库的内容。报错显示在rs.close()这里出现异常，通过代码测试if(rs &#x3D;&#x3D; null){out.print(“rs is null”);}，发现确实rs为空，而且也提示有NullPointerException空指针错误。核心原因提示Unable to load authentication plugin caching_sha2_password 。虽然不知道这是个什么鬼东西。思来想去一整天，觉得怎么可能数据库没连上呢？甚至吧workbench重装了还是一样。在网上找了n多教程，终于找到了。<br/> **原来是因为从MySQL 8.0.4开始, 默认的认证插件从mysql_native_password 变为caching_sha2_password. 需要进入mysql命令行来执行如下语句。并注意把你的用户名和密码替换掉。<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-keyword">ALTER</span> <span class="hljs-keyword">USER</span> <span class="hljs-string">&#x27;yourusername&#x27;</span>@<span class="hljs-string">&#x27;localhost&#x27;</span> IDENTIFIED <span class="hljs-keyword">WITH</span> mysql_native_password <span class="hljs-keyword">BY</span> <span class="hljs-string">&#x27;youpassword&#x27;</span>;<br><br></code></pre></td></tr></table></figure></li></ol><p>TIPS：不会进入mysql命令行的傻瓜教程：<br/> 12. 管理员身份运行cmd,在文件夹中找到mysql,选择Bin目录并进入<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/62a6899e53c687d0598e39662c12d919.png"/><br/> 13. 输入mysql -uroot -p和密码，进入Mysql<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/1d348210fcbfc04c2b3c563dc182ab51.png"/><br/> 14. 输入上述更改密码的指令<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/07bba0553db62699b7b43b61b87281aa.png"/><br/> 15. 这时再运行jsp代码，就不会再报错啦！5555终于可以正常显示内容了，我都要哭了。<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/0f8e2ada6e70d2ed32050f63aee37b74.png"/></p><p>附：<br/> <a href="https://pan.baidu.com/s/1mzegJAj-ETrZG3wFx1a-RA">驱动下载地址</a><br/> 提取码: g7c9</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>【超简易安装】在linux集群服务器上使用conda安装高版本cuda(cuda-11.8)和pytorch2.0</title>
    <link href="/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20%E3%80%90%E8%B6%85%E7%AE%80%E6%98%93%E5%AE%89%E8%A3%85%E3%80%91%E5%9C%A8linux%E9%9B%86%E7%BE%A4%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E4%BD%BF%E7%94%A8conda%E5%AE%89%E8%A3%85%E9%AB%98%E7%89%88%E6%9C%ACcuda(cuda-11.8)%E5%92%8Cpytorch2.0/"/>
    <url>/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20%E3%80%90%E8%B6%85%E7%AE%80%E6%98%93%E5%AE%89%E8%A3%85%E3%80%91%E5%9C%A8linux%E9%9B%86%E7%BE%A4%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E4%BD%BF%E7%94%A8conda%E5%AE%89%E8%A3%85%E9%AB%98%E7%89%88%E6%9C%ACcuda(cuda-11.8)%E5%92%8Cpytorch2.0/</url>
    
    <content type="html"><![CDATA[<h1 id="【超简易安装】在linux集群服务器上使用conda安装高版本cuda-cuda-11-8-和pytorch2-0"><a href="#【超简易安装】在linux集群服务器上使用conda安装高版本cuda-cuda-11-8-和pytorch2-0" class="headerlink" title="【超简易安装】在linux集群服务器上使用conda安装高版本cuda(cuda-11.8)和pytorch2.0"></a>【超简易安装】在linux集群服务器上使用conda安装高版本cuda(cuda-11.8)和pytorch2.0</h1><h4 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h4><h2 id="0-背景分析"><a href="#0-背景分析" class="headerlink" title="0. 背景分析"></a>0. 背景分析</h2><p>我使用的是lunix多人集群服务器。集群服务器需要用作业调度系统，也就是bsub命令之后才能提交作业，运行任务。在这种多人服务器下，如果想要查看原本的cuda版本，在命令行中直接输入nvidia-smi是无效的，会报错nvidia-smi：command not found。这种情况下如何查看cuda版本呢？可以看我之前的这篇文章 <a href="http://t.csdnimg.cn/szwbq">【nvidia-smi：command not found】如何在集群服务器上使用nvidia-smi查看GPU信息</a></p><p>看右上角，GPU的cuda版本为11.0，低于pytorch2.0需要的cuda11.8，因此考虑新安装一个高版本的cuda。（此前我也有疑惑，11.0是不是这块GPU支持的最高版本，但好像不是，可以自行下载更高版本的）<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/79c083b8f0adf616ea58e49a3c8d0c3f.png"/></p><h2 id="1-新建conda虚拟环境"><a href="#1-新建conda虚拟环境" class="headerlink" title="1. 新建conda虚拟环境"></a>1. 新建conda虚拟环境</h2><p>为了不影响其他版本的cuda，先新建虚拟环境。这里安装的是python3.10版本</p><figure class="highlight abnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs abnf">conda create -n env_name python<span class="hljs-operator">=</span><span class="hljs-operator">=</span><span class="hljs-number">3.10</span><br><br></code></pre></td></tr></table></figure><p>其中env_name是虚拟环境的名字，安装过程中输入y，随后用conda activate env_name命令进入虚拟环境。</p><h2 id="2-CUDA11-8安装"><a href="#2-CUDA11-8安装" class="headerlink" title="2. CUDA11.8安装"></a>2. CUDA11.8安装</h2><p>网上的教程有很多，也很复杂。但我突然发现<a href="https://anaconda.org/nvidia/repo/installers?label=cuda-11.8.0&amp;type=conda">conda官网</a>里有一键下载cuda版本包的命令，抱着试试看的心态就使用了。<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/002d36d09ad6bc72dce6f4b1c9444899.png"/><br/> 可以从label中筛选所需要的cuda版本，然后复制下载命令，直接在命令行中运行。<br/> 安装好之后输入nvcc -V，可以查看到相应版本的cuda。<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/c119e39a8c2fd1ce4290fc435f165c4d.png"/></p><h2 id="3-torch2-0安装"><a href="#3-torch2-0安装" class="headerlink" title="3. torch2.0安装"></a>3. torch2.0安装</h2><h3 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h3><p>这里选择使用下载.whl安装包的形式。在<a href="https://download.pytorch.org/whl/cu118/torch/">这个网站</a>上选择相应版本的torch。我选择的是第一个，即torch2.0版本+cuda11.8+python3.10，并且是linux系统的。(win_amd64指的是windows系统）<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/6b929cf3e2059773bd71bc6f9c3d6161.png"/><br/> 右键选择复制链接，然后在之前安装好的conda环境中，输入wget + 链接进行下载。如</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">wget</span> https://download.pytorch.org/whl/cu118/torch-<span class="hljs-number">2</span>.<span class="hljs-number">0</span>.<span class="hljs-number">0</span>%<span class="hljs-number">2</span>Bcu118-cp310-cp310-linux_x86_64.whl#sha256=<span class="hljs-number">4</span>b690e2b77f21073500c65d8bb9ea9656b8cb4e969f357370bbc992a3b074764<br><br></code></pre></td></tr></table></figure><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>下载结束后使用pip install 安装包名字.whl 进行安装</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">pip</span> install torch-<span class="hljs-number">2</span>.<span class="hljs-number">0</span>.<span class="hljs-number">0</span>+cu118-cp310-cp310-linux_x86_64.whl <br><br></code></pre></td></tr></table></figure><h3 id="查询是否成功"><a href="#查询是否成功" class="headerlink" title="查询是否成功"></a>查询是否成功</h3><p>输入python进入python环境，输入torch.__version__进行查询</p><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs asciidoc">python<br>torch.<span class="hljs-emphasis">__version__</span><br><br></code></pre></td></tr></table></figure><p>结果如图所示：<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/6f7b5855c2da5ed4e71a8097a739bd71.png"/><br/> 到这一步就在新的环境里配上cuda和torch了，运行项目代码总算不报错了。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>【常用bsub指令介绍】使用bsub命令提交作业、开启交互式窗口，在集群服务器上用pdb进行代码调试</title>
    <link href="/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20%E3%80%90%E5%B8%B8%E7%94%A8bsub%E6%8C%87%E4%BB%A4%E4%BB%8B%E7%BB%8D%E3%80%91%E4%BD%BF%E7%94%A8bsub%E5%91%BD%E4%BB%A4%E6%8F%90%E4%BA%A4%E4%BD%9C%E4%B8%9A%E3%80%81%E5%BC%80%E5%90%AF%E4%BA%A4%E4%BA%92%E5%BC%8F%E7%AA%97%E5%8F%A3%EF%BC%8C%E5%9C%A8%E9%9B%86%E7%BE%A4%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E7%94%A8pdb%E8%BF%9B%E8%A1%8C%E4%BB%A3%E7%A0%81%E8%B0%83%E8%AF%95/"/>
    <url>/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20%E3%80%90%E5%B8%B8%E7%94%A8bsub%E6%8C%87%E4%BB%A4%E4%BB%8B%E7%BB%8D%E3%80%91%E4%BD%BF%E7%94%A8bsub%E5%91%BD%E4%BB%A4%E6%8F%90%E4%BA%A4%E4%BD%9C%E4%B8%9A%E3%80%81%E5%BC%80%E5%90%AF%E4%BA%A4%E4%BA%92%E5%BC%8F%E7%AA%97%E5%8F%A3%EF%BC%8C%E5%9C%A8%E9%9B%86%E7%BE%A4%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E7%94%A8pdb%E8%BF%9B%E8%A1%8C%E4%BB%A3%E7%A0%81%E8%B0%83%E8%AF%95/</url>
    
    <content type="html"><![CDATA[<h4 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h4><h2 id="1-LSF作业调度系统和服务器集群介绍"><a href="#1-LSF作业调度系统和服务器集群介绍" class="headerlink" title="1. LSF作业调度系统和服务器集群介绍"></a>1. LSF作业调度系统和服务器集群介绍</h2><p>在一个服务器集群中，有很多的人要使用，却只有很少的GPU。LSF作业调度系统则是对每个用户提交的作业和需要使用的GPU进行调度。一般使用bsub命令来将待运行的作业提交到集群上。</p><p>用bsub &lt; run.sh提交了作业，一般是作业已经可以成功跑起来，提交了作业后直接等作业运行结束就行。但更多时候我们的代码可能会出现报错，需要进行调试。</p><p>一般情况下，我们会用pychram&#x2F; vscode等软件对代码打断点，进行调试。但使用的是本地的CPU资源，而不是服务器上的GPU。而且我们本地的电脑往往存储不够，不能加载大模型，没有在GPU上提交作业加载模型的话也无法在本地进行调试。这就需要用bsub开启一个交互式的窗口进行调试。</p><h2 id="2-bsub运行作业的两种方式"><a href="#2-bsub运行作业的两种方式" class="headerlink" title="2. bsub运行作业的两种方式"></a>2. bsub运行作业的两种方式</h2><h4 id="2-1-bsub直接提交作业"><a href="#2-1-bsub直接提交作业" class="headerlink" title="2.1 bsub直接提交作业"></a>2.1 bsub直接提交作业</h4><p>比较常用的一种方式。通常是把作业脚本和需要使用的gpu资源定义在sh文件里，然后用busb &lt; run.sh 来提交文件。一个sh文件示例如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">#</span><span class="language-bash">/bin/bash</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">BSUB -J job_name</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">BSUB -e /nfsshare/home/xxx/log/NAME_%J.err</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">BSUB -o /nfsshare/home/xxx/log/NAME_%J.out</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">BSUB -n 2</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">BSUB -q gpu</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">BSUB -R <span class="hljs-string">&quot;rusage[ngpus_physical=2]&quot;</span></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">BSUB -gpu <span class="hljs-string">&quot;num=2:mode=exclusive_process&quot;</span></span><br>python file.py<br><br></code></pre></td></tr></table></figure><p><strong>bsub参数说明</strong></p><p>|bsub参数|说明|示例<br>|——<br>|-n : 提交一个并行作业并指定作业中的核心数量|#BSUB -n 2<br>|-q : 将作业提交到指定的队列|如gpu, volta|#BSUB -q gpu<br>|-i : 从指定的文件路径获取作业的标准输入|输入路径<br>|-o : 将作业的标准输出附加到指定的文件路径|标准输出路径<br>|-e : 将作业的标准错误输出附加到指定的文件路径|报错输出路径<br>|-J : 将指定的名称分配给作业|名称|name<br>|-m : 在指定节点上运行提交的作业|-m gpu04</p><p><strong>不同GPU资源需求的命令示例</strong></p><p>(1)使用1块gpu卡运行作业</p><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs dts"><span class="hljs-number">1</span>、独占<span class="hljs-number">1</span>块gpu卡运行作业<br><span class="hljs-meta">#!/bin/sh</span><br><span class="hljs-meta">#BSUB –gpu <span class="hljs-string">&quot;num=1:mode=exclusive_process&quot;</span></span><br><span class="hljs-meta">#BSUB -n 1</span><br><span class="hljs-meta">#BSUB -q gpu</span><br><span class="hljs-meta">#BSUB -o %J.out</span><br><span class="hljs-meta">#BSUB -e %J.err</span><br><span class="hljs-meta">#BSUB -J gputest</span><br>nvidia-smi <span class="hljs-variable">&amp;gt</span><span class="hljs-punctuation">;</span><span class="hljs-variable">&amp;gt</span><span class="hljs-punctuation">;</span> out<br><br><br></code></pre></td></tr></table></figure><p>(2) 同一节点独占2块gpu卡运行作业</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-meta">#!/bin/sh</span><br><span class="hljs-comment">#BSUB -gpu &quot;num=2:mode=exclusive_process&quot;</span><br><span class="hljs-comment">#BSUB -n 2</span><br><span class="hljs-comment">#BSUB -q gpu</span><br><span class="hljs-comment">#BSUB -m gpu01</span><br><span class="hljs-comment">#BSUB -o %J.out</span><br><span class="hljs-comment">#BSUB -e %J.err</span><br><span class="hljs-comment">#BSUB -J gputest</span><br><span class="hljs-comment">#BSUB -R &quot;rusage[ngpus_physical=2]&quot;</span><br>nvidia-smi &amp;gt;&amp;gt;out<br><br></code></pre></td></tr></table></figure><p>(3) 独占两个节点上的4块gpu卡运行作业</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-meta">#!/bin/sh</span><br><span class="hljs-comment">#BSUB -gpu &quot;num=4:mode=exclusive_process&quot;</span><br><span class="hljs-comment">#BSUB -n 4</span><br><span class="hljs-comment">#BSUB -q gpu</span><br><span class="hljs-comment">#BSUB -o %J.out</span><br><span class="hljs-comment">#BSUB -e %J.err</span><br><span class="hljs-comment">#BSUB -J gputest</span><br><span class="hljs-comment">#BSUB -R &quot;rusage[ngpus_physical=2] span[ptile=2]&quot;</span><br>nvidia-smi &amp;gt;&amp;gt;out<br><br><br></code></pre></td></tr></table></figure><h4 id="2-2-bsub开启交互式窗口"><a href="#2-2-bsub开启交互式窗口" class="headerlink" title="2.2 bsub开启交互式窗口"></a>2.2 bsub开启交互式窗口</h4><p>用busb命令在命令行中开启一个交互式窗口可以方便我们使用交互式的 shell 会话，与计算节点上的 shell 进程进行交互。查看代码的中间过程。其使用方式为直接在命令行里输入bsub + gpu资源指定命令 + -Is &#x2F;bin&#x2F;bash，-Is &#x2F;bin&#x2F;bash 的意思是直接与计算节点进行交互，如：</p><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs ada">bsub -R <span class="hljs-string">&quot;rusage[ngpus_physical=1]&quot;</span>  -m gpu04  -<span class="hljs-keyword">Is</span> /bin/bash<br><br><br></code></pre></td></tr></table></figure><p>出现以下信息就表明已经成功连接到计算节点了：<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/63187f929ecb671aee20619b7300d6af.png"/></p><h2 id="3-使用pdb进行代码调试"><a href="#3-使用pdb进行代码调试" class="headerlink" title="3. 使用pdb进行代码调试"></a>3. 使用pdb进行代码调试</h2><p>可以自行百度更多pdb的使用指南，我常用的方式为：<br/> (1) 在python代码中需要添加断点的行前加入这两行：</p><figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs elm"><span class="hljs-keyword">import</span> pdb<br><span class="hljs-title">pdb</span>.set_trace()<br><br></code></pre></td></tr></table></figure><p>(2) 用bsub开启交互式窗口，然后输入 python project.py 运行python代码</p><p>(3）由于断点存在的关系，程序运行会卡在插入断点的那一行，然后输入interact启动一个python的交互式解释器，就可以像在vscode&#x2F;pychram的python interprect一样输入python代码查看对象的具体信息了。</p><h2 id="4-更多bsub指令分享"><a href="#4-更多bsub指令分享" class="headerlink" title="4. 更多bsub指令分享"></a>4. 更多bsub指令分享</h2><p>|常用指令|说明|示例<br>|——<br>|bsub &lt; xx.sh|提交脚本|bsub run.sh<br>|bjobs|查看作业信息<br>|bjobs -p jobid|查看某个作业等待运行（pend)的原因|bjobs -p 69087<br>|bkill jobid|终止某个作业<br>|lsload -l +gpu名称|查看某个节点的使用状态，其中ngpus为正在使用的gpu的数量|lsload -l gpu06<br>|lsload|显示集群的当前负载级别。<br>|bhosts|显示节点及其静态和动态资源</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>【wandb】在同一服务器上多用户登录</title>
    <link href="/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20%E3%80%90wandb%E3%80%91%E5%9C%A8%E5%90%8C%E4%B8%80%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E5%A4%9A%E7%94%A8%E6%88%B7%E7%99%BB%E5%BD%95/"/>
    <url>/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20%E3%80%90wandb%E3%80%91%E5%9C%A8%E5%90%8C%E4%B8%80%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E5%A4%9A%E7%94%A8%E6%88%B7%E7%99%BB%E5%BD%95/</url>
    
    <content type="html"><![CDATA[<h2 id="在同一服务器上多用户登录wandb"><a href="#在同一服务器上多用户登录wandb" class="headerlink" title="在同一服务器上多用户登录wandb"></a>在同一服务器上多用户登录wandb</h2><p>如果有别人在服务器上登录了wandb，很容易把日志存到他的wandb里。<br/> 可以在运行的sh脚本前，添加export WANDB_API_KEY&#x3D;‘xxxx’ （自己的wandb key），比如</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-built_in">export</span> <span class="hljs-attribute">CUDA_VISIBLE_DEVICES</span>=0,2<br><span class="hljs-built_in">export</span> <span class="hljs-attribute">WANDB_API_KEY</span>=<span class="hljs-string">&#x27;xxxx&#x27;</span><br><span class="hljs-attribute">GPU_NUM</span>=2<br>python xx.py<br><br></code></pre></td></tr></table></figure><p>这样就可以了</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>【plt保存图片的坑】python中为什么使用plt.savefig()保存图片为空白</title>
    <link href="/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20%E3%80%90plt%E4%BF%9D%E5%AD%98%E5%9B%BE%E7%89%87%E7%9A%84%E5%9D%91%E3%80%91python%E4%B8%AD%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8plt.savefig()%E4%BF%9D%E5%AD%98%E5%9B%BE%E7%89%87%E4%B8%BA%E7%A9%BA%E7%99%BD/"/>
    <url>/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20%E3%80%90plt%E4%BF%9D%E5%AD%98%E5%9B%BE%E7%89%87%E7%9A%84%E5%9D%91%E3%80%91python%E4%B8%AD%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8plt.savefig()%E4%BF%9D%E5%AD%98%E5%9B%BE%E7%89%87%E4%B8%BA%E7%A9%BA%E7%99%BD/</url>
    
    <content type="html"><![CDATA[<h1 id="【plt保存图片的坑】python中为什么使用plt-savefig-保存图片为空白"><a href="#【plt保存图片的坑】python中为什么使用plt-savefig-保存图片为空白" class="headerlink" title="【plt保存图片的坑】python中为什么使用plt.savefig()保存图片为空白"></a>【plt保存图片的坑】python中为什么使用plt.savefig()保存图片为空白</h1><p>检查一下，你是不是把plt.savefig()指令放在plt.show()之后了？</p><p>plt.show()会创建一个新的空白图形窗口,用于显示当前的图形。 因此,在plt.show()之后调用plt.savefig(),实际上是在保存这个新创建的空白图形窗口,而不是之前绘制的图形。</p><p>所以把plt.savefig()指令放在plt.show()之前即可解决</p><p>附：保存图片的代码</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs routeros">plt.savefig(<span class="hljs-string">&#x27;gemma-2b-it.svg&#x27;</span>, <span class="hljs-attribute">format</span>=<span class="hljs-string">&#x27;svg&#x27;</span>, <span class="hljs-attribute">dpi</span>=300, <span class="hljs-attribute">bbox_inches</span>=<span class="hljs-string">&#x27;tight&#x27;</span>)<br>plt.show()<br><br></code></pre></td></tr></table></figure>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>【nvidia-smi：command not found】如何在集群服务器上使用nvidia-smi查看GPU信息</title>
    <link href="/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20%E3%80%90nvidia-smi-command%20not%20found%E3%80%91%E5%A6%82%E4%BD%95%E5%9C%A8%E9%9B%86%E7%BE%A4%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E4%BD%BF%E7%94%A8nvidia-smi%E6%9F%A5%E7%9C%8BGPU%E4%BF%A1%E6%81%AF/"/>
    <url>/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20%E3%80%90nvidia-smi-command%20not%20found%E3%80%91%E5%A6%82%E4%BD%95%E5%9C%A8%E9%9B%86%E7%BE%A4%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E4%BD%BF%E7%94%A8nvidia-smi%E6%9F%A5%E7%9C%8BGPU%E4%BF%A1%E6%81%AF/</url>
    
    <content type="html"><![CDATA[<h4 id="1-nvidia-smi指令输出分析"><a href="#1-nvidia-smi指令输出分析" class="headerlink" title="1. nvidia-smi指令输出分析"></a>1. nvidia-smi指令输出分析</h4><p>对于普通的多卡服务器，nvidia-smi命令可以显示有关 NVIDIA 显卡和 GPU 的详细信息，如输入</p><figure class="highlight armasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs armasm"><span class="hljs-symbol">nvidia</span>-<span class="hljs-keyword">smi</span><br><br></code></pre></td></tr></table></figure><p>得到以下输出，可以看到相应的CUDA版本，GPU显存大小等信息。<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/e4e97cd16fc4816de604a39290038d8d.png"/></p><h4 id="2-集群上使用nvidia-smi指令"><a href="#2-集群上使用nvidia-smi指令" class="headerlink" title="2. 集群上使用nvidia-smi指令"></a>2. 集群上使用nvidia-smi指令</h4><p>如果登录了服务器后，直接在命令行中输入nvidia-smi，会有如下报错：<br/> bash: nvidia-smi: command not found<br/> 这是因为在集群中，我们只是登录到服务器上了，但没有运行作业，<strong>没有分配到GPU</strong>。我们需要提交一个作业，并在作业中运行nvidia-smi指令，从输出文件中读取相关信息。</p><p>以使用LSF作业调度系统为例，提交作业时往往需要编写一个check_nvidia_smi.sh文件，如下所示：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">#</span><span class="language-bash">/bin/bash</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">BSUB -J nvidia-smi</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">BSUB -n 1</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">BSUB -q gpu</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">BSUB -o 你的输出目录/nvidia_smi.txt</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">BSUB -gpu <span class="hljs-string">&quot;num=1:mode=exclusive_process&quot;</span></span><br>nvidia-smi<br><br></code></pre></td></tr></table></figure><p>其中，<br/> -J 指定作业名称<br/> -n 表示作业使用的核心数量<br/> -q 表示将作业提交的队列，gpu表示使用gpu队列，如果不确定队列名称可以使用bqueues指令来查看<br/> -o 表示输出文件的指定路径<br/> -gpu “num&#x3D;1:mode&#x3D;exclusive_process” 表示独占1张卡来运行作业</p><p>然后在命令行中提交此作业</p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm"><span class="hljs-keyword">bsub </span>&amp;lt<span class="hljs-comment">; check_nvidia_smi.sh</span><br><br></code></pre></td></tr></table></figure><p>即可在输出路径中找到输出文件，查看相应信息：<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/f95054038b256c9cbf5549c2669c60cd.png"/></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>【linux】执行bash文件后如何记录终端打印出来的输出和错误信息</title>
    <link href="/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20%E3%80%90linux%E3%80%91%E6%89%A7%E8%A1%8Cbash%E6%96%87%E4%BB%B6%E5%90%8E%E5%A6%82%E4%BD%95%E8%AE%B0%E5%BD%95%E7%BB%88%E7%AB%AF%E6%89%93%E5%8D%B0%E5%87%BA%E6%9D%A5%E7%9A%84%E8%BE%93%E5%87%BA%E5%92%8C%E9%94%99%E8%AF%AF%E4%BF%A1%E6%81%AF/"/>
    <url>/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20%E3%80%90linux%E3%80%91%E6%89%A7%E8%A1%8Cbash%E6%96%87%E4%BB%B6%E5%90%8E%E5%A6%82%E4%BD%95%E8%AE%B0%E5%BD%95%E7%BB%88%E7%AB%AF%E6%89%93%E5%8D%B0%E5%87%BA%E6%9D%A5%E7%9A%84%E8%BE%93%E5%87%BA%E5%92%8C%E9%94%99%E8%AF%AF%E4%BF%A1%E6%81%AF/</url>
    
    <content type="html"><![CDATA[<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>在命令行中执行sh文件后，终端里会显示打印出来的信息，但需要一点点翻动来看很麻烦。以下命令帮助我们将标准输出和标准错误显示在终端上，并且保存到文件中。</p><h3 id="命令"><a href="#命令" class="headerlink" title="命令"></a>命令</h3><p>命令如下，直接在命令行中输入即可：</p><figure class="highlight perl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs perl">LOG_STDOUT=<span class="hljs-string">&quot;/home/xxx/log/<span class="hljs-variable">$(</span>date &#x27;+%Y%m<span class="hljs-variable">%d</span>_%H%M<span class="hljs-variable">%S</span>&#x27;)_out.log&quot;</span><br>LOG_STDERR=<span class="hljs-string">&quot;/home/xxx/log/<span class="hljs-variable">$(</span>date &#x27;+%Y%m<span class="hljs-variable">%d</span>_%H%M<span class="hljs-variable">%S</span>&#x27;)_err.log&quot;</span><br><br>bash -<span class="hljs-keyword">x</span> xxx.sh &amp;<span class="hljs-keyword">gt</span>; &amp;<span class="hljs-keyword">gt</span>;(tee <span class="hljs-string">&quot;<span class="hljs-variable">$LOG_STDOUT</span>&quot;</span>) <span class="hljs-number">2</span>&amp;<span class="hljs-keyword">gt</span>; &amp;<span class="hljs-keyword">gt</span>;(tee <span class="hljs-string">&quot;<span class="hljs-variable">$LOG_STDERR</span>&quot;</span> &amp;<span class="hljs-keyword">gt</span>;&amp;amp;<span class="hljs-number">2</span>)<br><br></code></pre></td></tr></table></figure><h3 id="解释"><a href="#解释" class="headerlink" title="解释"></a>解释</h3><ol><li>LOG_STDOUT 为输出日志所在的目录1. LOG_STDERR 为错误日志所在的目录1. bash xxx.sh是执行任务脚本，加入-x参数是可以把sh里面的信息也打印出来（否则可能会忘记该任务用了哪些参数）1. 最后使用tee命令，可以使得输出和错误信息都保存到文件，同时也保持在终端中显示。</li></ol><h3 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h3><p>执行以上命令后我们会在相应目录下得到两个日志文件：<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/4ad7ea105998a5615ade45b7177b8072.png"/><br/> 其中out文件记录了stdout内容，err文件记录了所执行的sh脚本的内容，以及stderr的内容。同时在终端也能同步打印输出信息。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>【baichuan2模型部署经验】手把手教你在linux服务器上安装和使用baichuan2-7b-chat模型（模型下载+环境配置+报错分析）</title>
    <link href="/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20%E3%80%90baichuan2%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2%E7%BB%8F%E9%AA%8C%E3%80%91%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E5%9C%A8linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8baichuan2-7b-chat%E6%A8%A1%E5%9E%8B%EF%BC%88%E6%A8%A1%E5%9E%8B%E4%B8%8B%E8%BD%BD+%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE+%E6%8A%A5%E9%94%99%E5%88%86%E6%9E%90%EF%BC%89/"/>
    <url>/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20%E3%80%90baichuan2%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2%E7%BB%8F%E9%AA%8C%E3%80%91%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E5%9C%A8linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8baichuan2-7b-chat%E6%A8%A1%E5%9E%8B%EF%BC%88%E6%A8%A1%E5%9E%8B%E4%B8%8B%E8%BD%BD+%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE+%E6%8A%A5%E9%94%99%E5%88%86%E6%9E%90%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<h1 id="【baichuan2模型部署经验】手把手教你在linux服务器上安装和使用baichuan2-7b-chat模型（模型下载-环境配置-报错分析）"><a href="#【baichuan2模型部署经验】手把手教你在linux服务器上安装和使用baichuan2-7b-chat模型（模型下载-环境配置-报错分析）" class="headerlink" title="【baichuan2模型部署经验】手把手教你在linux服务器上安装和使用baichuan2-7b-chat模型（模型下载+环境配置+报错分析）"></a>【baichuan2模型部署经验】手把手教你在linux服务器上安装和使用baichuan2-7b-chat模型（模型下载+环境配置+报错分析）</h1><h4 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h4><h2 id="1-模型下载"><a href="#1-模型下载" class="headerlink" title="1. 模型下载"></a>1. 模型下载</h2><p>baichuan2的<a href="https://github.com/baichuan-inc/Baichuan2?tab=readme-ov-file#%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83">github</a>上给出的示例代码很简单，直接使用AutoModelForCausaLLM.from_pretrained(模型名称）这行代码就可以使用了，然而<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/5abb69f4a5209e941aff85a978d8f70d.png"/><br/> 殊不知在服务器上运行代码，没开代理的话，huggingface.co是连接不上的！因此我们需要把模型下载到本地。如果在huggingface模型库界面一个个文件手动下载效率太低，我在这篇文章中【 <a href="http://t.csdnimg.cn/6Shy1">从服务器上直接下载huggingface模型，解决huggingface无法连接问题</a>】给出了使用代码下载的方式，可以点击阅读。</p><h2 id="2-环境配置"><a href="#2-环境配置" class="headerlink" title="2. 环境配置"></a>2. 环境配置</h2><p>新建conda虚拟环境，下载配置文件。运行pip install -r requirements.txt<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/63b0ebcc0fde63b4134fbd706c7c77ba.png"/></p><h2 id="3-报错分析"><a href="#3-报错分析" class="headerlink" title="3. 报错分析"></a>3. 报错分析</h2><p>本以为就这么简单结束了，结果遇到一堆报错。解决如下</p><h3 id="1-AttributeError-module-‘torch-backends-cuda’-has-no-attribute-‘sdp-kernel’"><a href="#1-AttributeError-module-‘torch-backends-cuda’-has-no-attribute-‘sdp-kernel’" class="headerlink" title="1. AttributeError: module ‘torch.backends.cuda’ has no attribute ‘sdp_kernel’"></a>1. AttributeError: module ‘torch.backends.cuda’ has no attribute ‘sdp_kernel’</h3><p>【原因分析】要使用torch2.0版本才能正常运行，我之前的版本是1.几的。<br/> 【解决】重新建一个python&#x3D;3.10的虚拟环境，安装torch2.0<br/> 在<a href="https://download.pytorch.org/whl/cu118/torch/">这个网站</a>上选择相应版本的torch安装包。我选择的是第一个，即torch2.0版本+cuda11.8+python3.10，并且是linux系统的。(win_amd64指的是windows系统）<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/6b929cf3e2059773bd71bc6f9c3d6161.png"/><br/> 右键选择复制链接，然后在之前安装好的conda环境中，输入wget + 链接进行下载。如</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">wget</span> https://download.pytorch.org/whl/cu118/torch-<span class="hljs-number">2</span>.<span class="hljs-number">0</span>.<span class="hljs-number">0</span>%<span class="hljs-number">2</span>Bcu118-cp310-cp310-linux_x86_64.whl#sha256=<span class="hljs-number">4</span>b690e2b77f21073500c65d8bb9ea9656b8cb4e969f357370bbc992a3b074764<br><br></code></pre></td></tr></table></figure><p>下载结束后使用pip install 安装包名字.whl 进行安装</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">pip</span> install torch-<span class="hljs-number">2</span>.<span class="hljs-number">0</span>.<span class="hljs-number">0</span>+cu118-cp310-cp310-linux_x86_64.whl <br><br></code></pre></td></tr></table></figure><p>输入python进入python环境，输入torch.__version__进行查询</p><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs asciidoc">python<br>torch.<span class="hljs-emphasis">__version__</span><br><br></code></pre></td></tr></table></figure><p>结果如图所示：<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/6f7b5855c2da5ed4e71a8097a739bd71.png"/></p><h3 id="2-AttributeError-‘BaichuanTokenizer’-object-has-no-attribute-‘sp-model’"><a href="#2-AttributeError-‘BaichuanTokenizer’-object-has-no-attribute-‘sp-model’" class="headerlink" title="2. AttributeError: ‘BaichuanTokenizer’ object has no attribute ‘sp_model’"></a>2. AttributeError: ‘BaichuanTokenizer’ object has no attribute ‘sp_model’</h3><p>【解决方案】使用4.33.3版本的transformers</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">pip</span> install transformers==<span class="hljs-number">4</span>.<span class="hljs-number">33</span>.<span class="hljs-number">3</span><br><br></code></pre></td></tr></table></figure><h3 id="3-RuntimeError-Failed-to-import-transformers-modeling-utils-because-of-the-following-error-look-up-to-see-its-traceback"><a href="#3-RuntimeError-Failed-to-import-transformers-modeling-utils-because-of-the-following-error-look-up-to-see-its-traceback" class="headerlink" title="3. RuntimeError: Failed to import transformers.modeling_utils because of the following error (look up to see its traceback):"></a>3. RuntimeError: Failed to import transformers.modeling_utils because of the following error (look up to see its traceback):</h3><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs livecodeserver">CUDA Setup failed despite GPU being available. Please run <span class="hljs-keyword">the</span> following <span class="hljs-keyword">command</span> <span class="hljs-title">to</span> <span class="hljs-title">get</span> <span class="hljs-title">more</span> <span class="hljs-title">information</span>:<br><br>python -m bitsandbytes<br><br>Inspect <span class="hljs-keyword">the</span> output <span class="hljs-keyword">of</span> <span class="hljs-keyword">the</span> <span class="hljs-keyword">command</span> <span class="hljs-title">and</span> <span class="hljs-title">see</span> <span class="hljs-title">if</span> <span class="hljs-title">you</span> <span class="hljs-title">can</span> <span class="hljs-title">locate</span> <span class="hljs-title">CUDA</span> <span class="hljs-title">libraries</span>. <span class="hljs-title">You</span> <span class="hljs-title">might</span> <span class="hljs-title">need</span> <span class="hljs-title">to</span> <span class="hljs-title">add</span> <span class="hljs-title">them</span><br><span class="hljs-built_in">to</span> your LD_LIBRARY_PATH. If you suspect <span class="hljs-keyword">a</span> bug, please take <span class="hljs-keyword">the</span> information <span class="hljs-built_in">from</span> python -m bitsandbytes<br><span class="hljs-keyword">and</span> <span class="hljs-built_in">open</span> <span class="hljs-keyword">an</span> issue <span class="hljs-keyword">at</span>: <span class="hljs-keyword">https</span>://github.com/TimDettmers/bitsandbytes/issues<br><br></code></pre></td></tr></table></figure><p>因为cuda版本和torch不匹配（之前只下载了torch2.0,但没有配置相应的cuda11.8版本），执行以下代码安装cuda11.8</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">conda</span> install cuda -c nvidia/label/cuda-<span class="hljs-number">11</span>.<span class="hljs-number">8</span>.<span class="hljs-number">0</span><br><br></code></pre></td></tr></table></figure><h3 id="4-torch-cuda-OutOfMemoryError-CUDA-out-of-memory"><a href="#4-torch-cuda-OutOfMemoryError-CUDA-out-of-memory" class="headerlink" title="4. torch.cuda.OutOfMemoryError: CUDA out of memory."></a>4. torch.cuda.OutOfMemoryError: CUDA out of memory.</h3><p>Tried to allocate 192.00 MiB (GPU 0; 31.75 GiB total capacity; 30.58 GiB already allocated; 49.50 MiB free; 30.73 GiB reserved in total by PyTorch) If reserved memory is &gt;&gt; allocated memory try setting max_split_size_mb to avoid fragmentation. See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF<br/> 【原因分析】之前提交任务的时候只使用了单张内存为32G的V100卡，内存不足，需要指定两张卡来执行<br/> 【解决】我这里的是多人GPU服务器，提交任务使用的是LSF调度系统，参考提交任务的run.sh代码为：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">#</span><span class="language-bash">/bin/bash</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">BSUB -J 任务名称</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">BSUB -e /nfsshare/home/xxx/log/NAME_%J.err 报错日志路径</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">BSUB -o /nfsshare/home/xxx/log/NAME_%J.out 输出日志路径</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">BSUB -n 2 指定2块GPU</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">BSUB -q gpu 使用GPU序列</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">BSUB -m gpu01 用01号GOU</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">BSUB -R <span class="hljs-string">&quot;rusage[ngpus_physical=2]&quot;</span></span> <br><span class="hljs-meta prompt_">#</span><span class="language-bash">BSUB -gpu <span class="hljs-string">&quot;num=2:mode=exclusive_process&quot;</span></span> <br><br></code></pre></td></tr></table></figure>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>在服务器上下载anaconda，配置pytorch的过程 [CUDA11.4]，以及使用pychram连接服务器</title>
    <link href="/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20%E5%9C%A8%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E4%B8%8B%E8%BD%BDanaconda%EF%BC%8C%E9%85%8D%E7%BD%AEpytorch%E7%9A%84%E8%BF%87%E7%A8%8B%20%5BCUDA11.4%5D%EF%BC%8C%E4%BB%A5%E5%8F%8A%E4%BD%BF%E7%94%A8pychram%E8%BF%9E%E6%8E%A5%E6%9C%8D%E5%8A%A1%E5%99%A8/"/>
    <url>/2024/11/23/%E5%8E%9F%E5%88%9B--%20%20%E5%9C%A8%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E4%B8%8B%E8%BD%BDanaconda%EF%BC%8C%E9%85%8D%E7%BD%AEpytorch%E7%9A%84%E8%BF%87%E7%A8%8B%20%5BCUDA11.4%5D%EF%BC%8C%E4%BB%A5%E5%8F%8A%E4%BD%BF%E7%94%A8pychram%E8%BF%9E%E6%8E%A5%E6%9C%8D%E5%8A%A1%E5%99%A8/</url>
    
    <content type="html"><![CDATA[<h1 id="在服务器上下载anaconda，配置pytorch的过程-CUDA11-4-，以及使用pychram连接服务器"><a href="#在服务器上下载anaconda，配置pytorch的过程-CUDA11-4-，以及使用pychram连接服务器" class="headerlink" title="在服务器上下载anaconda，配置pytorch的过程 [CUDA11.4]，以及使用pychram连接服务器"></a>在服务器上下载anaconda，配置pytorch的过程 [CUDA11.4]，以及使用pychram连接服务器</h1><h3 id="服务器上anaconda下载及pytorch配置过程"><a href="#服务器上anaconda下载及pytorch配置过程" class="headerlink" title="服务器上anaconda下载及pytorch配置过程"></a>服务器上anaconda下载及pytorch配置过程</h3><p>​ 本文介绍利用mobaXterm连接服务器，再下载anaconda，配置Pytorch的过程。下载过程中经常有报错，踩了一些坑。</p><h5 id="1-登录服务器，下载anaconda"><a href="#1-登录服务器，下载anaconda" class="headerlink" title="1. 登录服务器，下载anaconda"></a>1. 登录服务器，下载anaconda</h5><p>先打开mobaXterm，打开session连接服务器。如果是第一次登录的话，可以点击左上角的session - SSH， 输入端口号，用户名，在命令行中输入密码。</p><p><strong>（1）下载anaconda</strong></p><p>先在<a href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/">清华镜像源</a>里下载对应的anaconda3，由于是Linux服务器，所以这里下载的是Anaconda3-4.0.0-Linux-x86_64.sh版本</p><p>利用服务器执行下载</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">wget</span> https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/Anaconda3-<span class="hljs-number">5</span>.<span class="hljs-number">3</span>.<span class="hljs-number">1</span>-Linux-x86_64.sh<br><br></code></pre></td></tr></table></figure><p>如果出现ERROR 403: Forbidden.的报错，可以把指令改成</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">wget</span> --user-agent=<span class="hljs-string">&quot;Mozilla&quot;</span>  https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/Anaconda3-<span class="hljs-number">5</span>.<span class="hljs-number">3</span>.<span class="hljs-number">1</span>-Linux-x86_64.sh<br><br></code></pre></td></tr></table></figure><p><strong>（2）下载完成后运行安装指令</strong></p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">bash</span> Anaconda3-<span class="hljs-number">5</span>.<span class="hljs-number">3</span>.<span class="hljs-number">1</span>-Linux-x86_64.sh<br><br></code></pre></td></tr></table></figure><p>一路yes即可，最后询问你是否要安装vscode，可以选择no。</p><p><strong>（3）安装完成后别忘了配置环境变量</strong></p><p>在左侧的文件夹中找到.bashrc，双击打开</p><p>在最后添加一行添加路径的代码，其中xxxxx(user name) 修改为自己的用户名。环境变量就配置好了。</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-built_in">export</span> <span class="hljs-attribute">PATH</span>=<span class="hljs-string">&quot;/home/xxxxxx(user name)/anaconda3/bin:<span class="hljs-variable">$PATH</span>&quot;</span><br><br></code></pre></td></tr></table></figure><p><strong>（4）测试是否安装成功</strong></p><p>输入指令</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-attribute">conda</span>  <span class="hljs-literal">info</span> --envs<br><br></code></pre></td></tr></table></figure><p>如果出现 &#x2F;home&#x2F;username&#x2F;anaconda3即表示安装成功。</p><h5 id="2-创建Pytorch虚拟环境，安装下载pytorch"><a href="#2-创建Pytorch虚拟环境，安装下载pytorch" class="headerlink" title="2. 创建Pytorch虚拟环境，安装下载pytorch"></a>2. 创建Pytorch虚拟环境，安装下载pytorch</h5><p><strong>（1）首先更改下载源</strong></p><p>下载Pytroch时通常会使用清华镜像，而在mobaXterm左侧的文件管理中找到.condarc文件，双击打开，将内容替换为如下所示。</p><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs less">channels:<br>  - defaults<br>show_channel_urls: true<br>default_channels:<br>  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main<br>  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/<span class="hljs-attribute">r</span><br><span class="hljs-attribute">  - https</span>:<span class="hljs-comment">//mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2</span><br><span class="hljs-attribute">custom_channels</span>:<br>  <span class="hljs-attribute">conda-forge</span>: <span class="hljs-attribute">https</span>:<span class="hljs-comment">//mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br>  <span class="hljs-attribute">msys2</span>: <span class="hljs-attribute">https</span>:<span class="hljs-comment">//mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br>  <span class="hljs-attribute">bioconda</span>: <span class="hljs-attribute">https</span>:<span class="hljs-comment">//mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br>  <span class="hljs-attribute">menpo</span>: <span class="hljs-attribute">https</span>:<span class="hljs-comment">//mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br>  <span class="hljs-attribute">pytorch</span>: <span class="hljs-attribute">https</span>:<span class="hljs-comment">//mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br>  <span class="hljs-attribute">simpleitk</span>: <span class="hljs-attribute">https</span>:<span class="hljs-comment">//mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><br><span class="hljs-attribute">remote_read_timeout_secs</span>: <span class="hljs-number">1000.0</span><br><br></code></pre></td></tr></table></figure><p>保存的时候会弹出窗口提示，选择yes即可。</p><p>在命令行中输入如下指令，更新下载源。要求输入y&#x2F;n的时候输入y即可。</p><figure class="highlight excel"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs excel">conda update -<span class="hljs-built_in">n</span> <span class="hljs-built_in">base</span> conda<br><br></code></pre></td></tr></table></figure><p><strong>（2）创建虚拟环境</strong></p><p>进入anaconda3文件夹</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> ./anaconda3<br><br></code></pre></td></tr></table></figure><p>创建名为pytorchenv的虚拟环境</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">conda</span> create -n pytorchenv python=<span class="hljs-number">3</span>.<span class="hljs-number">7</span><br><br></code></pre></td></tr></table></figure><p>激活并进入虚拟环境</p><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs applescript">conda <span class="hljs-built_in">activate</span> pytorchenv<br><br></code></pre></td></tr></table></figure><p><strong>（3）安装对应版本的Pytorch</strong></p><p>在<a href="https://pytorch.org/">Pytorch官网</a>中找到对应的pytorch版本，复制相应的命令行。<br/> 需要确认的参数有：<br/> 1.一般选择Stable<br/> 2.服务器为linux系统<br/> 3.使用conda包<br/> 4.选择python语言<br/> 5.选择相应的CUDA版本，查看CUDA版本可以在命令行中输入nvidia-smi，右上角就是了<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/9b75551e3e094385771b7de18ddaf5c0.png"/><br/> 选定pytorch版本后，复制下面的命令行语句<br/> <img alt="image-20211120150403149" src="https://i-blog.csdnimg.cn/blog_migrate/fe1c9e1dd0198fd635326f342bba476e.png"/></p><p>在命令行中粘贴</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">conda</span> install pytorch torchvision torchaudio cudatoolkit=<span class="hljs-number">11</span>.<span class="hljs-number">3</span> -c pytorch<br><br></code></pre></td></tr></table></figure><p>这个过程有时会报错，是网络连接不上，或者是其他一些未知错误，在安装的时候比较玄学。</p><p>安装失败的话需要多试几次，我在一个周六的上午突然就安装成功了，或许需要一定运气的成分。。</p><p>—-更新—–<br/> 使用pip语句安装通常会顺利一点，省去了conda安装时的安装环境检测<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/d014956a6b5b8412c857965337463aa2.png"/></p><p><strong>（4）测试是否安装成功</strong></p><figure class="highlight ceylon"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs ceylon">python<br><span class="hljs-keyword">import</span> torch<br>torch.cuda.<span class="hljs-keyword">is</span><span class="hljs-number">_</span>available()<br><br></code></pre></td></tr></table></figure><p>如果返回的是True就说明安装成功了。</p><p>【补充更新】</p><h5 id="3-在本地的pycharm上远程连接服务器，使用Pytorch"><a href="#3-在本地的pycharm上远程连接服务器，使用Pytorch" class="headerlink" title="3. 在本地的pycharm上远程连接服务器，使用Pytorch"></a>3. 在本地的pycharm上远程连接服务器，使用Pytorch</h5><p>现在我们已经可以在服务器端使用pytorch了，但是只能使用命令行来运行，还不是很方便。我们希望在本地电脑来编辑代码，使用pycharm来远程连接服务器，在服务器上进行调试。</p><p><strong>（1）下载pycharm专业版（需要破解）</strong><br/> 因为只用专业版才能连接服务器调试，可以自行网上下载并破解。</p><p><strong>（2） 添加ssh连接</strong><br/> 打开pycharm，在上方菜单栏里找到tools - deployment - configuration</p><p>打开后选择右上角的+号，选择SFTP,填写IP、端口号和密码，如下图所示：<br/> <img alt="image-20211126230732436" src="https://i-blog.csdnimg.cn/blog_migrate/980c0f5856c075ef9a54c8e349b7bd79.png"/></p><p>填写之后确认，点击test connection按钮，如果能seccessful connecte的话就说明配置好了。然后设置服务器中代码保存的位置(Root path)，我这里是&#x2F;home&#x2F;lyj，可修改为自己所对应的位置。</p><p><strong>（3）新建项目</strong><br/> 打开软件，点击左上角的file-new project新建项目。<br/> 选择python解释器<br/> 1：Location 这个位置是项目在本地所处的文件夹<br/> 2：Existing interpreter 选择已经存在的服务器端的python解释器。<br/> 3：remoter project location:这里是文件夹在服务器的存储位置<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/076850176d4bf5ea6ade4a514347d743.png"/></p><p><strong>（4）设置Run&#x2F;Debug Cofigurations</strong><br/> 选择项目，新建一个python文件。<br/> <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/2368f9cb556aabfbc9127141551d9ba0.png"/><br/> 如果运行按钮的绿色三角形没有亮起来的话，说明还没有设置run&#x2F;debug configurations。</p><p>单击Edit Configurations</p><p><img alt="image-20211127164937437" src="https://i-blog.csdnimg.cn/blog_migrate/9c488becc5b26d7484f96746903fe9c0.png"/><br/> 可以看见python interpreter中已经选择了pytorchenv虚拟环境中的python解释器，然后我们把script path修改为刚才新建的py文件所在的位置（注意一定要选到可执行的.py文件）<br/> <img alt="image-20211127164752650" src="https://i-blog.csdnimg.cn/blog_migrate/03ca1431baf656b1ecb23c746fdab985.png"/><br/> <strong>（5）设置本地项目与服务器项目的映射，并同步更新</strong><br/> 最后就是将本地代码与服务器代码同步起来，这样在本地修改的时候，服务器中存的代码也会同步修改。</p><p>设置本地文件夹与服务器中的文件夹自动同步。如图所示勾选automatic upload。这样在本地新建的文件都会自动上传到服务器中了。<br/> <img alt="image-20211127165801676" src="https://i-blog.csdnimg.cn/blog_migrate/84ec0d68abaa9602396d33025cd2b14f.png"/></p><p>这样运行本地修改的代码的时候，可以发现在下方的File Transfer里代码也同步更新到服务器所对应的代码中了。<br/> <img alt="image-20211127165725570" src="https://i-blog.csdnimg.cn/blog_migrate/112a0394a403893859844f22eb5d5c7b.png"/><br/> 过程比较繁琐，也可能出现意想不到的情况，但只要有耐心，过段时间再试试，可能就能解决好了~</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>测试的文章标题</title>
    <link href="/2019/10/10/%E6%B5%8B%E8%AF%95%E6%96%87%E4%BB%B6/"/>
    <url>/2019/10/10/%E6%B5%8B%E8%AF%95%E6%96%87%E4%BB%B6/</url>
    
    <content type="html"><![CDATA[<h1 id="这是井号开始的标题"><a href="#这是井号开始的标题" class="headerlink" title="这是井号开始的标题"></a>这是井号开始的标题</h1><p>这是第一句话<br>这是图片<br><img src="https://lyj-aliyun.oss-cn-shanghai.aliyuncs.com/test/test.jpg" alt="test.jpg"></p><h2 id="这是副标题"><a href="#这是副标题" class="headerlink" title="这是副标题"></a>这是副标题</h2><h4 id="四级标题"><a href="#四级标题" class="headerlink" title="四级标题"></a>四级标题</h4>]]></content>
    
    
    
    <tags>
      
      <tag>Injury</tag>
      
      <tag>Fight</tag>
      
      <tag>Shocking</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
